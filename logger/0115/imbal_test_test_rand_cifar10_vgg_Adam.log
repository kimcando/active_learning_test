

Fri Jan 15 14:45:41 2021
imbal_test_test_rand_cifar10_vgg_Adam's set level: 10
imbal_test_test_rand_cifar10_vgg_Adam logger is ready
imbal_test with imbalance_ratio: [0.2 0.8 0.2 0.8 0.2 1.  1.  1.  1.  1. ]
parallel mode is False
initial count: cifar10: [0 1 2 3 4 5 6 7 8 9] class, each has [5000 5000 5000 5000 5000 5000 5000 5000 5000 5000]
cifar10: [0 1 2 3 4 5 6 7 8 9] class, each has [1000 4000 1000 4000 1000 5000 5000 5000 5000 5000]
Epoch@@0
TRAINING class wise acc@0 :: {0: [0.0], 1: [0.027], 2: [0.0], 3: [0.022], 4: [0.0], 5: [0.1724], 6: [0.2426], 7: [0.2856], 8: [0.2066], 9: [0.0754]}
TRAIINING epoch@0 ::  acc@0.142  loss@2.433
TESTING class wise acc@0 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.005], 4: [0.0], 5: [0.011], 6: [0.002], 7: [0.0], 8: [0.995], 9: [0.0]}
TESTING epoch@0 ::  acc@0.101  loss@2.489
Epoch@@1
TRAINING class wise acc@1 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.01925], 4: [0.0], 5: [0.112], 6: [0.1798], 7: [0.1476], 8: [0.2948], 9: [0.2638]}
TRAIINING epoch@1 ::  acc@0.141  loss@2.160
TESTING class wise acc@1 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.003], 4: [0.0], 5: [0.0], 6: [0.002], 7: [0.999], 8: [0.0], 9: [0.0]}
TESTING epoch@1 ::  acc@0.100  loss@2.538
Epoch@@2
TRAINING class wise acc@2 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.0], 4: [0.0], 5: [0.1738], 6: [0.2462], 7: [0.241], 8: [0.1076], 9: [0.2378]}
TRAIINING epoch@2 ::  acc@0.140  loss@2.161
TESTING class wise acc@2 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.004], 4: [0.0], 5: [0.0], 6: [0.0], 7: [0.0], 8: [0.0], 9: [0.999]}
TESTING epoch@2 ::  acc@0.100  loss@2.465
Epoch@@3
TRAINING class wise acc@3 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.0], 4: [0.0], 5: [0.196], 6: [0.3102], 7: [0.1524], 8: [0.1516], 9: [0.1972]}
TRAIINING epoch@3 ::  acc@0.140  loss@2.161
TESTING class wise acc@3 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.001], 4: [0.0], 5: [0.0], 6: [0.003], 7: [0.0], 8: [1.0], 9: [0.0]}
TESTING epoch@3 ::  acc@0.100  loss@2.500
Epoch@@4
TRAINING class wise acc@4 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.0], 4: [0.0], 5: [0.0992], 6: [0.2496], 7: [0.305], 8: [0.1626], 9: [0.184]}
TRAIINING epoch@4 ::  acc@0.139  loss@2.162
TESTING class wise acc@4 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.001], 4: [0.0], 5: [1.0], 6: [0.001], 7: [0.0], 8: [0.0], 9: [0.0]}
TESTING epoch@4 ::  acc@0.100  loss@2.524
Epoch@@5
TRAINING class wise acc@5 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.0], 4: [0.0], 5: [0.182], 6: [0.2458], 7: [0.1596], 8: [0.2586], 9: [0.1542]}
TRAIINING epoch@5 ::  acc@0.139  loss@2.161
TESTING class wise acc@5 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.001], 4: [0.0], 5: [0.0], 6: [0.0], 7: [0.999], 8: [0.0], 9: [0.0]}
TESTING epoch@5 ::  acc@0.100  loss@2.484
Epoch@@6
TRAINING class wise acc@6 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.0], 4: [0.0], 5: [0.2062], 6: [0.2602], 7: [0.1606], 8: [0.217], 9: [0.1428]}
TRAIINING epoch@6 ::  acc@0.137  loss@2.162
TESTING class wise acc@6 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.006], 4: [0.0], 5: [0.997], 6: [0.002], 7: [0.0], 8: [0.0], 9: [0.0]}
TESTING epoch@6 ::  acc@0.100  loss@2.516
Epoch@@7
TRAINING class wise acc@7 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.0], 4: [0.0], 5: [0.2218], 6: [0.2242], 7: [0.233], 8: [0.1806], 9: [0.1424]}
TRAIINING epoch@7 ::  acc@0.139  loss@2.161
TESTING class wise acc@7 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.002], 4: [0.0], 5: [0.0], 6: [0.001], 7: [0.0], 8: [0.0], 9: [0.999]}
TESTING epoch@7 ::  acc@0.100  loss@2.505
Epoch@@8
TRAINING class wise acc@8 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.0], 4: [0.0], 5: [0.1362], 6: [0.2458], 7: [0.1612], 8: [0.2548], 9: [0.1924]}
TRAIINING epoch@8 ::  acc@0.138  loss@2.162
TESTING class wise acc@8 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.005], 4: [0.0], 5: [0.999], 6: [0.0], 7: [0.0], 8: [0.0], 9: [0.0]}
TESTING epoch@8 ::  acc@0.100  loss@2.512
Epoch@@9
TRAINING class wise acc@9 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.0], 4: [0.0], 5: [0.3346], 6: [0.1936], 7: [0.1856], 8: [0.1432], 9: [0.1628]}
TRAIINING epoch@9 ::  acc@0.142  loss@2.161
TESTING class wise acc@9 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.007], 4: [0.0], 5: [0.0], 6: [0.0], 7: [0.0], 8: [0.999], 9: [0.0]}
TESTING epoch@9 ::  acc@0.101  loss@2.520
Epoch@@10
TRAINING class wise acc@10 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.0], 4: [0.0], 5: [0.2064], 6: [0.169], 7: [0.1872], 8: [0.162], 9: [0.2904]}
TRAIINING epoch@10 ::  acc@0.141  loss@2.161
TESTING class wise acc@10 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.001], 4: [0.0], 5: [0.0], 6: [0.001], 7: [0.0], 8: [1.0], 9: [0.0]}
TESTING epoch@10 ::  acc@0.100  loss@2.482
Epoch@@11
TRAINING class wise acc@11 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.0], 4: [0.0], 5: [0.136], 6: [0.1774], 7: [0.2782], 8: [0.2162], 9: [0.2024]}
TRAIINING epoch@11 ::  acc@0.140  loss@2.161
TESTING class wise acc@11 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.001], 4: [0.0], 5: [0.0], 6: [1.0], 7: [0.0], 8: [0.0], 9: [0.0]}
TESTING epoch@11 ::  acc@0.100  loss@2.481
Epoch@@12
TRAINING class wise acc@12 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.0], 4: [0.0], 5: [0.1814], 6: [0.0764], 7: [0.1782], 8: [0.3058], 9: [0.2596]}
TRAIINING epoch@12 ::  acc@0.139  loss@2.161
TESTING class wise acc@12 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.001], 4: [0.0], 5: [1.0], 6: [0.002], 7: [0.0], 8: [0.0], 9: [0.0]}
TESTING epoch@12 ::  acc@0.100  loss@2.503
Epoch@@13
TRAINING class wise acc@13 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.0], 4: [0.0], 5: [0.1784], 6: [0.234], 7: [0.1046], 8: [0.3034], 9: [0.179]}
TRAIINING epoch@13 ::  acc@0.139  loss@2.160
TESTING class wise acc@13 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.001], 4: [0.0], 5: [0.0], 6: [0.002], 7: [0.0], 8: [1.0], 9: [0.0]}
TESTING epoch@13 ::  acc@0.100  loss@2.496
Epoch@@14
TRAINING class wise acc@14 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.0], 4: [0.0], 5: [0.182], 6: [0.195], 7: [0.196], 8: [0.1786], 9: [0.2252]}
TRAIINING epoch@14 ::  acc@0.136  loss@2.161
TESTING class wise acc@14 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.003], 4: [0.0], 5: [0.0], 6: [0.999], 7: [0.0], 8: [0.0], 9: [0.0]}
TESTING epoch@14 ::  acc@0.100  loss@2.490
Epoch@@15


Fri Jan 15 14:56:03 2021
imbal_test_test_rand_cifar10_vgg_Adam's set level: 10
imbal_test_test_rand_cifar10_vgg_Adam logger is ready
imbal_test with imbalance_ratio: [0.5 0.5 0.5 1.  1.  1.  1.  1.  1.  1. ]
parallel mode is False
initial count: cifar10: [0 1 2 3 4 5 6 7 8 9] class, each has [5000 5000 5000 5000 5000 5000 5000 5000 5000 5000]
cifar10: [0 1 2 3 4 5 6 7 8 9] class, each has [2500 2500 2500 5000 5000 5000 5000 5000 5000 5000]
Epoch@@0
TRAINING class wise acc@0 :: {0: [0.0212], 1: [0.002], 2: [0.0004], 3: [0.1654], 4: [0.1588], 5: [0.0846], 6: [0.2586], 7: [0.182], 8: [0.124], 9: [0.111]}
TRAIINING epoch@0 ::  acc@0.129  loss@2.468
TESTING class wise acc@0 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.0], 4: [0.986], 5: [0.0], 6: [0.0], 7: [0.0], 8: [0.133], 9: [0.0]}
TESTING epoch@0 ::  acc@0.112  loss@2.330
Epoch@@1
TRAINING class wise acc@1 :: {0: [0.0064], 1: [0.0], 2: [0.0], 3: [0.1262], 4: [0.0574], 5: [0.1358], 6: [0.405], 7: [0.2216], 8: [0.5874], 9: [0.2568]}
TRAIINING epoch@1 ::  acc@0.211  loss@2.024
TESTING class wise acc@1 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.0], 4: [0.375], 5: [0.0], 6: [0.356], 7: [0.0], 8: [0.622], 9: [0.256]}
TESTING epoch@1 ::  acc@0.161  loss@2.135
Epoch@@2
TRAINING class wise acc@2 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.0898], 4: [0.0998], 5: [0.2328], 6: [0.411], 7: [0.2102], 8: [0.6596], 9: [0.51]}
TRAIINING epoch@2 ::  acc@0.260  loss@1.856
TESTING class wise acc@2 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.0], 4: [0.0], 5: [0.0], 6: [0.847], 7: [0.21], 8: [0.143], 9: [0.649]}
TESTING epoch@2 ::  acc@0.185  loss@2.198
Epoch@@3
TRAINING class wise acc@3 :: {0: [0.0], 1: [0.0004], 2: [0.0], 3: [0.0798], 4: [0.0576], 5: [0.3], 6: [0.3782], 7: [0.3078], 8: [0.6046], 9: [0.6456]}
TRAIINING epoch@3 ::  acc@0.279  loss@1.816
TESTING class wise acc@3 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.0], 4: [0.288], 5: [0.0], 6: [0.446], 7: [0.517], 8: [0.555], 9: [0.848]}
TESTING epoch@3 ::  acc@0.265  loss@1.843
Epoch@@4
TRAINING class wise acc@4 :: {0: [0.0328], 1: [0.008], 2: [0.0224], 3: [0.0982], 4: [0.0702], 5: [0.1688], 6: [0.6298], 7: [0.4626], 8: [0.6732], 9: [0.7706]}
TRAIINING epoch@4 ::  acc@0.342  loss@1.701
TESTING class wise acc@4 :: {0: [0.0], 1: [0.0], 2: [0.001], 3: [0.0], 4: [0.65], 5: [0.0], 6: [0.0], 7: [0.338], 8: [0.819], 9: [0.847]}
TESTING epoch@4 ::  acc@0.265  loss@2.010
Epoch@@5
TRAINING class wise acc@5 :: {0: [0.1048], 1: [0.136], 2: [0.1292], 3: [0.1104], 4: [0.2194], 5: [0.2932], 6: [0.657], 7: [0.607], 8: [0.7912], 9: [0.7558]}
TRAIINING epoch@5 ::  acc@0.426  loss@1.490
TESTING class wise acc@5 :: {0: [0.668], 1: [0.0], 2: [0.328], 3: [0.0], 4: [0.0], 5: [0.447], 6: [0.736], 7: [0.808], 8: [0.0], 9: [0.87]}
TESTING epoch@5 ::  acc@0.386  loss@1.967
Epoch@@6
TRAINING class wise acc@6 :: {0: [0.1268], 1: [0.3464], 2: [0.0548], 3: [0.1408], 4: [0.4546], 5: [0.6054], 6: [0.7062], 7: [0.6954], 8: [0.7884], 9: [0.7566]}
TRAIINING epoch@6 ::  acc@0.519  loss@1.298
TESTING class wise acc@6 :: {0: [0.118], 1: [0.751], 2: [0.0], 3: [0.005], 4: [0.564], 5: [0.319], 6: [0.088], 7: [0.865], 8: [0.729], 9: [0.825]}
TESTING epoch@6 ::  acc@0.426  loss@1.802
Epoch@@7
TRAINING class wise acc@7 :: {0: [0.2376], 1: [0.5448], 2: [0.0296], 3: [0.2024], 4: [0.6288], 5: [0.6256], 6: [0.759], 7: [0.7462], 8: [0.8102], 9: [0.791]}
TRAIINING epoch@7 ::  acc@0.585  loss@1.150
TESTING class wise acc@7 :: {0: [0.353], 1: [0.76], 2: [0.0], 3: [0.106], 4: [0.529], 5: [0.409], 6: [0.849], 7: [0.755], 8: [0.897], 9: [0.77]}
TESTING epoch@7 ::  acc@0.543  loss@1.373
Epoch@@8
TRAINING class wise acc@8 :: {0: [0.4764], 1: [0.696], 2: [0.0088], 3: [0.3018], 4: [0.7282], 5: [0.6352], 6: [0.7868], 7: [0.785], 8: [0.8358], 9: [0.8376]}
TRAIINING epoch@8 ::  acc@0.647  loss@1.003
TESTING class wise acc@8 :: {0: [0.559], 1: [0.771], 2: [0.074], 3: [0.059], 4: [0.44], 5: [0.845], 6: [0.571], 7: [0.79], 8: [0.807], 9: [0.735]}
TESTING epoch@8 ::  acc@0.565  loss@1.263
Epoch@@9
TRAINING class wise acc@9 :: {0: [0.6208], 1: [0.7236], 2: [0.1004], 3: [0.438], 4: [0.754], 5: [0.6412], 6: [0.7976], 7: [0.7986], 8: [0.842], 9: [0.8522]}
TRAIINING epoch@9 ::  acc@0.688  loss@0.894
TESTING class wise acc@9 :: {0: [0.702], 1: [0.635], 2: [0.036], 3: [0.542], 4: [0.829], 5: [0.513], 6: [0.711], 7: [0.89], 8: [0.71], 9: [0.815]}
TESTING epoch@9 ::  acc@0.638  loss@1.016
Epoch@@10
TRAINING class wise acc@10 :: {0: [0.6984], 1: [0.7968], 2: [0.21], 3: [0.5588], 4: [0.78], 5: [0.6544], 6: [0.8386], 7: [0.8224], 8: [0.8776], 9: [0.8786]}
TRAIINING epoch@10 ::  acc@0.737  loss@0.771
TESTING class wise acc@10 :: {0: [0.316], 1: [0.763], 2: [0.261], 3: [0.433], 4: [0.74], 5: [0.757], 6: [0.682], 7: [0.883], 8: [0.636], 9: [0.72]}
TESTING epoch@10 ::  acc@0.619  loss@1.245
Epoch@@11
TRAINING class wise acc@11 :: {0: [0.7108], 1: [0.828], 2: [0.3188], 3: [0.6174], 4: [0.8], 5: [0.6688], 6: [0.8422], 7: [0.8418], 8: [0.8892], 9: [0.887]}
TRAIINING epoch@11 ::  acc@0.762  loss@0.700
TESTING class wise acc@11 :: {0: [0.267], 1: [0.673], 2: [0.021], 3: [0.654], 4: [0.212], 5: [0.795], 6: [0.739], 7: [0.704], 8: [0.704], 9: [0.896]}
TESTING epoch@11 ::  acc@0.567  loss@1.583
Epoch@@12
TRAINING class wise acc@12 :: {0: [0.7372], 1: [0.8316], 2: [0.3948], 3: [0.6594], 4: [0.8058], 5: [0.7038], 6: [0.8552], 7: [0.8578], 8: [0.8924], 9: [0.8988]}
TRAIINING epoch@12 ::  acc@0.783  loss@0.665
TESTING class wise acc@12 :: {0: [0.877], 1: [0.859], 2: [0.274], 3: [0.515], 4: [0.529], 5: [0.794], 6: [0.739], 7: [0.794], 8: [0.904], 9: [0.75]}
TESTING epoch@12 ::  acc@0.703  loss@0.987
Epoch@@13
TRAINING class wise acc@13 :: {0: [0.7584], 1: [0.8592], 2: [0.4704], 3: [0.6692], 4: [0.8424], 5: [0.7336], 6: [0.8714], 7: [0.8734], 8: [0.896], 9: [0.909]}
TRAIINING epoch@13 ::  acc@0.805  loss@0.593
TESTING class wise acc@13 :: {0: [0.718], 1: [0.925], 2: [0.416], 3: [0.465], 4: [0.86], 5: [0.28], 6: [0.914], 7: [0.117], 8: [0.81], 9: [0.651]}
TESTING epoch@13 ::  acc@0.616  loss@1.340
Epoch@@14
TRAINING class wise acc@14 :: {0: [0.612], 1: [0.6884], 2: [0.2048], 3: [0.5292], 4: [0.688], 5: [0.6242], 6: [0.7968], 7: [0.6788], 8: [0.829], 9: [0.808]}
TRAIINING epoch@14 ::  acc@0.671  loss@0.960
TESTING class wise acc@14 :: {0: [0.546], 1: [0.893], 2: [0.494], 3: [0.516], 4: [0.724], 5: [0.735], 6: [0.727], 7: [0.898], 8: [0.907], 9: [0.834]}
TESTING epoch@14 ::  acc@0.727  loss@0.847
Epoch@@15
TRAINING class wise acc@15 :: {0: [0.7456], 1: [0.838], 2: [0.47], 3: [0.6708], 4: [0.807], 5: [0.7206], 6: [0.8568], 7: [0.857], 8: [0.8964], 9: [0.9024]}
TRAIINING epoch@15 ::  acc@0.793  loss@0.620
TESTING class wise acc@15 :: {0: [0.702], 1: [0.961], 2: [0.342], 3: [0.528], 4: [0.844], 5: [0.81], 6: [0.931], 7: [0.621], 8: [0.827], 9: [0.678]}
TESTING epoch@15 ::  acc@0.724  loss@0.937
Epoch@@16
TRAINING class wise acc@16 :: {0: [0.7904], 1: [0.8732], 2: [0.5576], 3: [0.719], 4: [0.8524], 5: [0.7528], 6: [0.8892], 7: [0.884], 8: [0.9206], 9: [0.9182]}
TRAIINING epoch@16 ::  acc@0.829  loss@0.517
TESTING class wise acc@16 :: {0: [0.656], 1: [0.768], 2: [0.553], 3: [0.587], 4: [0.827], 5: [0.713], 6: [0.819], 7: [0.923], 8: [0.906], 9: [0.857]}
TESTING epoch@16 ::  acc@0.761  loss@0.772
Epoch@@17
TRAINING class wise acc@17 :: {0: [0.8132], 1: [0.8856], 2: [0.6296], 3: [0.7534], 4: [0.87], 5: [0.7826], 6: [0.9022], 7: [0.9092], 8: [0.9284], 9: [0.9314]}
TRAIINING epoch@17 ::  acc@0.852  loss@0.446
TESTING class wise acc@17 :: {0: [0.762], 1: [0.767], 2: [0.428], 3: [0.732], 4: [0.745], 5: [0.656], 6: [0.805], 7: [0.909], 8: [0.886], 9: [0.951]}
TESTING epoch@17 ::  acc@0.764  loss@0.778
Epoch@@18
TRAINING class wise acc@18 :: {0: [0.8484], 1: [0.908], 2: [0.6784], 3: [0.7674], 4: [0.8824], 5: [0.8094], 6: [0.9188], 7: [0.9234], 8: [0.9382], 9: [0.9428]}
TRAIINING epoch@18 ::  acc@0.871  loss@0.398
TESTING class wise acc@18 :: {0: [0.758], 1: [0.899], 2: [0.303], 3: [0.845], 4: [0.813], 5: [0.672], 6: [0.717], 7: [0.789], 8: [0.826], 9: [0.865]}
TESTING epoch@18 ::  acc@0.749  loss@0.860
Epoch@@19
TRAINING class wise acc@19 :: {0: [0.8392], 1: [0.9012], 2: [0.6732], 3: [0.7762], 4: [0.8806], 5: [0.8056], 6: [0.897], 7: [0.9194], 8: [0.935], 9: [0.934]}
TRAIINING epoch@19 ::  acc@0.865  loss@0.409
TESTING class wise acc@19 :: {0: [0.856], 1: [0.641], 2: [0.428], 3: [0.432], 4: [0.913], 5: [0.76], 6: [0.849], 7: [0.792], 8: [0.93], 9: [0.889]}
TESTING epoch@19 ::  acc@0.749  loss@0.907
Epoch@@20
TRAINING class wise acc@20 :: {0: [0.8664], 1: [0.916], 2: [0.7348], 3: [0.8058], 4: [0.907], 5: [0.8338], 6: [0.927], 7: [0.938], 8: [0.9486], 9: [0.9492]}
TRAIINING epoch@20 ::  acc@0.890  loss@0.339
TESTING class wise acc@20 :: {0: [0.792], 1: [0.906], 2: [0.709], 3: [0.643], 4: [0.638], 5: [0.676], 6: [0.809], 7: [0.852], 8: [0.861], 9: [0.821]}
TESTING epoch@20 ::  acc@0.771  loss@0.844
Epoch@@21
TRAINING class wise acc@21 :: {0: [0.828], 1: [0.874], 2: [0.6624], 3: [0.7702], 4: [0.8646], 5: [0.8064], 6: [0.909], 7: [0.9138], 8: [0.925], 9: [0.928]}
TRAIINING epoch@21 ::  acc@0.859  loss@0.440
TESTING class wise acc@21 :: {0: [0.757], 1: [0.812], 2: [0.421], 3: [0.467], 4: [0.871], 5: [0.85], 6: [0.766], 7: [0.793], 8: [0.831], 9: [0.931]}
TESTING epoch@21 ::  acc@0.750  loss@0.942
Epoch@@22
TRAINING class wise acc@22 :: {0: [0.86], 1: [0.896], 2: [0.694], 3: [0.7704], 4: [0.8588], 5: [0.8272], 6: [0.9174], 7: [0.9224], 8: [0.9402], 9: [0.9338]}
TRAIINING epoch@22 ::  acc@0.870  loss@0.409
TESTING class wise acc@22 :: {0: [0.653], 1: [0.839], 2: [0.704], 3: [0.679], 4: [0.717], 5: [0.726], 6: [0.88], 7: [0.566], 8: [0.855], 9: [0.913]}
TESTING epoch@22 ::  acc@0.753  loss@0.972
Epoch@@23
TRAINING class wise acc@23 :: {0: [0.8464], 1: [0.884], 2: [0.7164], 3: [0.7862], 4: [0.889], 5: [0.8196], 6: [0.9088], 7: [0.9138], 8: [0.919], 9: [0.9356]}
TRAIINING epoch@23 ::  acc@0.870  loss@0.413
TESTING class wise acc@23 :: {0: [0.716], 1: [0.78], 2: [0.674], 3: [0.647], 4: [0.775], 5: [0.779], 6: [0.739], 7: [0.828], 8: [0.766], 9: [0.923]}
TESTING epoch@23 ::  acc@0.763  loss@0.910
Epoch@@24
TRAINING class wise acc@24 :: {0: [0.8648], 1: [0.9036], 2: [0.734], 3: [0.8124], 4: [0.9076], 5: [0.8308], 6: [0.929], 7: [0.9246], 8: [0.9346], 9: [0.9454]}
TRAIINING epoch@24 ::  acc@0.887  loss@0.361
TESTING class wise acc@24 :: {0: [0.859], 1: [0.889], 2: [0.546], 3: [0.759], 4: [0.71], 5: [0.622], 6: [0.913], 7: [0.858], 8: [0.82], 9: [0.897]}
TESTING epoch@24 ::  acc@0.787  loss@0.864
Epoch@@25
TRAINING class wise acc@25 :: {0: [0.9072], 1: [0.9256], 2: [0.802], 3: [0.8556], 4: [0.9346], 5: [0.8828], 6: [0.9482], 7: [0.9614], 8: [0.9578], 9: [0.959]}
TRAIINING epoch@25 ::  acc@0.920  loss@0.248
TESTING class wise acc@25 :: {0: [0.772], 1: [0.796], 2: [0.598], 3: [0.638], 4: [0.672], 5: [0.478], 6: [0.877], 7: [0.743], 8: [0.957], 9: [0.923]}
TESTING epoch@25 ::  acc@0.745  loss@1.168
Epoch@@26
TRAINING class wise acc@26 :: {0: [0.92], 1: [0.956], 2: [0.8456], 3: [0.8854], 4: [0.9438], 5: [0.9058], 6: [0.9596], 7: [0.9712], 8: [0.97], 9: [0.9738]}
TRAIINING epoch@26 ::  acc@0.938  loss@0.204
TESTING class wise acc@26 :: {0: [0.762], 1: [0.962], 2: [0.535], 3: [0.592], 4: [0.842], 5: [0.823], 6: [0.897], 7: [0.8], 8: [0.904], 9: [0.82]}
TESTING epoch@26 ::  acc@0.794  loss@0.979
Epoch@@27
TRAINING class wise acc@27 :: {0: [0.93], 1: [0.9492], 2: [0.8568], 3: [0.8914], 4: [0.9538], 5: [0.9088], 6: [0.9588], 7: [0.9666], 8: [0.9668], 9: [0.9694]}
TRAIINING epoch@27 ::  acc@0.939  loss@0.188
TESTING class wise acc@27 :: {0: [0.803], 1: [0.817], 2: [0.62], 3: [0.782], 4: [0.848], 5: [0.678], 6: [0.725], 7: [0.862], 8: [0.881], 9: [0.905]}
TESTING epoch@27 ::  acc@0.792  loss@0.864
Epoch@@28
TRAINING class wise acc@28 :: {0: [0.9412], 1: [0.9628], 2: [0.882], 3: [0.9064], 4: [0.9576], 5: [0.9278], 6: [0.9662], 7: [0.9738], 8: [0.9744], 9: [0.9748]}
TRAIINING epoch@28 ::  acc@0.950  loss@0.163
TESTING class wise acc@28 :: {0: [0.859], 1: [0.805], 2: [0.635], 3: [0.832], 4: [0.792], 5: [0.507], 6: [0.714], 7: [0.743], 8: [0.912], 9: [0.919]}
TESTING epoch@28 ::  acc@0.772  loss@1.067
Epoch@@29
TRAINING class wise acc@29 :: {0: [0.9268], 1: [0.9376], 2: [0.8616], 3: [0.901], 4: [0.9516], 5: [0.9162], 6: [0.9558], 7: [0.9684], 8: [0.9576], 9: [0.966]}
TRAIINING epoch@29 ::  acc@0.939  loss@0.207
TESTING class wise acc@29 :: {0: [0.765], 1: [0.65], 2: [0.56], 3: [0.792], 4: [0.792], 5: [0.739], 6: [0.815], 7: [0.782], 8: [0.738], 9: [0.959]}
TESTING epoch@29 ::  acc@0.759  loss@1.083
Epoch@@30
TRAINING class wise acc@30 :: {0: [0.85], 1: [0.8256], 2: [0.7724], 3: [0.8444], 4: [0.9144], 5: [0.8714], 6: [0.926], 7: [0.9404], 8: [0.929], 9: [0.9314]}
TRAIINING epoch@30 ::  acc@0.892  loss@0.350
TESTING class wise acc@30 :: {0: [0.836], 1: [0.847], 2: [0.519], 3: [0.741], 4: [0.854], 5: [0.644], 6: [0.811], 7: [0.883], 8: [0.874], 9: [0.925]}
TESTING epoch@30 ::  acc@0.793  loss@0.866
Epoch@@31
TRAINING class wise acc@31 :: {0: [0.9008], 1: [0.9192], 2: [0.7984], 3: [0.8462], 4: [0.9222], 5: [0.8644], 6: [0.9102], 7: [0.9472], 8: [0.9566], 9: [0.9538]}
TRAIINING epoch@31 ::  acc@0.907  loss@0.297
TESTING class wise acc@31 :: {0: [0.763], 1: [0.768], 2: [0.695], 3: [0.627], 4: [0.748], 5: [0.797], 6: [0.876], 7: [0.816], 8: [0.802], 9: [0.971]}
TESTING epoch@31 ::  acc@0.786  loss@0.932
Epoch@@32
TRAINING class wise acc@32 :: {0: [0.9408], 1: [0.9432], 2: [0.8936], 3: [0.9132], 4: [0.9612], 5: [0.9326], 6: [0.9592], 7: [0.97], 8: [0.963], 9: [0.97]}
TRAIINING epoch@32 ::  acc@0.948  loss@0.168
TESTING class wise acc@32 :: {0: [0.74], 1: [0.775], 2: [0.651], 3: [0.546], 4: [0.816], 5: [0.839], 6: [0.691], 7: [0.893], 8: [0.911], 9: [0.83]}
TESTING epoch@32 ::  acc@0.769  loss@1.012
Epoch@@33
TRAINING class wise acc@33 :: {0: [0.9424], 1: [0.9624], 2: [0.888], 3: [0.9038], 4: [0.9594], 5: [0.9282], 6: [0.9528], 7: [0.9766], 8: [0.974], 9: [0.9762]}
TRAIINING epoch@33 ::  acc@0.949  loss@0.166
TESTING class wise acc@33 :: {0: [0.781], 1: [0.825], 2: [0.627], 3: [0.834], 4: [0.696], 5: [0.661], 6: [0.798], 7: [0.85], 8: [0.899], 9: [0.747]}
TESTING epoch@33 ::  acc@0.772  loss@1.188
Epoch@@34
TRAINING class wise acc@34 :: {0: [0.8664], 1: [0.884], 2: [0.7828], 3: [0.8288], 4: [0.9098], 5: [0.8632], 6: [0.9196], 7: [0.9324], 8: [0.9386], 9: [0.9264]}
TRAIINING epoch@34 ::  acc@0.892  loss@0.345
TESTING class wise acc@34 :: {0: [0.849], 1: [0.899], 2: [0.659], 3: [0.704], 4: [0.883], 5: [0.686], 6: [0.876], 7: [0.812], 8: [0.876], 9: [0.825]}
TESTING epoch@34 ::  acc@0.807  loss@0.792
Epoch@@35
TRAINING class wise acc@35 :: {0: [0.9632], 1: [0.966], 2: [0.9184], 3: [0.938], 4: [0.9764], 5: [0.9522], 6: [0.9766], 7: [0.9824], 8: [0.982], 9: [0.9762]}
TRAIINING epoch@35 ::  acc@0.966  loss@0.105
TESTING class wise acc@35 :: {0: [0.668], 1: [0.883], 2: [0.618], 3: [0.732], 4: [0.805], 5: [0.713], 6: [0.892], 7: [0.861], 8: [0.918], 9: [0.936]}
TESTING epoch@35 ::  acc@0.803  loss@1.002
Epoch@@36
TRAINING class wise acc@36 :: {0: [0.966], 1: [0.9744], 2: [0.9352], 3: [0.9512], 4: [0.9774], 5: [0.9652], 6: [0.9832], 7: [0.9856], 8: [0.985], 9: [0.9844]}
TRAIINING epoch@36 ::  acc@0.973  loss@0.081
TESTING class wise acc@36 :: {0: [0.831], 1: [0.935], 2: [0.614], 3: [0.739], 4: [0.78], 5: [0.723], 6: [0.907], 7: [0.781], 8: [0.916], 9: [0.849]}
TESTING epoch@36 ::  acc@0.808  loss@1.042
Epoch@@37
TRAINING class wise acc@37 :: {0: [0.9712], 1: [0.9764], 2: [0.9368], 3: [0.9594], 4: [0.9806], 5: [0.9694], 6: [0.9836], 7: [0.9872], 8: [0.9864], 9: [0.985]}
TRAIINING epoch@37 ::  acc@0.976  loss@0.074
TESTING class wise acc@37 :: {0: [0.768], 1: [0.847], 2: [0.52], 3: [0.613], 4: [0.855], 5: [0.847], 6: [0.805], 7: [0.852], 8: [0.907], 9: [0.923]}
TESTING epoch@37 ::  acc@0.794  loss@1.152
Epoch@@38
TRAINING class wise acc@38 :: {0: [0.972], 1: [0.9776], 2: [0.942], 3: [0.9576], 4: [0.9796], 5: [0.9694], 6: [0.9822], 7: [0.9858], 8: [0.9826], 9: [0.9872]}
TRAIINING epoch@38 ::  acc@0.975  loss@0.080
TESTING class wise acc@38 :: {0: [0.767], 1: [0.958], 2: [0.661], 3: [0.562], 4: [0.776], 5: [0.839], 6: [0.905], 7: [0.759], 8: [0.881], 9: [0.718]}
TESTING epoch@38 ::  acc@0.783  loss@1.323
Epoch@@39
TRAINING class wise acc@39 :: {0: [0.9248], 1: [0.9336], 2: [0.8904], 3: [0.9146], 4: [0.9556], 5: [0.9298], 6: [0.9634], 7: [0.9672], 8: [0.9628], 9: [0.9542]}
TRAIINING epoch@39 ::  acc@0.944  loss@0.181
TESTING class wise acc@39 :: {0: [0.702], 1: [0.843], 2: [0.674], 3: [0.771], 4: [0.815], 5: [0.63], 6: [0.882], 7: [0.874], 8: [0.929], 9: [0.92]}
TESTING epoch@39 ::  acc@0.804  loss@0.949
Epoch@@40
TRAINING class wise acc@40 :: {0: [0.972], 1: [0.9804], 2: [0.9472], 3: [0.9664], 4: [0.9804], 5: [0.9684], 6: [0.983], 7: [0.9866], 8: [0.988], 9: [0.989]}
TRAIINING epoch@40 ::  acc@0.978  loss@0.077
TESTING class wise acc@40 :: {0: [0.523], 1: [0.803], 2: [0.559], 3: [0.713], 4: [0.826], 5: [0.757], 6: [0.915], 7: [0.832], 8: [0.875], 9: [0.937]}
TESTING epoch@40 ::  acc@0.774  loss@1.283
Epoch@@41
TRAINING class wise acc@41 :: {0: [0.95], 1: [0.9592], 2: [0.9072], 3: [0.9318], 4: [0.9638], 5: [0.9484], 6: [0.959], 7: [0.9732], 8: [0.9698], 9: [0.9754]}
TRAIINING epoch@41 ::  acc@0.956  loss@0.141
TESTING class wise acc@41 :: {0: [0.788], 1: [0.92], 2: [0.597], 3: [0.596], 4: [0.797], 5: [0.803], 6: [0.872], 7: [0.907], 8: [0.896], 9: [0.885]}
TESTING epoch@41 ::  acc@0.806  loss@1.044
Epoch@@42
TRAINING class wise acc@42 :: {0: [0.9668], 1: [0.9664], 2: [0.9436], 3: [0.9498], 4: [0.9792], 5: [0.9678], 6: [0.982], 7: [0.9828], 8: [0.9812], 9: [0.9804]}
TRAIINING epoch@42 ::  acc@0.972  loss@0.104
TESTING class wise acc@42 :: {0: [0.839], 1: [0.758], 2: [0.673], 3: [0.675], 4: [0.797], 5: [0.798], 6: [0.763], 7: [0.837], 8: [0.87], 9: [0.808]}
TESTING epoch@42 ::  acc@0.782  loss@1.165
Epoch@@43
TRAINING class wise acc@43 :: {0: [0.9356], 1: [0.9496], 2: [0.88], 3: [0.9092], 4: [0.9544], 5: [0.9324], 6: [0.9574], 7: [0.9642], 8: [0.9698], 9: [0.9622]}
TRAIINING epoch@43 ::  acc@0.945  loss@0.183
TESTING class wise acc@43 :: {0: [0.757], 1: [0.848], 2: [0.602], 3: [0.709], 4: [0.825], 5: [0.687], 6: [0.874], 7: [0.902], 8: [0.878], 9: [0.925]}
TESTING epoch@43 ::  acc@0.801  loss@0.979
Epoch@@44
TRAINING class wise acc@44 :: {0: [0.9744], 1: [0.9844], 2: [0.9616], 3: [0.9714], 4: [0.9842], 5: [0.978], 6: [0.9878], 7: [0.9908], 8: [0.9896], 9: [0.9896]}
TRAIINING epoch@44 ::  acc@0.983  loss@0.054
TESTING class wise acc@44 :: {0: [0.761], 1: [0.835], 2: [0.552], 3: [0.772], 4: [0.777], 5: [0.774], 6: [0.836], 7: [0.894], 8: [0.875], 9: [0.925]}
TESTING epoch@44 ::  acc@0.800  loss@1.085
Epoch@@45
TRAINING class wise acc@45 :: {0: [0.9688], 1: [0.9816], 2: [0.9512], 3: [0.9648], 4: [0.9818], 5: [0.9774], 6: [0.9786], 7: [0.988], 8: [0.9872], 9: [0.9876]}
TRAIINING epoch@45 ::  acc@0.978  loss@0.079
TESTING class wise acc@45 :: {0: [0.711], 1: [0.797], 2: [0.541], 3: [0.732], 4: [0.791], 5: [0.792], 6: [0.941], 7: [0.834], 8: [0.877], 9: [0.863]}
TESTING epoch@45 ::  acc@0.788  loss@1.208
Epoch@@46
TRAINING class wise acc@46 :: {0: [0.9684], 1: [0.9572], 2: [0.9456], 3: [0.954], 4: [0.9792], 5: [0.9694], 6: [0.984], 7: [0.9838], 8: [0.9858], 9: [0.9846]}
TRAIINING epoch@46 ::  acc@0.974  loss@0.083
TESTING class wise acc@46 :: {0: [0.81], 1: [0.919], 2: [0.557], 3: [0.755], 4: [0.744], 5: [0.675], 6: [0.918], 7: [0.88], 8: [0.825], 9: [0.904]}
TESTING epoch@46 ::  acc@0.799  loss@1.220
Epoch@@47
TRAINING class wise acc@47 :: {0: [0.9784], 1: [0.986], 2: [0.9592], 3: [0.974], 4: [0.9876], 5: [0.9818], 6: [0.986], 7: [0.9916], 8: [0.9916], 9: [0.9894]}
TRAIINING epoch@47 ::  acc@0.984  loss@0.051
TESTING class wise acc@47 :: {0: [0.889], 1: [0.86], 2: [0.606], 3: [0.68], 4: [0.863], 5: [0.644], 6: [0.88], 7: [0.874], 8: [0.909], 9: [0.896]}
TESTING epoch@47 ::  acc@0.810  loss@1.067
Epoch@@48
TRAINING class wise acc@48 :: {0: [0.9784], 1: [0.9852], 2: [0.9624], 3: [0.9754], 4: [0.9858], 5: [0.98], 6: [0.9892], 7: [0.9914], 8: [0.991], 9: [0.9924]}
TRAIINING epoch@48 ::  acc@0.984  loss@0.067
TESTING class wise acc@48 :: {0: [0.847], 1: [0.853], 2: [0.502], 3: [0.618], 4: [0.93], 5: [0.672], 6: [0.82], 7: [0.858], 8: [0.866], 9: [0.869]}
TESTING epoch@48 ::  acc@0.783  loss@1.183
Epoch@@49
TRAINING class wise acc@49 :: {0: [0.942], 1: [0.9652], 2: [0.9284], 3: [0.9404], 4: [0.966], 5: [0.9562], 6: [0.9704], 7: [0.9754], 8: [0.9712], 9: [0.9666]}
TRAIINING epoch@49 ::  acc@0.960  loss@0.125
TESTING class wise acc@49 :: {0: [0.852], 1: [0.887], 2: [0.508], 3: [0.6], 4: [0.831], 5: [0.857], 6: [0.892], 7: [0.812], 8: [0.884], 9: [0.899]}
TESTING epoch@49 ::  acc@0.802  loss@1.121
