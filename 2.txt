

Fri Jan 15 16:01:52 2021
imbal_test_balance0.5_rand_cifar10_vgg_Adam's set level: 10
imbal_test_balance0.5_rand_cifar10_vgg_Adam logger is ready
imbal_test with imbalance_ratio: [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]
parallel mode is False
initial count: cifar10: [0 1 2 3 4 5 6 7 8 9] class, each has [5000 5000 5000 5000 5000 5000 5000 5000 5000 5000]
cifar10: [0 1 2 3 4 5 6 7 8 9] class, each has [2500 2500 2500 2500 2500 2500 2500 2500 2500 2500]
Epoch@@0
Files already downloaded and verified
TRAINING class wise acc@0 :: {0: [0.0968], 1: [0.2116], 2: [0.086], 3: [0.168], 4: [0.0704], 5: [0.0864], 6: [0.0836], 7: [0.1312], 8: [0.084], 9: [0.0376]}
TRAIINING epoch@0 ::  acc@0.106  loss@2.628
[[242 493 200 371 161 149 194 314 231 145]
 [ 64 529 226 448 212 197 201 286 226 111]
 [ 71 524 215 445 173 237 196 323 205 111]
 [ 42 576 223 420 189 218 192 318 214 108]
 [ 32 546 228 411 176 227 194 349 221 116]
 [ 35 516 246 440 190 216 208 326 205 118]
 [ 16 558 245 439 170 207 209 326 222 108]
 [ 26 554 220 429 189 230 214 328 204 106]
 [142 543 193 385 152 198 231 307 210 139]
 [ 59 570 231 418 203 198 196 330 201  94]]
TESTING class wise acc@0 :: {0: [0.164], 1: [0.0], 2: [0.0], 3: [0.0], 4: [0.0], 5: [0.0], 6: [0.0], 7: [0.0], 8: [0.932], 9: [0.0]}
TESTING epoch@0 ::  acc@0.110  loss@2.288
Epoch@@1
[[164   0   0   0   0   0   0   0 836   0]
 [ 21   0   0   0   0   0   0   0 979   0]
 [ 38   0   0   0   0   0   0   0 962   0]
 [ 11   0   0   0   0   0   0   0 989   0]
 [  7   0   0   0   0   0   0   0 993   0]
 [  9   0   0   0   0   0   0   0 991   0]
 [  1   0   0   0   0   0   0   0 999   0]
 [  8   0   0   0   0   0   0   0 992   0]
 [ 68   0   0   0   0   0   0   0 932   0]
 [ 20   0   0   0   0   0   0   0 980   0]]
TRAINING class wise acc@1 :: {0: [0.1792], 1: [0.016], 2: [0.1012], 3: [0.0876], 4: [0.1796], 5: [0.0908], 6: [0.246], 7: [0.208], 8: [0.0964], 9: [0.024]}
TRAIINING epoch@1 ::  acc@0.123  loss@2.273
[[448  20 212 166 339 180 395 414 272  54]
 [111  40 229 222 445 209 514 527 144  59]
 [133  31 253 243 405 204 550 461 139  81]
 [ 67  25 234 219 402 223 597 546 125  62]
 [ 58  18 213 240 449 238 543 537 138  66]
 [ 54  30 223 236 413 227 590 547 110  70]
 [ 36  31 237 226 421 216 615 550 116  52]
 [ 69  29 237 252 406 237 597 520 106  47]
 [329  30 200 213 384 185 430 426 241  62]
 [110  35 229 239 408 218 525 497 179  60]]
TESTING class wise acc@1 :: {0: [0.504], 1: [0.846], 2: [0.0], 3: [0.0], 4: [0.0], 5: [0.0], 6: [0.0], 7: [0.0], 8: [0.0], 9: [0.0]}
TESTING epoch@1 ::  acc@0.135  loss@2.205
Epoch@@2
[[504 496   0   0   0   0   0   0   0   0]
 [154 846   0   0   0   0   0   0   0   0]
 [111 889   0   0   0   0   0   0   0   0]
 [ 37 963   0   0   0   0   0   0   0   0]
 [ 54 946   0   0   0   0   0   0   0   0]
 [ 35 965   0   0   0   0   0   0   0   0]
 [  9 991   0   0   0   0   0   0   0   0]
 [ 30 970   0   0   0   0   0   0   0   0]
 [450 550   0   0   0   0   0   0   0   0]
 [125 875   0   0   0   0   0   0   0   0]]
TRAINING class wise acc@2 :: {0: [0.218], 1: [0.1648], 2: [0.0232], 3: [0.064], 4: [0.0192], 5: [0.288], 6: [0.4564], 7: [0.1084], 8: [0.3948], 9: [0.1144]}
TRAIINING epoch@2 ::  acc@0.185  loss@2.045
[[ 545  365   75   17   47  151  223   89  776  212]
 [ 342  412   90   13   52  238  393  104  594  262]
 [ 100  111   58  121   67  653  968  187  124  111]
 [  52   61   59  160   57  706 1072  196   54   83]
 [  65   87   49  156   48  714 1057  159   70   95]
 [  35   47   66  149   73  720 1093  214   36   67]
 [  23   49   35  170   68  783 1141  166   16   49]
 [  52  106   96  141   92  628  947  271   60  107]
 [ 572  319   46    7   27  109  193   62  987  178]
 [ 342  376  101   23   60  264  402  145  501  286]]
TESTING class wise acc@2 :: {0: [0.0], 1: [0.24], 2: [0.08], 3: [0.014], 4: [0.0], 5: [0.11], 6: [0.799], 7: [0.0], 8: [0.755], 9: [0.089]}
TESTING epoch@2 ::  acc@0.209  loss@1.961
Epoch@@3
[[  0 196  35   1   0  25  52   0 641  50]
 [  0 240  56   4   0  12  20   0 614  54]
 [  0 102  80  10   0  90 604   0  56  58]
 [  0  82 107  14   0 117 594   0  21  65]
 [  0  63  63   8   0  78 709   0  32  47]
 [  0  60  80   5   0 110 689   0  19  37]
 [  0  28  54   4   0  83 799   0   6  26]
 [  0  82 179  12   0 175 460   0  24  68]
 [  0 162  31   2   0  12  12   0 755  26]
 [  0 294  56   5   0  39  44   0 473  89]]
TRAINING class wise acc@3 :: {0: [0.1324], 1: [0.1992], 2: [0.088], 3: [0.0432], 4: [0.0412], 5: [0.2688], 6: [0.4516], 7: [0.13], 8: [0.452], 9: [0.2568]}
TRAIINING epoch@3 ::  acc@0.206  loss@1.906
[[ 331  424  136    8   23   61   80  154  690  593]
 [ 313  498   71   15    5   17   33   85  853  610]
 [ 117   65  220  102  113  495  908  226   34  220]
 [  67   31  226  108  147  599  958  210   16  138]
 [  75   47  176  106  103  606  994  219   20  154]
 [  51   16  167  134  120  672 1085  162    6   87]
 [  45   19  133  130  120  661 1129  163    6   94]
 [ 108   60  348  110  154  487  714  325   18  176]
 [ 248  507   60    6   11   13   18   79 1130  428]
 [ 404  451  142   21   21   39   59  157  564  642]]
TESTING class wise acc@3 :: {0: [0.0], 1: [0.717], 2: [0.039], 3: [0.81], 4: [0.0], 5: [0.0], 6: [0.0], 7: [0.0], 8: [0.269], 9: [0.061]}
TESTING epoch@3 ::  acc@0.190  loss@1.920
Epoch@@4
[[  0 691  25 105   0   0   0   0 137  42]
 [  0 717  26  48   0   0   0   0 168  41]
 [  0 141  39 747   0   0   0   0   0  73]
 [  0  93  44 810   0   0   0   0   0  53]
 [  0  86  18 852   0   0   0   0   2  42]
 [  0  56  31 878   0   0   0   0   0  35]
 [  0  33  18 926   0   0   0   0   0  23]
 [  0 105  53 773   0   0   0   0   1  68]
 [  0 653  14  36   0   0   0   0 269  28]
 [  0 729  39 102   0   0   0   0  69  61]]
TRAINING class wise acc@4 :: {0: [0.1788], 1: [0.234], 2: [0.104], 3: [0.0652], 4: [0.0284], 5: [0.3456], 6: [0.3344], 7: [0.1672], 8: [0.4344], 9: [0.2152]}
TRAIINING epoch@4 ::  acc@0.211  loss@1.876
[[ 447  470  152   33   25   32   52  175  630  484]
 [ 363  585   76   18    5    8   15   86  945  399]
 [ 132   55  260  167   78  658  614  316   31  189]
 [  77   23  251  163   78  775  723  279    7  124]
 [  95   38  199  148   71  779  760  263   16  131]
 [  53    9  188  166   61  864  840  242    3   74]
 [  42   19  160  169   65  910  836  211    7   81]
 [ 113   29  358  226  135  497  549  418    7  168]
 [ 302  603   59   12    9    9   10   78 1086  332]
 [ 476  521  130   25   25   31   28  154  572  538]]
TESTING class wise acc@4 :: {0: [0.501], 1: [0.331], 2: [0.0], 3: [0.0], 4: [0.0], 5: [0.717], 6: [0.0], 7: [0.319], 8: [0.372], 9: [0.0]}
TESTING epoch@4 ::  acc@0.224  loss@1.855
Epoch@@5
[[501 201   0   0   0  31   0  96 171   0]
 [322 331   0   0   0  12   0  48 287   0]
 [172  18   0   0   0 587   0 221   2   0]
 [105   6   0   0   0 665   0 222   2   0]
 [114  11   0   0   0 716   0 156   3   0]
 [ 91   3   0   0   0 717   0 189   0   0]
 [ 51   2   0   0   0 805   0 142   0   0]
 [136   8   0   0   0 536   0 319   1   0]
 [290 290   0   0   0  13   0  35 372   0]
 [483 264   0   0   0  22   0 105 126   0]]
TRAINING class wise acc@5 :: {0: [0.2012], 1: [0.2548], 2: [0.1108], 3: [0.1208], 4: [0.0616], 5: [0.1232], 6: [0.4912], 7: [0.1908], 8: [0.3796], 9: [0.2416]}
TRAIINING epoch@5 ::  acc@0.218  loss@1.852
[[ 503  432  142   39   39   14   49  193  528  561]
 [ 392  637   59    9    5    6   11   73  848  460]
 [ 154   24  277  230  184  238  855  345   24  169]
 [  95    9  261  302  174  283  990  278    7  101]
 [ 136   11  234  267  154  282 1034  261   12  109]
 [  62    4  197  303  135  308 1192  242    3   54]
 [  48    9  185  304  137  355 1228  180    2   52]
 [ 137   20  409  253  227  235  597  477    8  137]
 [ 322  680   64    3   16    5   13   70  949  378]
 [ 545  508  128   19   18    9   17  172  480  604]]
TESTING class wise acc@5 :: {0: [0.0], 1: [0.873], 2: [0.403], 3: [0.0], 4: [0.0], 5: [0.386], 6: [0.0], 7: [0.0], 8: [0.016], 9: [0.141]}
TESTING epoch@5 ::  acc@0.182  loss@1.945
Epoch@@6
[[  0 665 113   0   0   5   0   0   1 216]
 [  0 873  23   0   0   2   0   0   8  94]
 [  0  64 403   0   0 367   0   0   0 166]
 [  0  54 470   0   0 315   0   0   0 161]
 [  0  45 382   0   0 446   0   0   0 127]
 [  0  26 478   0   0 386   0   0   0 110]
 [  0  20 407   0   0 484   0   0   0  89]
 [  0  89 509   0   0 138   0   0   0 264]
 [  0 867  21   0   0   2   0   0  16  94]
 [  0 820  35   0   0   4   0   0   0 141]]
TRAINING class wise acc@6 :: {0: [0.2736], 1: [0.314], 2: [0.1152], 3: [0.0332], 4: [0.0512], 5: [0.214], 6: [0.5388], 7: [0.2168], 8: [0.3188], 9: [0.2216]}
TRAIINING epoch@6 ::  acc@0.230  loss@1.828
[[ 684  388  152   15   23   34   23  243  396  542]
 [ 420  785   42    4    5    6   11   81  736  410]
 [ 236   17  288   79  167  391  801  391   12  118]
 [ 123    2  258   83  156  494  977  337    5   65]
 [ 149    9  241   55  128  483 1023  327    9   76]
 [  73    2  250   85  144  535 1086  281    1   43]
 [  54    4  159   51  111  550 1347  181    1   42]
 [ 187    6  409  121  196  393  523  542    4  119]
 [ 406  774   39    4    3    8    9   90  797  370]
 [ 616  600   95    6   11   16   14  159  429  554]]
TESTING class wise acc@6 :: {0: [0.32], 1: [0.862], 2: [0.17], 3: [0.355], 4: [0.0], 5: [0.0], 6: [0.61], 7: [0.0], 8: [0.002], 9: [0.0]}
TESTING epoch@6 ::  acc@0.232  loss@1.822
Epoch@@7
[[320 577  62  37   0   0   4   0   0   0]
 [102 862  20  10   0   0   0   0   6   0]
 [153  38 170 354   0   0 285   0   0   0]
 [111  27 119 355   0   0 388   0   0   0]
 [ 98  19 109 357   0   0 417   0   0   0]
 [ 68   6 109 360   0   0 457   0   0   0]
 [ 56   8  66 260   0   0 610   0   0   0]
 [154  33 219 442   0   0 152   0   0   0]
 [121 840  24  12   0   0   1   0   2   0]
 [163 782  36  19   0   0   0   0   0   0]]
TRAINING class wise acc@7 :: {0: [0.4264], 1: [0.5064], 2: [0.1152], 3: [0.112], 4: [0.0656], 5: [0.1208], 6: [0.6828], 7: [0.2024], 8: [0.1696], 9: [0.2216]}
TRAIINING epoch@7 ::  acc@0.262  loss@1.779
[[1066  272  125   41   27   12   26  225  227  479]
 [ 315 1266   28    8    6    4    7   54  409  403]
 [ 283   11  288  283  188  230  756  418    8   35]
 [ 154    1  244  280  178  276 1031  307    5   24]
 [ 187    6  240  268  164  250 1042  317    8   18]
 [  80    5  204  292  169  302 1174  261    2   11]
 [  62    1  124  138  108  180 1707  169    1   10]
 [ 284    6  383  299  203  232  546  506   13   28]
 [ 599  751   36   11    8    8    8   85  424  570]
 [ 559  839   64   19    7   11   10  103  334  554]]
TESTING class wise acc@7 :: {0: [0.299], 1: [0.788], 2: [0.0], 3: [0.0], 4: [0.133], 5: [0.0], 6: [0.595], 7: [0.375], 8: [0.046], 9: [0.305]}
TESTING epoch@7 ::  acc@0.254  loss@1.944
Epoch@@8
[[299  51   0   0   4   0   2  69  72 503]
 [ 11 788   0   0   2   0   1   6   7 185]
 [188   4   0   0 110   0 226 408  11  53]
 [154  10   0   0 100   0 261 389  17  69]
 [150   3   0   0 133   0 319 338  18  39]
 [131   1   0   0 155   0 221 443   9  40]
 [ 72   1   0   0  77   0 595 209   5  41]
 [315   5   0   0  63   0  73 375  33 136]
 [118 203   0   0   0   0   1  13  46 619]
 [ 35 630   0   0   0   0   1  21   8 305]]
TRAINING class wise acc@8 :: {0: [0.5104], 1: [0.5296], 2: [0.1516], 3: [0.082], 4: [0.0968], 5: [0.098], 6: [0.7232], 7: [0.2124], 8: [0.272], 9: [0.3]}
TRAIINING epoch@8 ::  acc@0.298  loss@1.716
[[1276   83  138   20   32   19   30  222  488  192]
 [ 195 1324   14    5    5    1    7   31  228  690]
 [ 315    1  379  223  205  202  711  423   33    8]
 [ 157    0  334  205  274  199  969  338   23    1]
 [ 179    1  334  254  242  192  927  345   16   10]
 [  94    1  354  249  252  245  980  317    7    1]
 [  52    1  135  137  115  115 1808  120    9    8]
 [ 353    3  465  219  220  226  435  531   36   12]
 [ 922  243   47   16   12    6    4  116  680  454]
 [ 383  892   41    7    7    9    8   67  336  750]]
TESTING class wise acc@8 :: {0: [0.488], 1: [0.058], 2: [0.056], 3: [0.0], 4: [0.0], 5: [0.52], 6: [0.91], 7: [0.099], 8: [0.24], 9: [0.347]}
TESTING epoch@8 ::  acc@0.272  loss@1.875
Epoch@@9
[[488   0  52   0   0  89  39 160 162  10]
 [109  58  16   0   0  36  20  37 245 479]
 [ 57   0  56   0   0 398 410  79   0   0]
 [ 24   0  55   0   0 369 497  54   1   0]
 [ 30   0  34   0   0 311 577  44   4   0]
 [ 17   0  32   0   0 520 399  32   0   0]
 [  2   0   3   0   0  81 910   3   1   0]
 [ 42   0  76   0   0 423 354  99   6   0]
 [507   0  31   0   0  64  33 105 240  20]
 [175  19  18   0   0  62  38  56 285 347]]
TRAINING class wise acc@9 :: {0: [0.412], 1: [0.5388], 2: [0.1324], 3: [0.1076], 4: [0.1176], 5: [0.2064], 6: [0.7316], 7: [0.2436], 8: [0.4252], 9: [0.3244]}
TRAIINING epoch@9 ::  acc@0.324  loss@1.653
[[1030   29   96   28   17   45   16  274  848  117]
 [ 110 1347   11    2    9   14    4   18  283  702]
 [ 235    1  331  216  261  395  517  470   70    4]
 [ 120    0  317  269  318  444  622  372   36    2]
 [ 137    0  277  223  294  422  730  372   42    3]
 [  86    0  347  354  388  516  431  353   24    1]
 [  35    0  103   99  136  181 1829  100   16    1]
 [ 272    1  455  204  282  409  193  609   71    4]
 [ 840   76   34    7    4   21    9  124 1063  322]
 [ 266  853   23    2    6   15    5   77  442  811]]
TESTING class wise acc@9 :: {0: [0.355], 1: [0.392], 2: [0.0], 3: [0.0], 4: [0.8], 5: [0.0], 6: [0.305], 7: [0.319], 8: [0.467], 9: [0.343]}
TESTING epoch@9 ::  acc@0.298  loss@1.720
Epoch@@10
[[355   0   0   0  60   0   0 395 179  11]
 [ 55 392   0   0   8   0   0  34 183 328]
 [ 42   0   0   0 638   0  13 304   3   0]
 [ 29   0   0   0 791   0  14 153  13   0]
 [ 21   0   0   0 800   0  15 156   8   0]
 [ 15   0   0   0 861   0   4 115   4   1]
 [  6   0   0   0 625   0 305  61   3   0]
 [ 37   0   0   0 635   0   1 319   7   1]
 [325   3   0   0  20   0   0 133 467  52]
 [ 96 190   0   0  19   0   0  71 281 343]]
TRAINING class wise acc@10 :: {0: [0.4292], 1: [0.5852], 2: [0.1204], 3: [0.1988], 4: [0.1364], 5: [0.2284], 6: [0.7484], 7: [0.1928], 8: [0.4304], 9: [0.344]}
TRAIINING epoch@10 ::  acc@0.341  loss@1.610
[[1073   19   89   49   19   63   17  234  835  102]
 [ 102 1463   11   11    3   11    7   22  190  680]
 [ 253    0  301  406  301  433  381  357   65    3]
 [ 116    0  264  497  335  510  482  267   27    2]
 [ 114    1  288  439  341  487  532  269   29    0]
 [  64    0  320  556  421  571  295  259   14    0]
 [  35    1   64  155  137  162 1871   67    7    1]
 [ 269    0  392  430  279  489  105  482   51    3]
 [ 899   63   20   19   10   22    9  108 1076  274]
 [ 287  848   15   16   10   19    2   53  390  860]]
TESTING class wise acc@10 :: {0: [0.022], 1: [0.473], 2: [0.0], 3: [0.0], 4: [0.597], 5: [0.0], 6: [0.522], 7: [0.578], 8: [0.938], 9: [0.315]}
TESTING epoch@10 ::  acc@0.345  loss@1.667
Epoch@@11
[[ 22   0   0   0  16   0   1 103 856   2]
 [  1 473   0   0   1   0   0   6 256 263]
 [ 32   0   0   0 427   0  33 355 153   0]
 [ 18   0   0   0 479   0  43 360  99   1]
 [ 16   0   0   0 597   0  35 273  79   0]
 [ 18   0   0   0 556   0   6 372  47   1]
 [  6   0   0   0 354   0 522  89  29   0]
 [ 51   0   0   0 196   0   1 578 174   0]
 [ 11   0   0   0   8   0   1  33 938   9]
 [  5 175   0   0   3   0   0  14 488 315]]
TRAINING class wise acc@11 :: {0: [0.4632], 1: [0.6436], 2: [0.1532], 3: [0.1664], 4: [0.1728], 5: [0.1304], 6: [0.7836], 7: [0.246], 8: [0.4252], 9: [0.3832]}
TRAIINING epoch@11 ::  acc@0.357  loss@1.574
[[1158   11   95   53   22   25    9  251  775  101]
 [  88 1609   10    5    6    1    9   22  154  596]
 [ 234    1  383  435  369  261  361  395   56    5]
 [ 107    0  388  416  440  287  496  334   28    4]
 [ 115    0  365  491  432  303  452  319   22    1]
 [  63    0  436  500  498  326  307  355   12    3]
 [  35    0   78  152  141   56 1959   69    9    1]
 [ 233    1  583  371  286  255  110  615   43    3]
 [ 941   28   29   13    8   14   12   82 1063  310]
 [ 237  764   25    9    5   14    7   51  430  958]]
TESTING class wise acc@11 :: {0: [0.473], 1: [0.392], 2: [0.054], 3: [0.0], 4: [0.0], 5: [0.657], 6: [0.866], 7: [0.203], 8: [0.618], 9: [0.638]}
TESTING epoch@11 ::  acc@0.390  loss@1.563
Epoch@@12
[[473   0  10   0   0  27  10  56 398  26]
 [ 23 392   2   0   0   4   1   8  53 517]
 [174   0  54   0   0 449 197 115   8   3]
 [104   0  63   0   0 486 228 101  12   6]
 [ 80   0  54   0   0 514 255  90   5   2]
 [ 68   0  56   0   0 657 132  82   5   0]
 [  8   0  17   0   0  86 866  21   2   0]
 [154   0 111   0   0 440  75 203  17   0]
 [228   0   3   0   0  15   4  14 618 118]
 [ 82  95   3   0   0  11   9  10 152 638]]
TRAINING class wise acc@12 :: {0: [0.4292], 1: [0.6704], 2: [0.1484], 3: [0.1816], 4: [0.1676], 5: [0.2088], 6: [0.7988], 7: [0.3472], 8: [0.486], 9: [0.4232]}
TRAIINING epoch@12 ::  acc@0.386  loss@1.526
[[1073    1   87   29   40   25    4  268  887   86]
 [  71 1676    7    2    2    2    5   20  109  606]
 [ 237    0  371  350  355  377  317  447   43    3]
 [  89    0  275  454  405  454  487  307   25    4]
 [ 102    0  370  414  419  431  339  411   14    0]
 [  37    0  347  560  474  522  257  296    7    0]
 [  26    1   51  114  128  122 1997   53    7    1]
 [ 204    0  506  272  310  251   51  868   35    3]
 [ 824   22   28   11    8    8    6   93 1215  285]
 [ 238  696   22    4    3    7    6   62  404 1058]]
TESTING class wise acc@12 :: {0: [0.546], 1: [0.435], 2: [0.0], 3: [0.0], 4: [0.0], 5: [0.037], 6: [0.07], 7: [0.09], 8: [0.616], 9: [0.46]}
TESTING epoch@12 ::  acc@0.225  loss@2.333
Epoch@@13
[[546   0   0   0   0   0   0   6 428  20]
 [ 69 435   0   0   0   0   0   0 171 325]
 [607   0   0   0   0  42   0 332  17   2]
 [518   0   0   0   0  48   0 401  28   5]
 [568   0   0   0   0  31   0 394   6   1]
 [493   0   0   0   0  37   0 453  17   0]
 [263   0   0   0   0 263  70 384  16   4]
 [890   0   0   0   0   3   0  90  17   0]
 [229   8   0   0   0   0   0   2 616 145]
 [120 153   0   0   0   0   0   0 267 460]]
TRAINING class wise acc@13 :: {0: [0.4436], 1: [0.686], 2: [0.148], 3: [0.2364], 4: [0.2124], 5: [0.164], 6: [0.8092], 7: [0.3372], 8: [0.4984], 9: [0.4772]}
TRAIINING epoch@13 ::  acc@0.401  loss@1.486
[[1109    8   76   27   51   29    9  290  818   83]
 [  74 1715    5    3    1    1    8   15  109  569]
 [ 213    0  370  416  429  316  254  462   38    2]
 [  75    0  286  591  445  384  498  204   16    1]
 [ 100    0  392  538  531  317  262  353    7    0]
 [  48    0  334  649  566  410  286  201    5    1]
 [  16    0   43  161  110   94 2023   48    5    0]
 [ 230    0  514  248  427  179   34  843   19    6]
 [ 787   28   21    7   13    8    9  103 1246  278]
 [ 176  626   19    4   14    8    1   52  407 1193]]
TESTING class wise acc@13 :: {0: [0.747], 1: [0.298], 2: [0.0], 3: [0.022], 4: [0.0], 5: [0.0], 6: [0.03], 7: [0.212], 8: [0.454], 9: [0.674]}
TESTING epoch@13 ::  acc@0.244  loss@3.262
Epoch@@14
[[747   0   0   0   0   0   0  26 205  22]
 [ 34 298   0   0   0   0   0   1  95 572]
 [527   0   0  33   0   0   0 359  55  26]
 [524   0   0  22   0   0   2 255 130  67]
 [475   0   0   7   0   0   0 452  47  19]
 [464   0   0  39   0   0   0 387  72  38]
 [450   0   0  51   0   0  30 313 110  46]
 [684   0   0   3   0   0   0 212  81  20]
 [436   1   0   0   0   0   0   3 454 106]
 [ 70  14   0   0   0   0   0   1 241 674]]
TRAINING class wise acc@14 :: {0: [0.4536], 1: [0.7144], 2: [0.13], 3: [0.274], 4: [0.1916], 5: [0.1792], 6: [0.8088], 7: [0.4176], 8: [0.5184], 9: [0.518]}
TRAIINING epoch@14 ::  acc@0.421  loss@1.462
[[1134    1   62   30   58   25    4  296  834   56]
 [  61 1786    3    4    3    1    4   14   92  532]
 [ 215    0  325  505  409  319  228  459   37    3]
 [  76    0  255  685  320  446  450  253   14    1]
 [  91    0  391  503  479  354  215  448   19    0]
 [  26    0  317  799  423  448  263  217    7    0]
 [  18    0   34  210   61  114 2022   35    5    1]
 [ 230    0  450  205  360  154   25 1044   29    3]
 [ 742   19   21   15   12    5    6   91 1296  293]
 [ 171  538   12   13    8    6    3   47  407 1295]]
TESTING class wise acc@14 :: {0: [0.38], 1: [0.726], 2: [0.0], 3: [0.0], 4: [0.211], 5: [0.493], 6: [0.931], 7: [0.561], 8: [0.62], 9: [0.618]}
TESTING epoch@14 ::  acc@0.454  loss@1.520
Epoch@@15
[[380   0   0   0  33  19  12 134 393  29]
 [ 15 726   0   0   5   5   6   9  46 188]
 [ 81   0   0   0 174 297 186 255   6   1]
 [ 13   1   0   0 106 374 412  87   4   3]
 [ 20   0   0   0 211 310 212 237  10   0]
 [  8   0   0   0 114 493 314  71   0   0]
 [  3   0   0   0   6  50 931  10   0   0]
 [ 28   0   0   0 165 163  73 561   9   1]
 [152   4   0   0  19  12  16  65 620 112]
 [ 35 158   0   0   8  14  19  31 117 618]]
TRAINING class wise acc@15 :: {0: [0.45], 1: [0.7084], 2: [0.156], 3: [0.1792], 4: [0.1604], 5: [0.3676], 6: [0.806], 7: [0.4492], 8: [0.5312], 9: [0.5892]}
TRAIINING epoch@15 ::  acc@0.440  loss@1.440
[[1125    5   74   18   65   27   10  314  795   67]
 [  47 1771    5    2    7    2    8   30   87  541]
 [ 195    0  390  270  372  511  198  536   26    2]
 [  67    0  239  448  263  799  499  172   13    0]
 [  82    0  481  270  401  511  172  570   13    0]
 [  23    0  246  526  272  919  302  205    7    0]
 [  21    0   25  136   46  207 2015   46    4    0]
 [ 220    0  466  129  311  208   17 1123   20    6]
 [ 722    7   19    7   15   12    9   87 1328  294]
 [ 121  451   17    6   11    6    2   47  366 1473]]
TESTING class wise acc@15 :: {0: [0.268], 1: [0.665], 2: [0.0], 3: [0.553], 4: [0.119], 5: [0.0], 6: [0.62], 7: [0.806], 8: [0.701], 9: [0.73]}
TESTING epoch@15 ::  acc@0.446  loss@1.490
Epoch@@16
[[268   0   0  19   9   0   1 141 526  36]
 [  6 665   0   3   1   0   0  11  49 265]
 [ 80   0   0 246 129   0  13 514  18   0]
 [ 35   0   0 553 117   0  48 228  16   3]
 [ 39   0   0 187 119   0  11 632   9   3]
 [ 22   0   0 537 164   0  12 260   3   2]
 [  7   0   0 305  21   0 620  43   3   1]
 [ 67   0   0  56  56   0   2 806  10   3]
 [130   1   0   9   7   0   3  54 701  95]
 [ 31 109   0   5   3   0   2  16 104 730]]
TRAINING class wise acc@16 :: {0: [0.4888], 1: [0.7188], 2: [0.1208], 3: [0.3116], 4: [0.2004], 5: [0.286], 6: [0.8124], 7: [0.492], 8: [0.534], 9: [0.6148]}
TRAIINING epoch@16 ::  acc@0.458  loss@1.410
[[1222    3   53   25   55   23    7  328  735   49]
 [  52 1797    6    2    6    3    1   15   83  535]
 [ 196    0  302  418  419  408  174  562   20    1]
 [  58    0  141  779  230  623  447  213    7    2]
 [  87    0  367  384  501  408  124  622    7    0]
 [  38    0  154  862  309  715  242  169   10    1]
 [  18    0   28  225   26  145 2031   24    2    1]
 [ 196    1  374  144  364  144   26 1230   18    3]
 [ 758   15   10    7   22   12    5   91 1335  245]
 [ 143  415   10    5   13    7    2   33  335 1537]]
TESTING class wise acc@16 :: {0: [0.198], 1: [0.563], 2: [0.006], 3: [0.497], 4: [0.242], 5: [0.0], 6: [0.924], 7: [0.0], 8: [0.548], 9: [0.303]}
TESTING epoch@16 ::  acc@0.328  loss@2.064
Epoch@@17
[[198   3   7  82 201   0  27   0 468  14]
 [ 19 563   4  46  63   0  55   0  72 178]
 [ 42   0   6 451 296   0 184   0  21   0]
 [  4   0   1 497  56   0 438   0   4   0]
 [  6   0   2 487 242   0 263   0   0   0]
 [  0   0   0 614  59   0 327   0   0   0]
 [  1   0   0  64  11   0 924   0   0   0]
 [  4   0   2 358 546   0  88   0   2   0]
 [111   5   8  72 168   0  42   0 548  46]
 [ 70  98   6 106 120   0 125   0 172 303]]
TRAINING class wise acc@17 :: {0: [0.4956], 1: [0.7624], 2: [0.1672], 3: [0.3268], 4: [0.2344], 5: [0.2652], 6: [0.8348], 7: [0.4784], 8: [0.5672], 9: [0.6476]}
TRAIINING epoch@17 ::  acc@0.478  loss@1.358
[[1239    2   58   21   68   13    3  301  730   65]
 [  45 1906    5    4    4    4    3   14   67  448]
 [ 161    0  418  405  482  344  155  509   25    1]
 [  43    0  195  817  266  628  405  136    9    1]
 [  70    0  422  357  586  343  123  591    7    1]
 [  19    0  187  976  285  663  234  131    4    1]
 [   4    0   23  192   34  131 2087   25    4    0]
 [ 214    0  350  139  445  118   17 1196   20    1]
 [ 677   10   16    5   19    8    7   92 1418  248]
 [ 116  377    5    3   13    3    2   41  321 1619]]
TESTING class wise acc@17 :: {0: [0.741], 1: [0.401], 2: [0.202], 3: [0.282], 4: [0.0], 5: [0.195], 6: [0.623], 7: [0.796], 8: [0.582], 9: [0.262]}
TESTING epoch@17 ::  acc@0.408  loss@1.709
Epoch@@18
[[741   0  11   3   0   5   2 102 136   0]
 [ 88 401   2   0   0   1   1  23 219 265]
 [136   0 202  97   0  89  22 450   3   1]
 [ 48   0 187 282   0 161  64 254   4   0]
 [ 46   0 258 115   0 107  33 437   4   0]
 [ 28   0 239 316   0 195  27 192   3   0]
 [ 18   0  69 161   0  46 623  81   2   0]
 [ 58   0  90  20   0  30   5 796   1   0]
 [348   0   8   2   0   4   2  49 582   5]
 [161  33   2   2   0   2   1  47 490 262]]
TRAINING class wise acc@18 :: {0: [0.4756], 1: [0.754], 2: [0.108], 3: [0.2992], 4: [0.198], 5: [0.3648], 6: [0.8144], 7: [0.5524], 8: [0.562], 9: [0.6784]}
TRAIINING epoch@18 ::  acc@0.481  loss@1.363
[[1189    3   45   16   59   20    2  339  783   44]
 [  38 1885    5    3    1    5    1   17   78  467]
 [ 154    0  270  372  511  446  147  571   26    3]
 [  50    0   83  748  266  814  352  178    7    2]
 [  70    0  340  367  495  445  110  662   11    0]
 [  17    0  105  844  241  912  212  167    2    0]
 [  14    0   14  184   33  177 2036   36    5    1]
 [ 181    0  262  148  309  191    7 1381   19    2]
 [ 689   11   17   12   21    3    1   86 1405  255]
 [ 109  292    5    2   11    7    1   45  332 1696]]
TESTING class wise acc@18 :: {0: [0.415], 1: [0.656], 2: [0.388], 3: [0.451], 4: [0.0], 5: [0.0], 6: [0.526], 7: [0.649], 8: [0.769], 9: [0.817]}
TESTING epoch@18 ::  acc@0.467  loss@1.573
Epoch@@19
[[415   0  33   2   0   0   0  90 428  32]
 [ 11 656   3   0   0   0   0   5  35 290]
 [109   0 388 146   0   0  12 313  31   1]
 [ 39   0 349 451   0   0  24 104  23  10]
 [ 40   0 464 136   0   0  13 332  13   2]
 [ 25   0 304 578   0   0   4  75  12   2]
 [ 15   0 142 276   0   0 526  26   8   7]
 [113   0 162  46   0   0   0 649  27   3]
 [ 99   5  11   4   0   0   2  25 769  85]
 [ 18  45   4   0   0   0   0   6 110 817]]
TRAINING class wise acc@19 :: {0: [0.4816], 1: [0.7824], 2: [0.18], 3: [0.3652], 4: [0.2156], 5: [0.3056], 6: [0.8392], 7: [0.5228], 8: [0.6032], 9: [0.7336]}
TRAIINING epoch@19 ::  acc@0.503  loss@1.308
[[1204    5   72    7   62   20    2  303  786   39]
 [  29 1956    3    2    1    6    4   11   79  409]
 [ 168    0  450  443  505  309  121  479   25    0]
 [  35    0  200  913  195  683  340  122   12    0]
 [  71    0  508  387  539  267   91  629    8    0]
 [  22    0  199 1027  196  764  168  121    2    1]
 [   5    0   38  162   22  162 2098   10    2    1]
 [ 153    0  369  146  367  131    7 1307   18    2]
 [ 639    3   20    6   14    9    2   66 1508  233]
 [  97  257   15    4    4    6    0   30  253 1834]]
TESTING class wise acc@19 :: {0: [0.741], 1: [0.53], 2: [0.0], 3: [0.022], 4: [0.324], 5: [0.782], 6: [0.656], 7: [0.608], 8: [0.02], 9: [0.539]}
TESTING epoch@19 ::  acc@0.422  loss@1.665
Epoch@@20
[[741   0   0   1  73  25   2 138   4  16]
 [ 84 530   0   0  42  35   1  31  14 263]
 [ 81   0   0  11 322 288  28 270   0   0]
 [ 16   0   0  22 162 714  36  48   0   2]
 [ 21   0   0   5 324 230  21 399   0   0]
 [  6   0   0   6 156 782   7  43   0   0]
 [  3   0   0  36  49 243 656  13   0   0]
 [ 13   0   0   0 220 157   2 608   0   0]
 [826   1   0   1  33  19   1  51  20  48]
 [222  36   0   1  68  51   0  60  23 539]]
TRAINING class wise acc@20 :: {0: [0.5248], 1: [0.7888], 2: [0.1976], 3: [0.3048], 4: [0.1984], 5: [0.364], 6: [0.8396], 7: [0.5368], 8: [0.576], 9: [0.7372]}
TRAIINING epoch@20 ::  acc@0.507  loss@1.279
[[1312    0   71   10   55   17    2  275  705   53]
 [  22 1972    1    2    3    3    2   14   60  421]
 [ 156    0  494  297  486  416  115  513   20    3]
 [  34    0  195  762  202  853  339  110    5    0]
 [  59    0  576  266  496  368   78  650    5    2]
 [  15    0  212  858  189  910  189  126    1    0]
 [   6    0   25  169   22  164 2099   14    1    0]
 [ 118    0  458  106  280  163   16 1342   13    4]
 [ 725    6   12    3   21    5    4   65 1440  219]
 [  83  259    6    2    9    4    0   24  270 1843]]
TESTING class wise acc@20 :: {0: [0.553], 1: [0.723], 2: [0.351], 3: [0.0], 4: [0.0], 5: [0.928], 6: [0.669], 7: [0.287], 8: [0.479], 9: [0.652]}
TESTING epoch@20 ::  acc@0.464  loss@1.482
Epoch@@21
[[553   0 138   0   0  37   1 166  92  13]
 [ 21 723  15   0   0  20   1  11  39 170]
 [ 24   0 351   0   0 540  19  66   0   0]
 [  3   0  73   0   0 885  24  13   1   1]
 [  6   0 372   0   0 546  19  56   1   0]
 [  0   0  52   0   0 928   8  12   0   0]
 [  1   0  18   0   0 312 669   0   0   0]
 [  3   0 428   0   0 280   2 287   0   0]
 [342   6  51   0   0  37   0  35 479  50]
 [ 61  53  41   0   0  49   0  26 118 652]]
TRAINING class wise acc@21 :: {0: [0.5392], 1: [0.8132], 2: [0.1632], 3: [0.376], 4: [0.2528], 5: [0.3188], 6: [0.8444], 7: [0.5372], 8: [0.652], 9: [0.7816]}
TRAIINING epoch@21 ::  acc@0.528  loss@1.228
[[1348    0   40   15   69   15    2  294  684   33]
 [  24 2033    2    4    1    1    1    5   44  385]
 [ 146    0  408  355  566  340  107  566   11    1]
 [  23    0  141  940  209  771  301  112    3    0]
 [  62    0  457  301  632  265   63  716    4    0]
 [  14    0  154 1033  200  797  194  107    1    0]
 [   2    0   19  188   23  149 2111    7    1    0]
 [ 125    0  260  141  494  111   11 1343   14    1]
 [ 579    9    7    6   15    6    4   64 1630  180]
 [  73  188    4    5    6    2    1   26  241 1954]]
TESTING class wise acc@21 :: {0: [0.844], 1: [0.73], 2: [0.353], 3: [0.58], 4: [0.0], 5: [0.0], 6: [0.711], 7: [0.73], 8: [0.366], 9: [0.519]}
TESTING epoch@21 ::  acc@0.483  loss@1.558
Epoch@@22
[[844   0  19   7   0   0   1  79  44   6]
 [ 41 730   7   8   0   0   1   5  37 171]
 [136   0 353 218   0   0  29 262   1   1]
 [ 64   0 195 580   0   0  56  94   5   6]
 [ 52   0 379 200   0   0  39 326   2   2]
 [ 35   0 206 637   0   0  20  99   2   1]
 [ 19   0  45 202   0   0 711  21   1   1]
 [ 75   0 136  56   0   0   2 730   1   0]
 [550   2   7   8   0   0   0  23 366  44]
 [183  91  19  10   0   0   1  35 142 519]]
TRAINING class wise acc@22 :: {0: [0.5216], 1: [0.7916], 2: [0.1808], 3: [0.3292], 4: [0.2344], 5: [0.4176], 6: [0.8444], 7: [0.5592], 8: [0.6816], 9: [0.752]}
TRAIINING epoch@22 ::  acc@0.531  loss@1.270
[[1304    1   50   17   70   11    4  310  704   29]
 [  24 1979    3    2    5    5    1   13   67  401]
 [ 145    0  452  350  526  328   92  587   19    1]
 [  30    0  146  823  211  925  243  112   10    0]
 [  63    0  485  317  586  289   66  686    7    1]
 [  11    0  139  884  189 1044  135   95    3    0]
 [   3    0   22  142   19  186 2111   14    2    1]
 [ 162    0  256  132  407  124    4 1398   13    4]
 [ 504    6   17    7   11   14    4   62 1704  171]
 [  70  216   15    2    7   16    1   32  261 1880]]
TESTING class wise acc@22 :: {0: [0.544], 1: [0.86], 2: [0.373], 3: [0.604], 4: [0.0], 5: [0.063], 6: [0.822], 7: [0.313], 8: [0.743], 9: [0.799]}
TESTING epoch@22 ::  acc@0.512  loss@1.407
Epoch@@23
[[544   5  41  16   0   1   2  67 290  34]
 [  6 860   6   0   0   0   0   3  22 103]
 [ 88   0 373 359   0  41  48  79  10   2]
 [ 47   1 110 604   0 117  85  26   4   6]
 [ 41   0 400 393   0  57  49  52   6   2]
 [ 15   1  83 790   0  63  33  12   3   0]
 [  6   1  26  76   0  60 822   5   2   2]
 [ 78   0 385 192   0   7   4 313  20   1]
 [120   9  13   6   0   1   2  11 743  95]
 [  9  97  10   4   0   0   0   9  72 799]]
TRAINING class wise acc@23 :: {0: [0.582], 1: [0.7892], 2: [0.1864], 3: [0.3828], 4: [0.252], 5: [0.3668], 6: [0.852], 7: [0.5604], 8: [0.7008], 9: [0.764]}
TRAIINING epoch@23 ::  acc@0.544  loss@1.230
[[1455    1   53   19   68   15    1  285  575   28]
 [  25 1973    5    4    3    2    2    8   67  411]
 [ 147    0  466  378  564  310   69  551   12    3]
 [  29    0  160  957  190  831  247   76    8    2]
 [  72    0  512  282  630  270   57  673    3    1]
 [  18    0  146 1023  165  917  132   97    0    2]
 [   4    0   13  190   16  134 2130   13    0    0]
 [ 115    0  297  133  418  121    6 1401    8    1]
 [ 467    9   15   13   12    3    2   50 1752  177]
 [  75  208    6    5    8    4    2   22  260 1910]]
TESTING class wise acc@23 :: {0: [0.543], 1: [0.347], 2: [0.536], 3: [0.0], 4: [0.0], 5: [0.618], 6: [0.717], 7: [0.154], 8: [0.837], 9: [0.89]}
TESTING epoch@23 ::  acc@0.464  loss@1.622
Epoch@@24
[[543   0  54   0   0   6   2  36 334  25]
 [ 12 347   4   0   0   4   1   1  46 585]
 [144   0 536   0   0 185  41  69  22   3]
 [ 73   1 252   0   0 539  65  31  32   7]
 [ 56   0 714   0   0 158  13  42  11   6]
 [ 38   0 279   0   0 618  28  16  19   2]
 [  8   0  64   0   0 185 717  11   8   7]
 [ 99   0 643   0   0  60   1 154  34   9]
 [ 77   0  12   0   0   5   1   7 837  61]
 [  9   1   4   0   0   3   0   2  91 890]]
TRAINING class wise acc@24 :: {0: [0.592], 1: [0.818], 2: [0.2256], 3: [0.2872], 4: [0.2136], 5: [0.4872], 6: [0.8792], 7: [0.594], 8: [0.7172], 9: [0.7924]}
TRAIINING epoch@24 ::  acc@0.561  loss@1.166
[[1480    1   53   10   68   11    2  298  552   25]
 [  22 2045    5    3    1    4    0    5   58  357]
 [ 147    0  564  259  535  380   67  537   11    0]
 [  16    0  187  718  164 1125  213   72    5    0]
 [  46    0  620  206  534  283   41  764    6    0]
 [   4    0  163  781  150 1218  105   79    0    0]
 [   1    0   11  116   10  155 2198    7    1    1]
 [ 119    0  362   88  324  109    4 1485    7    2]
 [ 457    8    7    4    9    3    1   47 1793  171]
 [  68  175    7    1    6    2    0   16  244 1981]]
TESTING class wise acc@24 :: {0: [0.727], 1: [0.473], 2: [0.095], 3: [0.0], 4: [0.0], 5: [0.684], 6: [0.462], 7: [0.843], 8: [0.509], 9: [0.868]}
TESTING epoch@24 ::  acc@0.466  loss@1.638
Epoch@@25
[[727   0   4   0   0   4   1 171  76  17]
 [ 22 473   3   0   0   7   0  14  50 431]
 [ 67   0  95   0   0 148   3 680   7   0]
 [ 40   0 103   0   0 608   8 231   6   4]
 [ 32   0  57   0   0  82   1 822   3   3]
 [ 10   0  87   0   0 684   2 213   1   3]
 [ 15   0  69   0   0 349 462 100   2   3]
 [ 56   0  36   0   0  58   0 843   5   2]
 [371   0   3   0   0   9   0  48 509  60]
 [ 37   8   2   0   0   1   0  21  63 868]]
TRAINING class wise acc@25 :: {0: [0.6116], 1: [0.7976], 2: [0.1616], 3: [0.3796], 4: [0.3168], 5: [0.3916], 6: [0.8744], 7: [0.5628], 8: [0.73], 9: [0.772]}
TRAIINING epoch@25 ::  acc@0.560  loss@1.185
[[1529    0   36   17   66    8    0  269  550   25]
 [  23 1994    5    1    1    4    2    4   64  402]
 [ 149    0  404  344  690  290   59  553   10    1]
 [  24    0  126  949  198  896  205   95    3    4]
 [  65    0  468  246  792  207   40  678    4    0]
 [   5    0   86 1043  194  979  104   89    0    0]
 [   3    0   13  111   17  161 2186    8    0    1]
 [ 138    0  248  103  474  116    3 1407   10    1]
 [ 411    5   10    5   16    6    3   48 1825  171]
 [  80  197    5    1    5    6    2   17  257 1930]]
TESTING class wise acc@25 :: {0: [0.734], 1: [0.896], 2: [0.46], 3: [0.218], 4: [0.0], 5: [0.523], 6: [0.753], 7: [0.497], 8: [0.63], 9: [0.676]}
TESTING epoch@25 ::  acc@0.539  loss@1.501
Epoch@@26
[[734   3  43  10   0   6   0  87  78  39]
 [  4 896   5   1   0   2   0   2  11  79]
 [ 84   0 460 204   0  88  38 115   5   6]
 [ 38   1 161 218   0 485  47  31   8  11]
 [ 34   0 598 183   0  63  22  93   4   3]
 [ 19   0 152 251   0 523  27  24   1   3]
 [  5   0  41  67   0 116 753  12   3   3]
 [ 84   1 317  66   0  25   2 497   3   5]
 [218  11  12   7   0   2   1  14 630 105]
 [ 46 186  12   7   0   1   0  10  62 676]]
TRAINING class wise acc@26 :: {0: [0.6108], 1: [0.8368], 2: [0.2368], 3: [0.3144], 4: [0.2692], 5: [0.4952], 6: [0.89], 7: [0.5992], 8: [0.704], 9: [0.8216]}
TRAIINING epoch@26 ::  acc@0.578  loss@1.121
[[1527    0   41    8   58   14    0  307  524   21]
 [  12 2092    4    3    1    0    0    6   37  345]
 [ 117    0  592  296  568  294   57  566    9    1]
 [  23    0  163  786  145 1167  153   62    1    0]
 [  61    0  575  205  673  230   36  716    4    0]
 [  15    0  139  798  122 1238  114   73    1    0]
 [   3    0   15   84    8  158 2225    6    1    0]
 [ 122    0  263  100  403   99    2 1498   11    2]
 [ 482    0    5    4   14    4    0   55 1760  176]
 [  60  156    5    2    7    4    3   10  199 2054]]
TESTING class wise acc@26 :: {0: [0.575], 1: [0.815], 2: [0.658], 3: [0.0], 4: [0.0], 5: [0.737], 6: [0.878], 7: [0.448], 8: [0.614], 9: [0.619]}
TESTING epoch@26 ::  acc@0.534  loss@1.495
Epoch@@27
[[575   0 176   0   0  33   8 136  66   6]
 [ 16 815  18   0   0  15   9   5  42  80]
 [ 26   0 658   0   0 203  64  49   0   0]
 [  2   0 219   0   0 636 135   5   2   1]
 [  8   0 759   0   0 129  50  53   1   0]
 [  2   0 193   0   0 737  58  10   0   0]
 [  1   0  36   0   0  83 878   1   1   0]
 [  6   0 450   0   0  86  10 448   0   0]
 [202   2  66   0   0  45  13  47 614  11]
 [ 54 113  43   0   0  10   7  19 135 619]]
TRAINING class wise acc@27 :: {0: [0.704], 1: [0.8552], 2: [0.3308], 3: [0.3444], 4: [0.2524], 5: [0.45], 6: [0.8976], 7: [0.5768], 8: [0.7988], 9: [0.8352]}
TRAIINING epoch@27 ::  acc@0.605  loss@1.055
[[1760    1   56   10   46    6    0  220  385   16]
 [   7 2138    1    1    2    3    2    5   30  311]
 [ 118    0  827  257  568  248   36  441    4    1]
 [  14    0  221  861  114 1059  181   49    1    0]
 [  45    0  832  177  631  185   34  592    4    0]
 [   2    0  163  980  105 1125   95   30    0    0]
 [   0    0   12  102    8  130 2244    4    0    0]
 [ 111    0  450   84  317   87    3 1442    6    0]
 [ 331    4   13    2    6    3    0   30 1997  114]
 [  36  150    3    1    0    3    2   13  204 2088]]
TESTING class wise acc@27 :: {0: [0.682], 1: [0.879], 2: [0.305], 3: [0.443], 4: [0.0], 5: [0.24], 6: [0.924], 7: [0.531], 8: [0.812], 9: [0.802]}
TESTING epoch@27 ::  acc@0.562  loss@1.524
Epoch@@28
[[682   3  26  19   0   5   6  93 144  22]
 [  3 879   2   2   0   0   0   1  27  86]
 [ 87   0 305 294   0  71  98 132  10   3]
 [ 28   1  79 443   0 199 192  33  15  10]
 [ 30   1 392 263   0  47  97 164   4   2]
 [  8   0  58 556   0 240  94  32   9   3]
 [  1   0  11  38   0  22 924   2   1   1]
 [ 90   1 174 142   0  15  16 531  26   5]
 [109   9   6   7   0   3   3  19 812  32]
 [ 18  68   5   7   0   1   1   3  95 802]]
TRAINING class wise acc@28 :: {0: [0.6664], 1: [0.8288], 2: [0.24], 3: [0.2756], 4: [0.238], 5: [0.528], 6: [0.8552], 7: [0.5592], 8: [0.744], 9: [0.7916]}
TRAIINING epoch@28 ::  acc@0.573  loss@1.187
[[1666    0   61   15   63   10    6  237  417   25]
 [  22 2072    3    0    5    4    9    9   57  319]
 [ 156    0  600  260  554  327   64  531    8    0]
 [  22    0  194  689  135 1185  204   65    5    1]
 [  73    0  681  214  595  260   39  633    5    0]
 [   8    0  137  713  127 1320  121   72    2    0]
 [   6    0   23   77   18  231 2138    6    1    0]
 [ 158    0  325   95  391  119    6 1398    6    2]
 [ 391    0   15    6   13   10    3   46 1860  156]
 [  72  133    4    0    7    6    2   31  266 1979]]
TESTING class wise acc@28 :: {0: [0.453], 1: [0.731], 2: [0.486], 3: [0.531], 4: [0.0], 5: [0.0], 6: [0.845], 7: [0.615], 8: [0.711], 9: [0.908]}
TESTING epoch@28 ::  acc@0.528  loss@1.596
Epoch@@29
[[453   2  51  16   0   0   7  95 310  66]
 [  4 731   1   3   0   0   3   7  12 239]
 [ 71   0 486 169   0   0  87 169  15   3]
 [ 24   1 220 531   0   0 143  56  18   7]
 [ 32   0 556 100   0   0  43 263   5   1]
 [ 17   0 175 679   0   0  84  35   7   3]
 [  6   0  49  92   0   0 845   7   1   0]
 [ 64   0 221  59   0   0  17 615  19   5]
 [ 72   6  10  13   0   0   9  19 711 160]
 [ 11  16  10   3   0   0   2   5  45 908]]
TRAINING class wise acc@29 :: {0: [0.73], 1: [0.8816], 2: [0.2748], 3: [0.3692], 4: [0.3028], 5: [0.4456], 6: [0.9128], 7: [0.6056], 8: [0.8164], 9: [0.858]}
TRAIINING epoch@29 ::  acc@0.620  loss@1.016
[[1825    1   33    9   53   14    0  229  318   18]
 [  15 2204    1    1    0    0    1    3   35  240]
 [ 120    0  687  231  729  232   30  470    0    1]
 [  13    0  140  923  156 1055  165   47    1    0]
 [  44    0  726  183  757  159   17  606    8    0]
 [   2    0  129 1000  133 1114   84   38    0    0]
 [   0    0   14   88    8  107 2282    1    0    0]
 [ 121    0  327   76  384   69    1 1514    8    0]
 [ 312    0   10    2   13    0    2   18 2041  102]
 [  51  110    1    0    0    2    0    8  183 2145]]
TESTING class wise acc@29 :: {0: [0.74], 1: [0.74], 2: [0.085], 3: [0.764], 4: [0.389], 5: [0.0], 6: [0.691], 7: [0.633], 8: [0.774], 9: [0.826]}
TESTING epoch@29 ::  acc@0.564  loss@1.442
Epoch@@30
[[740   0   8  29  22   0   1 100  89  11]
 [ 12 740   0   5   1   0   0   3  29 210]
 [ 67   0  85 299 305   0  16 219   6   3]
 [ 26   1  35 764  82   0  42  38  10   2]
 [ 21   0  62 210 389   0  10 305   1   2]
 [ 11   0  22 867  55   0  16  27   1   1]
 [ 11   0  18 238  31   0 691   8   1   2]
 [ 48   0  39 135 142   0   0 633   2   1]
 [147   3   4  11   7   0   0  19 774  35]
 [ 33  20   1  10   5   0   0  14  91 826]]
TRAINING class wise acc@30 :: {0: [0.7016], 1: [0.8192], 2: [0.2636], 3: [0.3552], 4: [0.2744], 5: [0.4896], 6: [0.9032], 7: [0.5276], 8: [0.782], 9: [0.8228]}
TRAIINING epoch@30 ::  acc@0.594  loss@1.087
[[1754    0   49   12   51   10    1  215  395   13]
 [  22 2048    5    3    2    2    1    7   51  359]
 [ 127    0  659  296  630  212   44  521    9    2]
 [  10    0  173  888  148 1050  165   63    2    1]
 [  60    0  714  202  686  151   18  664    5    0]
 [   9    0  132  913  105 1224   74   41    1    1]
 [   2    0    6   69   13  148 2258    3    1    0]
 [ 163    0  363   92  487   64    6 1319    6    0]
 [ 357    1   10    3    8    6    3   26 1955  131]
 [  72  137    6    3    9    2    0   16  198 2057]]
TESTING class wise acc@30 :: {0: [0.583], 1: [0.853], 2: [0.562], 3: [0.194], 4: [0.0], 5: [0.639], 6: [0.855], 7: [0.492], 8: [0.735], 9: [0.839]}
TESTING epoch@30 ::  acc@0.575  loss@1.467
Epoch@@31
[[583   4 100  23   0  31  12 128  88  31]
 [  7 853   4   0   0   4   7   5  20 100]
 [ 32   0 562 162   0 110  77  54   2   1]
 [  8   1 147 194   0 529 103  15   2   1]
 [  8   0 692 104   0  74  54  65   2   1]
 [  4   0 119 187   0 639  35  14   1   1]
 [  0   0  33  29   0  78 855   3   1   1]
 [ 14   0 356  75   0  47  13 492   3   0]
 [117   6  30   8   0   7  16  22 735  59]
 [ 21  47  15   5   0   5   2  13  53 839]]
TRAINING class wise acc@31 :: {0: [0.7592], 1: [0.8616], 2: [0.3232], 3: [0.4096], 4: [0.2428], 5: [0.428], 6: [0.9084], 7: [0.6156], 8: [0.8184], 9: [0.838]}
TRAIINING epoch@31 ::  acc@0.620  loss@1.025
[[1898    0   35   12   36   11    0  225  267   16]
 [  10 2154    1    2    3    5    0    5   49  271]
 [ 116    0  808  229  639  221   27  453    6    1]
 [   8    0  158 1024  113 1025  142   27    3    0]
 [  48    0  879  190  607  168   19  589    0    0]
 [   3    0  156 1068   92 1070   71   38    1    1]
 [   1    0   11   92    6  116 2271    2    1    0]
 [ 118    0  422   84  261   66    2 1539    6    2]
 [ 312    1   10    4    7    2    1   28 2046   89]
 [  54  119    5    3    3    2    0   10  209 2095]]
TESTING class wise acc@31 :: {0: [0.624], 1: [0.695], 2: [0.0], 3: [0.0], 4: [0.491], 5: [0.785], 6: [0.832], 7: [0.64], 8: [0.67], 9: [0.72]}
TESTING epoch@31 ::  acc@0.546  loss@1.537
Epoch@@32
[[624   1   0   0  43  32   4 170 104  22]
 [ 19 695   0   0  14  13   8  16  34 201]
 [ 45   0   0   0 441 226  61 225   2   0]
 [  5   0   0   0 155 687 101  48   1   3]
 [ 12   0   0   0 491 184  45 267   1   0]
 [  1   0   0   0 133 785  46  35   0   0]
 [  0   0   0   0  42 120 832   6   0   0]
 [ 13   0   0   0 213 123  10 640   1   0]
 [135   4   0   0  18  24   6  40 670 103]
 [ 54  41   0   0  24  19   5  48  89 720]]
TRAINING class wise acc@32 :: {0: [0.776], 1: [0.8728], 2: [0.2764], 3: [0.3732], 4: [0.32], 5: [0.4552], 6: [0.916], 7: [0.5944], 8: [0.83], 9: [0.858]}
TRAIINING epoch@32 ::  acc@0.627  loss@0.985
[[1940    0   39    6   47    4    1  212  240   11]
 [  10 2182    0    0    4    0    0    4   32  268]
 [ 122    0  691  221  763  181   28  489    5    0]
 [   8    0  138  933  146 1102  136   35    1    1]
 [  47    0  732  171  800  147   21  578    4    0]
 [   2    0  116 1019  118 1138   66   41    0    0]
 [   0    0    5   77    5  121 2290    2    0    0]
 [ 149    0  330   79  397   50    2 1486    7    0]
 [ 271    7   11    7    5    3    0   32 2075   89]
 [  48  127    1    3    3    1    0   11  161 2145]]
TESTING class wise acc@32 :: {0: [0.737], 1: [0.727], 2: [0.0], 3: [0.826], 4: [0.69], 5: [0.0], 6: [0.769], 7: [0.281], 8: [0.694], 9: [0.913]}
TESTING epoch@32 ::  acc@0.564  loss@1.481
Epoch@@33
[[737   0   0  41  88   0   2  28  66  38]
 [ 10 727   0   8   6   0   0   0  11 238]
 [ 64   0   0 352 527   0  30  21   3   3]
 [ 15   0   0 826 111   0  38   4   0   6]
 [ 27   0   0 241 690   0  19  20   2   1]
 [  6   0   0 904  64   0  11  12   1   2]
 [  3   0   0 183  38   0 769   3   3   1]
 [ 84   0   0 166 460   0   1 281   2   6]
 [124   4   0  14  28   0   2  11 694 123]
 [ 23  14   0   7  13   0   0   3  27 913]]
TRAINING class wise acc@33 :: {0: [0.7712], 1: [0.8728], 2: [0.2792], 3: [0.4304], 4: [0.3812], 5: [0.392], 6: [0.9164], 7: [0.6376], 8: [0.8316], 9: [0.8532]}
TRAIINING epoch@33 ::  acc@0.637  loss@0.971
[[1928    0   37    6   65    3    1  210  237   13]
 [   8 2182    2    1    3    1    0    7   30  266]
 [  98    0  698  228  933  145   15  380    3    0]
 [   8    0  143 1076  172  946  130   20    4    1]
 [  39    0  712  190  953  114   13  479    0    0]
 [   1    0  109 1199  122  980   63   24    1    1]
 [   0    0    4   93    5  106 2291    1    0    0]
 [ 140    0  259   55  402   45    1 1594    4    0]
 [ 284    3    8    4    5    2    0   27 2079   88]
 [  51  108    1    4    3    0    0   12  188 2133]]
TESTING class wise acc@33 :: {0: [0.733], 1: [0.911], 2: [0.474], 3: [0.046], 4: [0.0], 5: [0.583], 6: [0.847], 7: [0.715], 8: [0.802], 9: [0.638]}
TESTING epoch@33 ::  acc@0.575  loss@1.755
Epoch@@34
[[733   4  11   1   0   4   3  74 149  21]
 [  5 911   5   1   0   1   1   3  20  53]
 [ 94   1 474  28   0 118  72 201   9   3]
 [ 26   1 205  46   0 509 123  79   9   2]
 [ 37   0 509  29   0 137  73 207   7   1]
 [ 18   0 223  48   0 583  63  60   5   0]
 [  3   3  34   6   0  87 847  15   3   2]
 [ 49   0 165  14   0  40   8 715   7   2]
 [ 97  12   8   1   0   5   3  13 802  59]
 [ 26 175  11   1   0   7   2  23 117 638]]
TRAINING class wise acc@34 :: {0: [0.7692], 1: [0.8644], 2: [0.384], 3: [0.2472], 4: [0.2912], 5: [0.6152], 6: [0.916], 7: [0.6136], 8: [0.824], 9: [0.8464]}
TRAIINING epoch@34 ::  acc@0.637  loss@0.990
[[1923    0   54    2   51   14    1  198  244   13]
 [  15 2161    2    0    0    1    2    3   35  281]
 [  96    0  960  160  628  229   26  397    4    0]
 [  11    0  161  618  106 1448  122   31    3    0]
 [  30    0  979  121  728  167   14  457    4    0]
 [   2    0  159  609  110 1538   57   24    0    1]
 [   1    0    8   52    7  142 2290    0    0    0]
 [ 150    0  409   46  288   63    5 1534    5    0]
 [ 298    3    9    1    9    3    2   21 2060   94]
 [  51  123    6    3    1    3    2   13  182 2116]]
TESTING class wise acc@34 :: {0: [0.675], 1: [0.805], 2: [0.576], 3: [0.684], 4: [0.0], 5: [0.0], 6: [0.825], 7: [0.509], 8: [0.829], 9: [0.823]}
TESTING epoch@34 ::  acc@0.573  loss@1.384
Epoch@@35
[[675   2  38  12   0   0   1 140 117  15]
 [ 11 805   6   5   0   0   0   5  35 133]
 [ 41   0 576 227   0   0  41 109   6   0]
 [ 18   0 170 684   0   0  90  28   8   2]
 [ 11   0 679 199   0   0  34  73   4   0]
 [  5   0 128 811   0   0  32  21   3   0]
 [  1   0  32 129   0   0 825  10   2   1]
 [  9   0 377  94   0   0   4 509   7   0]
 [ 81   3  18   7   0   0   2  34 829  26]
 [ 19  28   8   5   0   0   0  12 105 823]]
TRAINING class wise acc@35 :: {0: [0.79], 1: [0.8616], 2: [0.2864], 3: [0.382], 4: [0.3716], 5: [0.474], 6: [0.9232], 7: [0.628], 8: [0.8424], 9: [0.876]}
TRAIINING epoch@35 ::  acc@0.644  loss@0.960
[[1975    0   28    3   51    5    0  207  219   12]
 [  18 2154    1    0    1    0    0    5   48  273]
 [  87    1  716  208  902  185   21  378    2    0]
 [   8    0  131  955  123 1138  117   26    1    1]
 [  27    0  783  154  929  114   14  473    6    0]
 [   1    0  112 1011  111 1185   56   23    0    1]
 [   0    0    3   86    6   96 2308    0    1    0]
 [ 176    0  235   63  401   47    2 1570    5    1]
 [ 242    2    9    1    7    3    0   30 2106  100]
 [  45  104    4    1    2    1    2    6  145 2190]]
TESTING class wise acc@35 :: {0: [0.592], 1: [0.806], 2: [0.485], 3: [0.721], 4: [0.034], 5: [0.049], 6: [0.78], 7: [0.622], 8: [0.606], 9: [0.532]}
TESTING epoch@35 ::  acc@0.523  loss@1.927
Epoch@@36
[[592   5  65  32   1   4   5 146 119  31]
 [ 14 806  17  16   0   7  25  22  27  66]
 [ 27   0 485 206  25  23  48 182   4   0]
 [  4   0 113 721   3  71  57  28   3   0]
 [  5   0 523 181  34  21  29 204   1   2]
 [  0   0  94 803   1  49  26  27   0   0]
 [  0   0  41 110   3  62 780   3   0   1]
 [  9   0 203 133  13   6   8 622   6   0]
 [ 90  32  35  34   1   7  11  59 606 125]
 [ 37 227  30  48   0   5   5  40  76 532]]
TRAINING class wise acc@36 :: {0: [0.7728], 1: [0.8584], 2: [0.3796], 3: [0.3448], 4: [0.3204], 5: [0.5272], 6: [0.9236], 7: [0.6852], 8: [0.8384], 9: [0.8608]}
TRAIINING epoch@36 ::  acc@0.651  loss@0.956
[[1932    0   39    3   32    8    0  233  240   13]
 [   5 2146    1    3    2    1    1    3   41  297]
 [  89    0  949  183  729  196   16  334    4    0]
 [   3    0  175  862  119 1213  102   25    0    1]
 [  24    0  960  122  801  132   17  441    3    0]
 [   3    0  119  891   87 1318   58   23    1    0]
 [   0    0    7   63    8  111 2309    1    1    0]
 [ 140    0  283   44  253   59    0 1713    5    3]
 [ 277    2    8    5    3    4    6   20 2096   79]
 [  42  118    7    2    1    2    0   11  165 2152]]
TESTING class wise acc@36 :: {0: [0.687], 1: [0.905], 2: [0.505], 3: [0.111], 4: [0.0], 5: [0.779], 6: [0.783], 7: [0.62], 8: [0.754], 9: [0.687]}
TESTING epoch@36 ::  acc@0.583  loss@1.480
Epoch@@37
[[687   4  34   8   0  13   2 118 100  34]
 [ 14 905   0   2   0   6   3   7  15  48]
 [ 50   0 505 133   0 142  27 136   6   1]
 [ 12   0 103 111   0 688  51  31   3   1]
 [ 20   0 555 118   0 150  37 120   0   0]
 [  5   0  73 105   0 779  16  20   2   0]
 [  3   0  24  24   0 159 783   4   2   1]
 [ 19   0 227  67   0  61   3 620   3   0]
 [121  13  11   9   0   6   1  20 754  65]
 [ 33 174  15   4   0  11   1  17  58 687]]
TRAINING class wise acc@37 :: {0: [0.836], 1: [0.916], 2: [0.4176], 3: [0.4272], 4: [0.3644], 5: [0.4776], 6: [0.9612], 7: [0.7512], 8: [0.8936], 9: [0.9016]}
TRAIINING epoch@37 ::  acc@0.695  loss@0.795
[[2090    0   21    2   25    2    0  165  188    7]
 [   4 2290    1    0    0    0    0    3   11  191]
 [  52    0 1044  190  843   84    6  279    2    0]
 [   2    0  147 1068   86 1109   81    7    0    0]
 [  14    0 1047  105  911   63    4  356    0    0]
 [   1    0  106 1067   72 1194   44   16    0    0]
 [   0    0    1   44    0   52 2403    0    0    0]
 [  95    0  236   32  231   21    0 1878    5    2]
 [ 185    1    3    1    3    0    0   12 2234   61]
 [  29   78    1    0    1    0    0    3  134 2254]]
TESTING class wise acc@37 :: {0: [0.829], 1: [0.87], 2: [0.646], 3: [0.483], 4: [0.0], 5: [0.0], 6: [0.777], 7: [0.653], 8: [0.835], 9: [0.863]}
TESTING epoch@37 ::  acc@0.596  loss@2.728
Epoch@@38
[[829   2  24   3   0   0   1  34  89  18]
 [  6 870   1   0   0   0   0   1  28  94]
 [104   0 646 103   0   0  28  95  16   8]
 [ 88   1 258 483   0   0  66  49  37  18]
 [ 60   0 712  66   0   0  18 133  10   1]
 [ 38   0 223 619   0   0  33  63  17   7]
 [ 22   3  74  98   0   0 777  13   9   4]
 [138   0 157  26   0   0   0 653  19   7]
 [113   6   5   1   0   0   0   5 835  35]
 [ 21  49   0   0   0   0   0   1  66 863]]
TRAINING class wise acc@38 :: {0: [0.7232], 1: [0.808], 2: [0.2944], 3: [0.3432], 4: [0.3468], 5: [0.4948], 6: [0.8736], 7: [0.6408], 8: [0.7864], 9: [0.8076]}
TRAIINING epoch@38 ::  acc@0.612  loss@1.158
[[1808    0   62    8   63   15    3  228  297   16]
 [  27 2020   10    1    3   12    4    9   67  347]
 [  90    0  736  261  799  184   29  393    7    1]
 [  16    0  175  858  134 1141  128   43    4    1]
 [  41    0  790  184  867  144   21  448    5    0]
 [   3    0  105  917  124 1237   73   39    1    1]
 [   2    0   22  114   10  162 2184    4    1    1]
 [ 146    0  312   59  302   62    5 1602   12    0]
 [ 332    6   17    4    9    8    4   51 1966  103]
 [  77  126   16    7    9   10    2   19  215 2019]]
TESTING class wise acc@38 :: {0: [0.773], 1: [0.81], 2: [0.0], 3: [0.592], 4: [0.778], 5: [0.043], 6: [0.774], 7: [0.647], 8: [0.818], 9: [0.815]}
TESTING epoch@38 ::  acc@0.605  loss@1.397
Epoch@@39
[[773   1   0   9  50   1   0  83  74   9]
 [  8 810   0   1   7   0   0   8  31 135]
 [ 45   0   0 122 718  12  21  79   3   0]
 [ 25   0   0 592 222  65  46  41   7   2]
 [ 21   0   0 102 778   9  18  70   1   1]
 [ 11   0   0 708 194  43  16  27   1   0]
 [  4   0   0  89  64  58 774   7   1   3]
 [ 28   0   0  41 277   3   0 647   4   0]
 [121   2   0   4  12   1   1  20 818  21]
 [ 40  28   0   3   8   0   1  11  94 815]]
TRAINING class wise acc@39 :: {0: [0.8416], 1: [0.9096], 2: [0.4644], 3: [0.42], 4: [0.3172], 5: [0.5148], 6: [0.9604], 7: [0.7592], 8: [0.8952], 9: [0.9076]}
TRAIINING epoch@39 ::  acc@0.699  loss@0.771
[[2104    0   30    2   22    1    0  167  168    6]
 [   6 2274    0    0    0    0    0    1   17  202]
 [  43    0 1161  172  748   99    5  271    1    0]
 [   0    0  132 1050   80 1156   72   10    0    0]
 [  16    0 1183  109  793   41    6  352    0    0]
 [   0    0  102 1011   50 1287   40   10    0    0]
 [   0    0    1   39    1   58 2401    0    0    0]
 [ 104    0  213   29  242   13    0 1898    1    0]
 [ 186    0    1    1    2    0    0   15 2238   57]
 [  16   81    0    0    1    0    0    3  130 2269]]
TESTING class wise acc@39 :: {0: [0.785], 1: [0.827], 2: [0.0], 3: [0.505], 4: [0.711], 5: [0.253], 6: [0.784], 7: [0.637], 8: [0.881], 9: [0.864]}
TESTING epoch@39 ::  acc@0.625  loss@1.662
Epoch@@40
[[785   1   0   6  24   1   0  42 131  10]
 [ 10 827   0   2   3   0   0   2  20 136]
 [ 92   0   0 129 605  19  29 116   8   2]
 [ 36   1   0 505 183 177  39  45  12   2]
 [ 27   0   0 123 711  19  19  95   5   1]
 [ 16   0   0 543 143 253  10  31   4   0]
 [  7   0   0  55  61  76 784  12   3   2]
 [ 79   0   0  62 202   9   1 637   7   3]
 [ 49   1   0   1   9   1   2   9 881  47]
 [ 27  43   0   2   6   1   0   3  54 864]]
TRAINING class wise acc@40 :: {0: [0.858], 1: [0.93], 2: [0.4368], 3: [0.4048], 4: [0.3916], 5: [0.5432], 6: [0.9644], 7: [0.8172], 8: [0.91], 9: [0.9204]}
TRAIINING epoch@40 ::  acc@0.718  loss@0.703
[[2145    0   17    0   20    0    1  187  130    0]
 [   2 2325    0    1    0    0    0    0   13  159]
 [  32    0 1092  114  973   73    4  210    2    0]
 [   0    0  106 1012   49 1265   63    5    0    0]
 [   9    0 1118   61  979   46    1  286    0    0]
 [   0    0   74  990   40 1358   31    7    0    0]
 [   0    0    2   39    1   47 2411    0    0    0]
 [  84    0  176   10  175   10    0 2043    2    0]
 [ 152    0    2    0    3    0    0    5 2275   63]
 [  16   81    1    0    0    0    0    2   99 2301]]
TESTING class wise acc@40 :: {0: [0.699], 1: [0.785], 2: [0.678], 3: [0.675], 4: [0.0], 5: [0.0], 6: [0.74], 7: [0.786], 8: [0.825], 9: [0.888]}
TESTING epoch@40 ::  acc@0.608  loss@1.668
Epoch@@41
[[699   0  61   9   0   0   0 134  80  17]
 [  3 785   5   7   0   0   0  10  18 172]
 [ 27   0 678 163   0   0  21 104   6   1]
 [ 20   1 208 675   0   0  32  56   7   1]
 [ 13   0 712 110   0   0  13 150   1   1]
 [  7   0 164 772   0   0  10  43   4   0]
 [  6   0  83 159   0   0 740  11   0   1]
 [ 12   0 141  55   0   0   0 786   5   1]
 [ 79   2  15   4   0   0   0  24 825  51]
 [ 16  20   7   3   0   0   0  18  48 888]]
TRAINING class wise acc@41 :: {0: [0.708], 1: [0.7888], 2: [0.3816], 3: [0.3748], 4: [0.2976], 5: [0.4556], 6: [0.8592], 7: [0.6352], 8: [0.7668], 9: [0.7972]}
TRAIINING epoch@41 ::  acc@0.606  loss@1.196
[[1770    0   65   16   56    6    2  259  310   16]
 [  33 1972    3    3    8   10    1   22   77  371]
 [  73    1  954  236  707  189   45  285   10    0]
 [  12    0  177  937  151 1056  132   30    5    0]
 [  45    0 1004  177  744  145   36  346    3    0]
 [  11    0  153  970  124 1139   77   25    1    0]
 [   2    0   25  129    9  179 2148    5    3    0]
 [ 201    0  309   81  256   44    7 1588   12    2]
 [ 341    4   19    9   11    9    4   61 1917  125]
 [  74  135   15    6   12    5    0   25  235 1993]]
TESTING class wise acc@41 :: {0: [0.676], 1: [0.881], 2: [0.0], 3: [0.157], 4: [0.591], 5: [0.62], 6: [0.768], 7: [0.774], 8: [0.7], 9: [0.658]}
TESTING epoch@41 ::  acc@0.582  loss@1.440
Epoch@@42
[[676   5   0   9  61  14   1 184  43   7]
 [ 20 881   0   3   7   3   2   9  29  46]
 [ 28   0   0  94 649  58  28 142   1   0]
 [  7   1   0 157 187 543  45  58   2   0]
 [  3   0   0  68 591  57  24 255   2   0]
 [  3   0   0 180 145 620   8  44   0   0]
 [  0   0   0  50  67 104 768  11   0   0]
 [  8   0   0  33 162  20   2 774   1   0]
 [163   6   0  10  28   7   3  42 700  41]
 [ 51 148   0  12  20   6   1  32  72 658]]
TRAINING class wise acc@42 :: {0: [0.8352], 1: [0.906], 2: [0.3852], 3: [0.382], 4: [0.4108], 5: [0.512], 6: [0.9532], 7: [0.7776], 8: [0.8908], 9: [0.8944]}
TRAIINING epoch@42 ::  acc@0.695  loss@0.787
[[2088    0   27    1   29    0    0  171  180    4]
 [   4 2265    1    0    1    0    0    2   21  206]
 [  41    0  963  126 1034  104    9  221    2    0]
 [   4    0  122  955   89 1239   86    4    1    0]
 [  15    0  942   97 1027   70    4  344    1    0]
 [   0    0   83 1009   73 1280   50    5    0    0]
 [   0    0    2   38    2   75 2383    0    0    0]
 [ 114    0  169   22  233   15    0 1944    3    0]
 [ 190    1    0    1    4    1    0   14 2227   62]
 [  37   79    1    0    3    0    0    9  135 2236]]
TESTING class wise acc@42 :: {0: [0.685], 1: [0.836], 2: [0.624], 3: [0.733], 4: [0.008], 5: [0.0], 6: [0.821], 7: [0.695], 8: [0.782], 9: [0.841]}
TESTING epoch@42 ::  acc@0.602  loss@1.517
Epoch@@43
[[685   2  43  21   3   0   1 122  91  32]
 [  8 836   6   9   0   0   1   5  12 123]
 [ 39   0 624 183   5   0  33 112   4   0]
 [  7   1 160 733   0   0  65  32   2   0]
 [ 10   0 663 171   8   0  28 116   2   2]
 [  2   0 104 849   1   0  18  25   0   1]
 [  1   0  62 110   1   0 821   3   1   1]
 [ 19   0 200  75   7   0   0 695   4   0]
 [ 91   6  18  22   0   0   1  17 782  63]
 [ 23  41  11  11   0   0   3  17  53 841]]
TRAINING class wise acc@43 :: {0: [0.8024], 1: [0.8656], 2: [0.4272], 3: [0.3424], 4: [0.3536], 5: [0.5292], 6: [0.9364], 7: [0.766], 8: [0.856], 9: [0.8752]}
TRAIINING epoch@43 ::  acc@0.675  loss@0.879
[[2006    1   25    2   38    1    0  219  196   12]
 [  15 2164    0    2    1    1    2    6   33  276]
 [  55    0 1068  134  840  154   10  235    3    1]
 [   5    0  167  856   77 1294   82   18    1    0]
 [  22    0 1085   92  884   90   12  314    1    0]
 [   3    0  127  925   59 1323   48   13    1    1]
 [   2    0    8   47    2  100 2341    0    0    0]
 [ 123    0  240   21  181   18    2 1915    0    0]
 [ 232    2    8    1    3    2    2   24 2140   86]
 [  59   82    2    1    1    0    0   10  157 2188]]
TESTING class wise acc@43 :: {0: [0.603], 1: [0.791], 2: [0.653], 3: [0.0], 4: [0.0], 5: [0.748], 6: [0.757], 7: [0.821], 8: [0.831], 9: [0.857]}
TESTING epoch@43 ::  acc@0.606  loss@1.625
Epoch@@44
[[603   0  43   0   0  13   1 243  86  11]
 [  8 791   1   0   0   2   0  14  31 153]
 [ 21   0 653   0   0 136  25 159   6   0]
 [  7   1 239   0   0 622  39  80  10   2]
 [  4   0 713   0   0  90  15 175   2   1]
 [  4   0 175   0   0 748  13  57   3   0]
 [  0   0  79   0   0 139 757  19   5   1]
 [  7   0 122   0   0  47   0 821   3   0]
 [ 78   2  13   0   0   6   1  37 831  32]
 [ 22  23   6   0   0   2   1  21  68 857]]
TRAINING class wise acc@44 :: {0: [0.858], 1: [0.9276], 2: [0.4664], 3: [0.362], 4: [0.3884], 5: [0.5824], 6: [0.9708], 7: [0.8388], 8: [0.916], 9: [0.9216]}
TRAIINING epoch@44 ::  acc@0.723  loss@0.683
[[2145    0   18    0   12    0    0  198  125    2]
 [   2 2319    0    0    0    0    0    0   11  168]
 [  29    0 1166   80  956   67    3  199    0    0]
 [   0    0   89  905   67 1365   71    3    0    0]
 [   6    0 1139   72  971   56    1  255    0    0]
 [   0    0   80  886   41 1456   32    5    0    0]
 [   0    0    3   21    0   49 2427    0    0    0]
 [  92    0  141    9  153    8    0 2097    0    0]
 [ 156    1    2    0    1    0    0    8 2290   42]
 [  30   70    0    0    1    0    0    1   94 2304]]
TESTING class wise acc@44 :: {0: [0.703], 1: [0.829], 2: [0.268], 3: [0.717], 4: [0.531], 5: [0.005], 6: [0.802], 7: [0.721], 8: [0.849], 9: [0.871]}
TESTING epoch@44 ::  acc@0.630  loss@1.744
Epoch@@45
[[703   1  14  20  49   0   2 126  69  16]
 [  9 829   1   1   1   0   0   4  19 136]
 [ 25   0 268 185 404   3  26  83   4   2]
 [ 19   1  90 717  66   5  53  39   7   3]
 [ 10   0 191 126 531   0  28 111   2   1]
 [ 10   0  70 808  51   5  20  31   5   0]
 [  4   1  39 117  21   9 802   4   2   1]
 [ 27   0  45  77 122   0   1 721   5   2]
 [ 91   1   7   6   6   0   1  15 849  24]
 [ 20  28   2   3   3   0   0  10  63 871]]
TRAINING class wise acc@45 :: {0: [0.8912], 1: [0.9404], 2: [0.478], 3: [0.492], 4: [0.3776], 5: [0.4668], 6: [0.9832], 7: [0.8856], 8: [0.93], 9: [0.9312]}
TRAIINING epoch@45 ::  acc@0.738  loss@0.609
[[2228    0   13    0    6    0    0  157   95    1]
 [   1 2351    0    0    0    0    0    0    6  142]
 [  21    0 1195   83 1025   49    2  125    0    0]
 [   0    0   78 1230   32 1112   48    0    0    0]
 [   2    0 1269   54  944   29    1  201    0    0]
 [   0    0   70 1211   25 1167   25    2    0    0]
 [   0    0    0   22    0   20 2458    0    0    0]
 [  51    0  105    4  117    6    0 2214    3    0]
 [ 122    0    0    0    1    0    0    5 2325   47]
 [  12   73    0    0    0    0    0    2   85 2328]]
TESTING class wise acc@45 :: {0: [0.832], 1: [0.862], 2: [0.254], 3: [0.093], 4: [0.482], 5: [0.749], 6: [0.777], 7: [0.796], 8: [0.795], 9: [0.875]}
TESTING epoch@45 ::  acc@0.651  loss@2.047
Epoch@@46
[[832   1   7   1  21   6   1  66  50  15]
 [ 15 862   1   1   2   1   0   5  15  98]
 [ 56   0 254  70 346 117  22 127   6   2]
 [ 29   1  88  93  73 623  30  55   3   5]
 [ 17   0 214  63 482  58  16 147   2   1]
 [ 13   0  80  63  45 749  10  36   3   1]
 [  6   1  34  30  25 105 777  16   2   4]
 [ 41   0  31  23  75  32   0 796   2   0]
 [ 99   6   5   2   8   2   1  14 795  68]
 [ 30  28   2   0   0   3   0  14  48 875]]
TRAINING class wise acc@46 :: {0: [0.9044], 1: [0.9488], 2: [0.462], 3: [0.3828], 4: [0.4556], 5: [0.5848], 6: [0.982], 7: [0.9068], 8: [0.9468], 9: [0.95]}
TRAIINING epoch@46 ::  acc@0.752  loss@0.568
[[2261    0    6    0    4    0    0  136   92    1]
 [   1 2372    0    0    0    0    0    0    8  119]
 [  14    0 1155   38 1125   60    2  106    0    0]
 [   0    0   49  957   31 1413   50    0    0    0]
 [   2    0 1128   32 1139   39    0  160    0    0]
 [   0    0   43  941   30 1462   21    3    0    0]
 [   0    0    0   17    1   27 2455    0    0    0]
 [  47    0   75    6  101    3    0 2267    0    1]
 [  94    0    2    0    0    0    0    3 2367   34]
 [   6   53    0    0    0    0    0    2   64 2375]]
TESTING class wise acc@46 :: {0: [0.744], 1: [0.801], 2: [0.721], 3: [0.793], 4: [0.0], 5: [0.0], 6: [0.688], 7: [0.721], 8: [0.832], 9: [0.864]}
TESTING epoch@46 ::  acc@0.616  loss@1.868
Epoch@@47
[[744   1  48  20   0   0   1  96  78  12]
 [ 17 801   2   3   0   0   1   5  21 150]
 [ 34   0 721 172   0   0   6  64   3   0]
 [ 11   1 135 793   0   0  19  35   5   1]
 [ 15   0 736 163   0   0   5  79   1   1]
 [  8   0 105 863   0   0   2  22   0   0]
 [  2   1  90 211   0   0 688   6   1   1]
 [ 23   0 174  80   0   0   0 721   2   0]
 [ 81   5  17  16   0   0   1  11 832  37]
 [ 16  17   9   8   0   0   0  13  73 864]]
TRAINING class wise acc@47 :: {0: [0.9148], 1: [0.9608], 2: [0.5216], 3: [0.4652], 4: [0.396], 5: [0.4708], 6: [0.9804], 7: [0.9112], 8: [0.9424], 9: [0.9564]}
TRAIINING epoch@47 ::  acc@0.752  loss@0.552
[[2287    0    4    1    8    0    0  124   76    0]
 [   1 2402    0    0    0    0    0    0    2   95]
 [  14    0 1304   69  973   47    3   90    0    0]
 [   0    0   74 1163   35 1178   46    4    0    0]
 [   1    0 1270   46  990   46    2  145    0    0]
 [   0    0   46 1219   27 1177   30    1    0    0]
 [   0    0    1   23    0   25 2451    0    0    0]
 [  47    0   78    3   93    1    0 2278    0    0]
 [ 104    0    0    0    2    0    0    3 2356   35]
 [   4   44    0    0    0    0    0    2   59 2391]]
TESTING class wise acc@47 :: {0: [0.763], 1: [0.914], 2: [0.046], 3: [0.818], 4: [0.549], 5: [0.0], 6: [0.771], 7: [0.766], 8: [0.705], 9: [0.77]}
TESTING epoch@47 ::  acc@0.610  loss@1.885
Epoch@@48
[[763   5   7  30  60   0   3  87  26  19]
 [ 16 914   4   2   8   0   0   9  13  34]
 [ 31   0  46 236 556   0  33  96   0   2]
 [  9   1  26 818  85   0  31  30   0   0]
 [ 12   0  47 205 549   0  26 160   0   1]
 [  3   0  23 871  65   0   8  30   0   0]
 [  2   0  10 181  32   0 771   3   0   1]
 [ 19   0  25 102  86   0   0 766   1   1]
 [172  11   6  15  25   0   4  18 705  44]
 [ 38 112   3  10  14   0   1  19  33 770]]
TRAINING class wise acc@48 :: {0: [0.892], 1: [0.9432], 2: [0.47], 3: [0.456], 4: [0.452], 5: [0.4904], 6: [0.97], 7: [0.894], 8: [0.9408], 9: [0.9376]}
TRAIINING epoch@48 ::  acc@0.745  loss@0.591
[[2230    0   13    1   10    0    0  157   89    0]
 [   1 2358    0    0    0    0    0    2    6  133]
 [  12    0 1175   85 1047   54    6  121    0    0]
 [   0    0  103 1140   52 1137   66    2    0    0]
 [   3    0 1107   66 1130   37    3  154    0    0]
 [   0    0   56 1133   49 1226   34    2    0    0]
 [   0    0    2   36    0   37 2425    0    0    0]
 [  50    0   89    6  115    4    0 2235    0    1]
 [ 108    1    2    0    1    0    0    5 2352   31]
 [  13   70    0    0    1    0    0    0   72 2344]]
TESTING class wise acc@48 :: {0: [0.752], 1: [0.859], 2: [0.643], 3: [0.705], 4: [0.0], 5: [0.0], 6: [0.813], 7: [0.774], 8: [0.861], 9: [0.869]}
TESTING epoch@48 ::  acc@0.628  loss@2.317
Epoch@@49
[[752   1  29  12   0   0   1  93  93  19]
 [  7 859   2   2   0   0   0   3  21 106]
 [ 45   0 643 158   0   0  38 107   7   2]
 [ 17   1 145 705   0   0  61  49  16   6]
 [ 19   0 714 106   0   0  25 132   2   2]
 [  6   0 113 790   0   0  44  38   8   1]
 [  2   0  67 100   0   0 813  15   1   2]
 [ 31   0 121  68   0   0   1 774   3   2]
 [ 73   2  11   7   0   0   1  12 861  33]
 [ 24  36   2   7   0   0   0   8  54 869]]
TRAINING class wise acc@49 :: {0: [0.7912], 1: [0.9104], 2: [0.4124], 3: [0.356], 4: [0.42], 5: [0.54], 6: [0.9268], 7: [0.8204], 8: [0.866], 9: [0.8748]}
TRAIINING epoch@49 ::  acc@0.692  loss@0.876
[[1978    1   46   11   42    3    2  243  163   11]
 [   6 2276    0    1    0    1    0    4   23  189]
 [  30    0 1031  172  993   94   14  163    3    0]
 [   7    0  141  890   90 1244  108   19    1    0]
 [  14    0 1005  125 1050   80   11  215    0    0]
 [   3    0  122  884   68 1350   65    8    0    0]
 [   0    0    5   51    2  124 2317    1    0    0]
 [  56    0  177   40  157   14    2 2051    2    1]
 [ 214    1   11   11   12    4    6   23 2165   53]
 [  47   90    3    2    1    2    2   15  151 2187]]
TESTING class wise acc@49 :: {0: [0.474], 1: [0.741], 2: [0.0], 3: [0.056], 4: [0.684], 5: [0.752], 6: [0.801], 7: [0.746], 8: [0.677], 9: [0.851]}
TESTING epoch@49 ::  acc@0.578  loss@2.083
[[474   0   0   7 121  47   0 151 167  33]
 [  9 741   0   4  10  16   1   8  12 199]
 [ 34   0   0  49 600 159  59  92   4   3]
 [  2   1   0  56 185 656  61  30   4   5]
 [ 12   0   0  30 684  96  45 128   4   1]
 [  1   0   0  45 150 752  18  32   1   1]
 [  1   0   0  12  61 119 801   3   3   0]
 [  7   0   0  18 167  52   6 746   3   1]
 [ 86   1   0  10  60  51  11  47 677  57]
 [ 20  15   0   3  18  13   3  19  58 851]]
