

Fri Jan 15 16:15:05 2021
imbal_test_imbal1_rand_cifar10_vgg_Adam's set level: 10
imbal_test_imbal1_rand_cifar10_vgg_Adam logger is ready
imbal_test with imbalance_ratio: [0.5 1.  1.  1.  1.  1.  1.  1.  1.  1. ]
parallel mode is False
initial count: cifar10: [0 1 2 3 4 5 6 7 8 9] class, each has [5000 5000 5000 5000 5000 5000 5000 5000 5000 5000]
cifar10: [0 1 2 3 4 5 6 7 8 9] class, each has [2500 5000 5000 5000 5000 5000 5000 5000 5000 5000]
Epoch@@0
Files already downloaded and verified
TRAINING class wise acc@0 :: {0: [0.0044], 1: [0.1266], 2: [0.0834], 3: [0.069], 4: [0.1704], 5: [0.0692], 6: [0.2018], 7: [0.1212], 8: [0.304], 9: [0.1582]}
TRAIINING epoch@0 ::  acc@0.137  loss@2.403
[[  11  280  156  141  194  148  170  261  752  387]
 [   1  633  307  294  397  296  391  544 1346  791]
 [  12  548  417  320  735  337  749  538  825  519]
 [   3  580  408  345  608  399  614  625  873  545]
 [   2  535  456  303  852  300  950  588  568  446]
 [   4  594  413  327  611  346  600  615  882  608]
 [   4  554  494  304  953  262 1009  558  479  383]
 [   3  586  430  308  590  319  567  606 1016  575]
 [   5  601  302  228  335  288  294  579 1520  848]
 [   6  647  295  260  359  286  348  562 1446  791]]
TESTING class wise acc@0 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.13], 4: [0.006], 5: [0.0], 6: [0.89], 7: [0.07], 8: [0.0], 9: [0.662]}
TESTING epoch@0 ::  acc@0.176  loss@2.100
Epoch@@1
[[  0   0   0  67   5   0  87  54   0 787]
 [  0   0   0 105   5   0  96  91   0 703]
 [  0   0   0  84   6   0 698  42   0 170]
 [  0   0   0 130  19   0 700  45   0 106]
 [  0   0   0  52   6   0 833  28   0  81]
 [  0   0   0 162  10   0 703  37   0  88]
 [  0   0   0  42   6   0 890  16   0  46]
 [  0   0   0 151  14   0 582  70   0 183]
 [  0   0   0  66   7   0  47  67   0 813]
 [  0   0   0 122   6   0 126  84   0 662]]
TRAINING class wise acc@1 :: {0: [0.0], 1: [0.2422], 2: [0.0264], 3: [0.155], 4: [0.1952], 5: [0.3162], 6: [0.2762], 7: [0.2578], 8: [0.4606], 9: [0.291]}
TRAIINING epoch@1 ::  acc@0.234  loss@1.893
[[   0  509   16   74   13   91   29  274  798  696]
 [   0 1211   16   60    7   94   19  262 2079 1252]
 [   0  168  132  531  749  941  884  847  257  491]
 [   0   82  113  775  358 1418  678 1069  150  357]
 [   0  112  233  506  976  915 1202  578  143  335]
 [   0   57   90  846  337 1581  722  975  117  275]
 [   0   55  190  650  865 1079 1381  511   74  195]
 [   0  136  106  719  265 1216  539 1289  208  522]
 [   0 1214   19   51    9  109   18  241 2303 1036]
 [   0 1120   37  117   13  155   22  481 1600 1455]]
TESTING class wise acc@1 :: {0: [0.0], 1: [0.238], 2: [0.0], 3: [0.048], 4: [0.801], 5: [0.115], 6: [0.0], 7: [0.128], 8: [0.457], 9: [0.333]}
TESTING epoch@1 ::  acc@0.212  loss@2.073
Epoch@@2
[[  0 186   0  25  60  47   0 176 268 238]
 [  0 238   0  34  34  40   0 193 185 276]
 [  0  13   0  38 657 101   0 124   9  58]
 [  0   6   0  48 696 135   0  89   5  21]
 [  0   8   0  27 801  57   0  70   7  30]
 [  0   9   0  46 728 115   0  83   0  19]
 [  0   0   0  12 885  66   0  30   1   6]
 [  0   5   0  81 546 201   0 128   2  37]
 [  0 193   0  23  20  20   0 115 457 172]
 [  0 173   0  43  53  55   0 271  72 333]]
TRAINING class wise acc@2 :: {0: [0.0012], 1: [0.3428], 2: [0.056], 3: [0.1262], 4: [0.1336], 5: [0.4326], 6: [0.5546], 7: [0.345], 8: [0.5888], 9: [0.4552]}
TRAIINING epoch@2 ::  acc@0.320  loss@1.741
[[   3  393   45   36   22  114   35  285  890  677]
 [   2 1714   26   19   13   54   27  279  966 1900]
 [   3  109  280  468  525 1041 1002  949  145  478]
 [   1   52  181  631  383 1760  558 1083   40  311]
 [   5   75  232  490  668  997 1416  717   76  324]
 [   0   33  139  711  312 2163  329 1086   22  205]
 [   1   30  167  333  592  590 2773  324   31  159]
 [   0   61  121  533  214 1547  229 1725   23  547]
 [   6  851   34   16    7   64   25  234 2944  819]
 [   0 1390   25   26   22   91   13  566  591 2276]]
TESTING class wise acc@2 :: {0: [0.224], 1: [0.114], 2: [0.538], 3: [0.02], 4: [0.0], 5: [0.18], 6: [0.486], 7: [0.813], 8: [0.29], 9: [0.57]}
TESTING epoch@2 ::  acc@0.323  loss@1.739
Epoch@@3
[[224 144 210   2   0   0   2 139 165 114]
 [  9 114  35   0   0   0   2 195   4 641]
 [ 44   2 538  18   0  28  83 275   9   3]
 [  3   1 298  20   0 151  38 478   1  10]
 [ 16   6 538  19   0  64  95 250   5   7]
 [  4   1 168  19   0 180   4 622   0   2]
 [  6   0 351  19   0  56 486  80   0   2]
 [  3   0  93  10   0  55   3 813   0  23]
 [109 284  93   1   0   2   0  82 290 139]
 [ 17  82  41   1   0   0   0 281   8 570]]
TRAINING class wise acc@3 :: {0: [0.0736], 1: [0.4422], 2: [0.3416], 3: [0.1874], 4: [0.1662], 5: [0.444], 6: [0.6954], 7: [0.6222], 8: [0.757], 9: [0.5692]}
TRAIINING epoch@3 ::  acc@0.449  loss@1.438
[[ 184  209  426   33  111   28   29   88 1235  157]
 [  18 2211   75   24   44    8   60  168  439 1953]
 [ 121   54 1708  521  686  417  666  499  243   85]
 [  23   46  560  937  452 1365  679  730   77  131]
 [  52   44 1250  592  831  558  644  827  103   99]
 [   6   22  366  837  336 2220  231  894   30   58]
 [  19   62  505  394  202  153 3477   98   46   44]
 [  14   35  220  318  276  661   52 3111   35  278]
 [ 164  494  205   17   66   12   31   73 3785  153]
 [  27 1336   77   32   42   14   25  313  288 2846]]
TESTING class wise acc@3 :: {0: [0.229], 1: [0.395], 2: [0.354], 3: [0.028], 4: [0.067], 5: [0.0], 6: [0.099], 7: [0.772], 8: [0.629], 9: [0.883]}
TESTING epoch@3 ::  acc@0.346  loss@1.905
Epoch@@4
[[229  74 131   2  21   0   0  88 277 178]
 [  2 395   3   0   4   0   3   9   7 577]
 [ 61   4 354  22  72   0   4 402   9  72]
 [ 30  30  58  28  57   0   5 543   7 242]
 [ 39   5 227   5  67   0   2 580  10  65]
 [ 16   8  33   7  26   0   0 763   7 140]
 [  8  48 146 274  66   0  99 212   1 146]
 [ 10   2  10   0   1   0   0 772   7 198]
 [ 63 198  16   0   0   0   1  17 629  76]
 [  5  68   0   0   2   0   0  20  22 883]]
TRAINING class wise acc@4 :: {0: [0.2728], 1: [0.7632], 2: [0.4194], 3: [0.3042], 4: [0.3124], 5: [0.5168], 6: [0.719], 7: [0.7236], 8: [0.7868], 9: [0.7478]}
TRAIINING epoch@4 ::  acc@0.572  loss@1.150
[[ 682   68  313   31  207   11   22   70  914  182]
 [  21 3816   12   53   23    5   68   17  239  746]
 [ 241   25 2097  432 1022  262  473  250  135   63]
 [  33   60  421 1521  520 1299  637  353   56  100]
 [ 138   23 1314  521 1562  236  310  778   46   72]
 [  14   22  219 1006  411 2584  163  520   13   48]
 [  19   97  411  563  147   97 3595   23   34   14]
 [  45   10   82  236  484  328   19 3618   17  161]
 [ 326  251  114   26   74    3   42   23 3934  207]
 [  36  705   21   50   63    4   18  147  217 3739]]
TESTING class wise acc@4 :: {0: [0.534], 1: [0.933], 2: [0.168], 3: [0.194], 4: [0.361], 5: [0.467], 6: [0.351], 7: [0.875], 8: [0.803], 9: [0.693]}
TESTING epoch@4 ::  acc@0.538  loss@1.246
Epoch@@5
[[534  23  30   4  86   1   0  35 223  64]
 [  3 933   2   4   1   1   0   3  18  35]
 [ 99   2 168  28 476  16  14 170   9  18]
 [ 26  21  33 194 151 201  11 309   7  47]
 [ 49   2  20  19 361   9   0 510  10  20]
 [  8   4   7  68  75 467   2 356   5   8]
 [  4  24 119 277 120  27 351  64   4  10]
 [ 11   3   0   5  36  13   0 875   3  54]
 [ 82  43   4   6   7   1   2  10 803  42]
 [ 12 232   1   5   2   0   1  17  37 693]]
TRAINING class wise acc@5 :: {0: [0.538], 1: [0.8476], 2: [0.4498], 3: [0.4386], 4: [0.4868], 5: [0.5712], 6: [0.746], 7: [0.7506], 8: [0.8224], 9: [0.8456]}
TRAIINING epoch@5 ::  acc@0.656  loss@0.953
[[1345   24  252   60  125    3   15   65  435  176]
 [  26 4238   16   54    3    5   29    7  182  440]
 [ 279   12 2249  523 1009  174  436  161  113   44]
 [  46   46  384 2193  302 1160  448  275   50   96]
 [ 160    9 1056  390 2434  174  177  537   24   39]
 [   7   11  173 1212  288 2856   94  321    9   29]
 [  15   53  439  559   79   60 3730    8   42   15]
 [  48    5   76  315  460  230    9 3753    8   96]
 [ 324  176   84   60   15    0   35   13 4112  181]
 [  81  379   20   73   12    2    7   68  130 4228]]
TESTING class wise acc@5 :: {0: [0.494], 1: [0.897], 2: [0.394], 3: [0.266], 4: [0.594], 5: [0.756], 6: [0.658], 7: [0.749], 8: [0.897], 9: [0.858]}
TESTING epoch@5 ::  acc@0.656  loss@0.981
Epoch@@6
[[494  10  55  10  24   2   1  10 316  78]
 [  0 897   1   4   0   1   0   3  28  66]
 [ 75   4 394  72 255  76  38  21  51  14]
 [ 10   9  67 266  69 403  61  27  35  53]
 [ 25   0  95  47 594  78  24 115  12  10]
 [  2   3  30  90  49 756  12  35   8  15]
 [  2  29 100  87  32  38 658   2  40  12]
 [ 15   2  13  38  56  92   0 749   3  32]
 [ 24  32   9   7   3   3   1   3 897  21]
 [ 10  78   3   3   0   2   0  10  36 858]]
TRAINING class wise acc@6 :: {0: [0.594], 1: [0.8794], 2: [0.557], 3: [0.5462], 4: [0.636], 5: [0.5928], 6: [0.7708], 7: [0.7886], 8: [0.8606], 9: [0.872]}
TRAIINING epoch@6 ::  acc@0.716  loss@0.804
[[1485   14  331   50   43    2    8   75  329  163]
 [  13 4397   14   61    1    2   18    6  134  354]
 [ 294    8 2785  536  716  113  309  127   83   29]
 [  34   28  371 2731  227  912  358  220   37   82]
 [ 105    2  734  288 3180  149  107  405   10   20]
 [  10    7  130 1245  251 2964  108  264    2   19]
 [   5   40  425  474   92   55 3854    9   34   12]
 [  49    3   95  321  332  168    4 3943   14   71]
 [ 242  128  106   55    3    1   23   11 4303  128]
 [  78  274   30   79    0    4    4   54  117 4360]]
TESTING class wise acc@6 :: {0: [0.386], 1: [0.751], 2: [0.308], 3: [0.05], 4: [0.269], 5: [0.953], 6: [0.33], 7: [0.769], 8: [0.673], 9: [0.907]}
TESTING epoch@6 ::  acc@0.540  loss@1.457
Epoch@@7
[[386   8 151  44  21  53   0  79  76 182]
 [  1 751   0  50   0  11   2   3   2 180]
 [ 26   0 308  30  83 464  30  44   7   8]
 [  2   1  10  50   5 887   5  29   1  10]
 [  3   0  15   7 269 577   2 126   0   1]
 [  0   0   3  13   4 953   0  24   0   3]
 [  0   0  10  25   0 634 330   0   1   0]
 [  1   1   1  10   5 206   0 769   0   7]
 [ 19  80  19  48   0  15  11   9 673 126]
 [  0  21   3  32   0  12   0  18   7 907]]
TRAINING class wise acc@7 :: {0: [0.642], 1: [0.8936], 2: [0.6222], 3: [0.6272], 4: [0.6912], 5: [0.6318], 6: [0.7932], 7: [0.8162], 8: [0.8788], 9: [0.8882]}
TRAIINING epoch@7 ::  acc@0.754  loss@0.726
[[1605   13  316   59   45    2    4   53  262  141]
 [  15 4468   12   65    0    1   20    6  125  288]
 [ 262    6 3111  477  551  105  283  104   79   22]
 [  39   25  367 3136  185  734  250  177   27   60]
 [  79    1  632  247 3456  154   92  322   11    6]
 [   6    9  132 1147  200 3159   79  248    5   15]
 [   8   36  386  423   63   70 3966    3   33   12]
 [  61    3   83  312  244  128    7 4081    6   75]
 [ 213  114   94   53    2    0   21    2 4394  107]
 [  69  249   21   81    3    1    1   53   81 4441]]
TESTING class wise acc@7 :: {0: [0.775], 1: [0.934], 2: [0.483], 3: [0.31], 4: [0.378], 5: [0.148], 6: [0.44], 7: [0.576], 8: [0.922], 9: [0.846]}
TESTING epoch@7 ::  acc@0.581  loss@1.428
Epoch@@8
[[775   7  16   3   1   0   0   1 166  31]
 [  1 934   0   0   0   0   0   0  20  45]
 [196  17 483  55  40  15  15   8 131  40]
 [100 156  59 310  11   8   5  20  94 237]
 [114   5 148 100 378  76   2 119  19  39]
 [ 48  63  48 476   6 148   2  50  32 127]
 [ 17 222  93  95   4   4 440   1 101  23]
 [163  11  17  24   2   6   0 576  21 180]
 [ 35  22   1   0   0   0   0   0 922  20]
 [ 17  96   1   0   0   0   0   0  40 846]]
TRAINING class wise acc@8 :: {0: [0.6924], 1: [0.907], 2: [0.6688], 3: [0.645], 4: [0.7136], 5: [0.652], 6: [0.816], 7: [0.8316], 8: [0.889], 9: [0.8916]}
TRAIINING epoch@8 ::  acc@0.775  loss@0.661
[[1731    8  246   69   42    0    3   52  243  106]
 [  15 4535    9   59    1    1   18    2  112  248]
 [ 251    5 3344  438  504   72  242   76   58   10]
 [  38   28  313 3225  180  711  240  161   28   76]
 [  71    0  551  261 3568  141   86  309    7    6]
 [   8    7  111 1085  200 3260   79  230    3   17]
 [   6   37  332  388   57   61 4080    2   31    6]
 [  51    1   80  270  219  134    3 4158    8   76]
 [ 182  105   74   65    0    0   21    5 4445  103]
 [  85  226   13   94    1    1    1   45   76 4458]]
TESTING class wise acc@8 :: {0: [0.788], 1: [0.845], 2: [0.712], 3: [0.665], 4: [0.661], 5: [0.54], 6: [0.689], 7: [0.882], 8: [0.905], 9: [0.722]}
TESTING epoch@8 ::  acc@0.741  loss@0.810
Epoch@@9
[[788   0  83  11   5   0   0  15  90   8]
 [ 18 845   1  15   0   0   2   1  91  27]
 [ 72   1 712  87  67  12  13  27   9   0]
 [ 20   4 111 665  32  57  24  70  12   5]
 [  8   0 174  72 661   3   8  72   2   0]
 [  7   1  46 256  38 540   5 104   2   1]
 [  6   1 157 121   8   1 689   6  11   0]
 [ 20   0  11  43  37   5   0 882   1   1]
 [ 60   4  14   9   0   0   1   4 905   3]
 [ 79  86  10  21   1   0   0  28  53 722]]
TRAINING class wise acc@9 :: {0: [0.7464], 1: [0.9192], 2: [0.7092], 3: [0.6952], 4: [0.7678], 5: [0.68], 6: [0.8426], 7: [0.8552], 8: [0.9156], 9: [0.9056]}
TRAIINING epoch@9 ::  acc@0.807  loss@0.570
[[1866    6  224   58   28    0    3   43  198   74]
 [   8 4596    5   57    0    0   10    0   90  234]
 [ 242    2 3546  398  408   58  211   76   49   10]
 [  27   16  270 3476  167  615  196  156   18   59]
 [  47    0  454  221 3839  123   67  242    5    2]
 [   4    4   81 1037  195 3400   57  208    4   10]
 [   5   21  303  326   52   47 4213    5   24    4]
 [  40    1   60  277  200  101    2 4276    2   41]
 [ 138   74   60   46    1    0   20    3 4578   80]
 [  62  213   12   67    1    3    4   45   65 4528]]
TESTING class wise acc@9 :: {0: [0.647], 1: [0.864], 2: [0.547], 3: [0.632], 4: [0.694], 5: [0.386], 6: [0.891], 7: [0.851], 8: [0.955], 9: [0.87]}
TESTING epoch@9 ::  acc@0.734  loss@0.843
Epoch@@10
[[647   4  43  23  13   0   7  21 220  22]
 [  3 864   0   6   0   0   5   0  45  77]
 [ 50   1 547  77  86   4 151  26  56   2]
 [ 13   8  39 632  47  36 112  65  30  18]
 [ 15   1  56  70 694  18  46  91   9   0]
 [  3   0  26 334  38 386  98  88  17  10]
 [  1   2  20  46  18   2 891   5  15   0]
 [ 25   2   8  63  17  10   8 851   3  13]
 [ 11   9   4   3   2   0   3   2 955  11]
 [ 16  36   1  11   0   0   2  11  53 870]]
TRAINING class wise acc@10 :: {0: [0.7624], 1: [0.935], 2: [0.754], 3: [0.7414], 4: [0.8052], 5: [0.7062], 6: [0.8604], 7: [0.8796], 8: [0.9184], 9: [0.9224]}
TRAIINING epoch@10 ::  acc@0.832  loss@0.508
[[1906    1  210   57   28    0    2   43  168   85]
 [   6 4675    6   35    0    1   14    0   85  178]
 [ 213    3 3770  325  355   44  190   43   52    5]
 [  35   17  241 3707  136  511  180  115   21   37]
 [  40    0  374  192 4026  117   51  193    6    1]
 [   6    2   70  956  176 3531   72  178    1    8]
 [   5   21  259  287   55   39 4302    4   25    3]
 [  49    1   36  243  169   81    0 4398    0   23]
 [ 150   52   60   37    1    0   19    0 4592   89]
 [  66  163    4   66    2    0    1   21   65 4612]]
TESTING class wise acc@10 :: {0: [0.702], 1: [0.823], 2: [0.775], 3: [0.49], 4: [0.709], 5: [0.707], 6: [0.736], 7: [0.842], 8: [0.939], 9: [0.884]}
TESTING epoch@10 ::  acc@0.761  loss@0.751
Epoch@@11
[[702   2 118   8   8   0   1  13 137  11]
 [  5 823   3   5   0   2   1   0  71  90]
 [ 38   0 775  45  54  27  15  23  23   0]
 [ 12   1 128 490  45 200  23  74  17  10]
 [ 12   1 201  18 709  14   9  31   5   0]
 [  5   0  38  96  64 707   4  78   6   2]
 [  3   0 145  66  12  19 736   6  12   1]
 [ 26   0  16  12  85  12   1 842   1   5]
 [ 24   1  15   4   0   1   0   2 939  14]
 [ 32  23   4   7   0   1   0   5  44 884]]
TRAINING class wise acc@11 :: {0: [0.7824], 1: [0.9318], 2: [0.774], 3: [0.7612], 4: [0.8194], 5: [0.73], 6: [0.8778], 7: [0.8892], 8: [0.929], 9: [0.9248]}
TRAIINING epoch@11 ::  acc@0.845  loss@0.470
[[1956    3  175   49   29    1    1   40  165   81]
 [   6 4659    3   44    0    0   14    1   83  190]
 [ 187    5 3870  283  340   37  177   42   53    6]
 [  26   16  227 3806  107  475  167  121   16   39]
 [  28    0  346  185 4097  115   39  183    5    2]
 [   2    0   68  900  158 3650   38  175    1    8]
 [   4   22  202  267   41   42 4389    6   23    4]
 [  35    1   43  171  167  103    2 4446    0   32]
 [ 118   59   54   42    0    0    9    1 4645   72]
 [  55  155    7   60    2    0    3   22   72 4624]]
TESTING class wise acc@11 :: {0: [0.716], 1: [0.892], 2: [0.646], 3: [0.511], 4: [0.73], 5: [0.36], 6: [0.788], 7: [0.978], 8: [0.875], 9: [0.873]}
TESTING epoch@11 ::  acc@0.737  loss@0.884
Epoch@@12
[[716   2  81   9  20   0   3  86  53  30]
 [  6 892   3  12   0   0   9   6  19  53]
 [ 55   0 646  19 155   4  17 101   2   1]
 [ 13   1  54 511  73  20  29 288   2   9]
 [  6   0  55  16 730   1  14 177   1   0]
 [  1   0  29 138  96 360   6 369   1   0]
 [  3   0  86  60  41   0 788  19   3   0]
 [  3   0   0   1  17   0   0 978   0   1]
 [ 46   9  27   4   4   0   0  12 875  23]
 [ 10  43   6  16   1   0   4  37  10 873]]
TRAINING class wise acc@12 :: {0: [0.8176], 1: [0.9406], 2: [0.801], 3: [0.7808], 4: [0.8424], 5: [0.7534], 6: [0.8862], 7: [0.9012], 8: [0.9398], 9: [0.941]}
TRAIINING epoch@12 ::  acc@0.863  loss@0.413
[[2044    1  171   37   19    2    0   32  128   66]
 [   8 4703    1   41    0    0   13    0   74  160]
 [ 189    1 4005  227  298   33  169   37   33    8]
 [  24   12  179 3904  117  448  151  111   12   42]
 [  34    1  313  138 4212  111   31  157    2    1]
 [   3    1   45  809  161 3767   45  164    4    1]
 [   2   18  223  237   26   35 4431    2   22    4]
 [  26    0   33  181  151   81    0 4506    0   22]
 [ 123   47   32   32    0    0   12    0 4699   55]
 [  45  132    7   47    0    1    0   17   46 4705]]
TESTING class wise acc@12 :: {0: [0.773], 1: [0.933], 2: [0.737], 3: [0.56], 4: [0.683], 5: [0.327], 6: [0.859], 7: [0.772], 8: [0.924], 9: [0.886]}
TESTING epoch@12 ::  acc@0.745  loss@0.903
Epoch@@13
[[773   5  44   7   2   0   2   4 118  45]
 [  2 933   0   1   0   0   1   0  18  45]
 [ 59   7 737  35  39   2  44   8  60   9]
 [ 26  30 129 560  28   6  93  23  55  50]
 [ 47   2 141  30 683   1  19  61  13   3]
 [ 14   8  49 367  39 327  87  70  24  15]
 [  6  11  67  13  13   0 859   1  28   2]
 [ 67   0  24  45  25   1   2 772   9  55]
 [ 26  19   3   2   0   0   1   0 924  25]
 [ 16  59   3   4   0   0   0   0  32 886]]
TRAINING class wise acc@13 :: {0: [0.8428], 1: [0.9524], 2: [0.8262], 3: [0.803], 4: [0.8672], 5: [0.7808], 6: [0.902], 7: [0.9128], 8: [0.9484], 9: [0.943]}
TRAIINING epoch@13 ::  acc@0.880  loss@0.360
[[2107    1  164   31   14    0    0   37   99   47]
 [   5 4762    2   26    0    0    9    0   53  143]
 [ 170    1 4131  223  262   24  121   32   35    1]
 [  24   12  171 4015   79  425  131  104   14   25]
 [  22    0  272  108 4336   90   38  133    0    1]
 [   3    1   48  749  122 3904   45  126    1    1]
 [   3   13  185  200   29   42 4510    2   16    0]
 [  24    0   27  159  128   73    0 4564    0   25]
 [  82   49   37   26    0    0    9    0 4742   55]
 [  51  109    4   52    1    0    1   12   55 4715]]
TESTING class wise acc@13 :: {0: [0.717], 1: [0.896], 2: [0.747], 3: [0.558], 4: [0.784], 5: [0.776], 6: [0.937], 7: [0.73], 8: [0.905], 9: [0.853]}
TESTING epoch@13 ::  acc@0.790  loss@0.765
Epoch@@14
[[717   5 114  22  15   0   5   6  94  22]
 [  8 896   3  12   0   0   6   1  16  58]
 [ 34   0 747  33  44  24 103   5   9   1]
 [  3   2  95 558  58 147 118   7   4   8]
 [  4   0 110  26 784  15  49  11   1   0]
 [  3   0  35  91  46 776  37  12   0   0]
 [  0   1  28  14  11   5 937   1   3   0]
 [ 12   0  27  48 106  69   5 730   0   3]
 [ 23  14  22  11   1   1   6   1 905  16]
 [ 15  50   8  37   0   5   7   6  19 853]]
TRAINING class wise acc@14 :: {0: [0.868], 1: [0.9578], 2: [0.845], 3: [0.8138], 4: [0.8788], 5: [0.7906], 6: [0.9102], 7: [0.9254], 8: [0.9472], 9: [0.9454]}
TRAIINING epoch@14 ::  acc@0.889  loss@0.334
[[2170    2  128   19   12    3    0   14   95   57]
 [   2 4789    2   29    0    0    8    0   48  122]
 [ 146    0 4225  202  214   31  120   21   36    5]
 [  20   10  140 4069   82  422  125   75   16   41]
 [  25    0  225   97 4394  101   25  126    5    2]
 [   4    1   38  714  119 3953   44  126    0    1]
 [   1   11  167  171   21   48 4551    2   25    3]
 [  20    0   16  139  108   71    0 4627    1   18]
 [  85   43   41   22    1    0   17    0 4736   55]
 [  35  110    4   53    0    0    1   21   49 4727]]
TESTING class wise acc@14 :: {0: [0.68], 1: [0.914], 2: [0.819], 3: [0.622], 4: [0.808], 5: [0.801], 6: [0.762], 7: [0.825], 8: [0.9], 9: [0.868]}
TESTING epoch@14 ::  acc@0.800  loss@0.682
Epoch@@15
[[680   2 165  31  12   2   1  15  51  41]
 [  5 914   6  14   0   0   5   2  14  40]
 [ 25   0 819  37  42  37  27  11   2   0]
 [  5   1 101 622  25 201  15  23   2   5]
 [  2   0 116  24 808  27   3  20   0   0]
 [  0   0  49  99  34 801   2  14   0   1]
 [  1   0 105  91  13  24 762   1   2   1]
 [  7   0  20  29  64  53   0 825   0   2]
 [ 20  12  35  15   1   2   2   1 900  12]
 [ 18  50   7  24   0   0   1  12  20 868]]
TRAINING class wise acc@15 :: {0: [0.854], 1: [0.96], 2: [0.861], 3: [0.8388], 4: [0.8936], 5: [0.811], 6: [0.927], 7: [0.9358], 8: [0.9522], 9: [0.9584]}
TRAIINING epoch@15 ::  acc@0.902  loss@0.299
[[2135    1  129   34   28    2    0   20  102   49]
 [   1 4800    0   27    0    0    8    0   51  113]
 [ 150    1 4305  177  181   14  121   15   34    2]
 [  19    8  120 4194   55  383  103   84   14   20]
 [  24    0  229   69 4468   90   13  106    1    0]
 [   1    1   28  651  110 4055   43  109    0    2]
 [   3    8  143  151   13   32 4635    1   14    0]
 [  17    0   19   98  109   65    0 4679    1   12]
 [  79   42   47   12    0    0    9    2 4761   48]
 [  37   88    0   29    1    0    1    8   44 4792]]
TESTING class wise acc@15 :: {0: [0.691], 1: [0.937], 2: [0.597], 3: [0.395], 4: [0.598], 5: [0.93], 6: [0.733], 7: [0.724], 8: [0.877], 9: [0.868]}
TESTING epoch@15 ::  acc@0.735  loss@1.286
Epoch@@16
[[691  17  51  29   4  12   3  16  94  83]
 [  0 937   0  15   0   2   2   0  10  34]
 [ 57   3 597  73  30 180  29  12  14   5]
 [  8   7  22 395  13 517  13  13   3   9]
 [ 15   0  76  28 598 227  13  40   1   2]
 [  0   1   3  43   9 930   1  11   1   1]
 [  1   7  29  41   6 178 733   0   4   1]
 [  7   1   2  35  12 206   1 724   0  12]
 [ 20  21  14  19   0  13   5   4 877  27]
 [  3  63   2  35   0  14   0   4  11 868]]
TRAINING class wise acc@16 :: {0: [0.8912], 1: [0.9634], 2: [0.8766], 3: [0.8494], 4: [0.9034], 5: [0.8282], 6: [0.9256], 7: [0.9356], 8: [0.9592], 9: [0.9586]}
TRAIINING epoch@16 ::  acc@0.910  loss@0.273
[[2228    2  108   16   18    0    0   20   76   32]
 [   0 4817    1   27    0    0    5    0   47  103]
 [ 122    1 4383  144  155   24  108   22   40    1]
 [  12   11  128 4247   45  345  106   60   17   29]
 [  26    0  182   71 4517   78   12  112    1    1]
 [   1    0   24  602  104 4141   33   94    0    1]
 [   0   11  147  154   16   28 4628    0   15    1]
 [  17    0   10  108   99   68    1 4678    1   18]
 [  64   34   44   19    0    0    8    0 4796   35]
 [  26   98    1   42    0    0    0   14   26 4793]]
TESTING class wise acc@16 :: {0: [0.828], 1: [0.905], 2: [0.649], 3: [0.57], 4: [0.846], 5: [0.835], 6: [0.89], 7: [0.717], 8: [0.936], 9: [0.893]}
TESTING epoch@16 ::  acc@0.807  loss@0.753
Epoch@@17
[[828   9  32  16   9   0   2   2  71  31]
 [  2 905   0   8   0   0   1   1  34  49]
 [ 59   0 649  53  86  37  85   4  26   1]
 [ 17   7  38 570  41 243  51   7  13  13]
 [ 15   1  36  34 846  30  23  10   4   1]
 [  3   2  13  65  38 835  23  10   5   6]
 [  3   2  18  30  15  20 890   1  19   2]
 [ 23   1   6  30 138  71   1 717   7   6]
 [ 31   9   4   5   1   0   3   0 936  11]
 [ 16  34   3   8   0   2   1   1  42 893]]
TRAINING class wise acc@17 :: {0: [0.8948], 1: [0.9632], 2: [0.88], 3: [0.8742], 4: [0.9126], 5: [0.8526], 6: [0.9276], 7: [0.9438], 8: [0.9602], 9: [0.9578]}
TRAIINING epoch@17 ::  acc@0.918  loss@0.247
[[2237    0  106    9   14    0    1   14   76   43]
 [   3 4816    2   24    0    0    8    0   45  102]
 [ 123    3 4400  151  167    5  106   13   30    2]
 [  11    9   98 4371   41  302   90   50    5   23]
 [  20    0  170   53 4563   74   13  105    1    1]
 [   1    0   23  498   87 4263   32   94    1    1]
 [   1   10  131  160   17   30 4638    1   10    2]
 [  16    0    4   91  102   53    0 4719    0   15]
 [  60   40   33   10    0    0   11    0 4801   45]
 [  28   89    1   35    0    0    1   18   39 4789]]
TESTING class wise acc@17 :: {0: [0.644], 1: [0.941], 2: [0.763], 3: [0.706], 4: [0.727], 5: [0.508], 6: [0.604], 7: [0.934], 8: [0.952], 9: [0.855]}
TESTING epoch@17 ::  acc@0.763  loss@0.958
Epoch@@18
[[644   9  51  15   6   0   0  14 196  65]
 [  1 941   1   0   0   0   0   0  26  31]
 [ 45   4 763  73  32   8   7  25  38   5]
 [  7  16  65 706  37  29   8  80  28  24]
 [ 10   2 115  35 727   6   4  89  12   0]
 [  4   3  41 296  28 508   1 100  13   6]
 [  5  22 180  93  16   2 604   7  67   4]
 [  8   0   6  20  21   2   0 934   2   7]
 [ 11  15   4   1   0   0   0   2 952  15]
 [  7  93   1   2   0   0   0  11  31 855]]
TRAINING class wise acc@18 :: {0: [0.8944], 1: [0.9674], 2: [0.8898], 3: [0.8752], 4: [0.9174], 5: [0.8528], 6: [0.941], 7: [0.9532], 8: [0.9626], 9: [0.967]}
TRAIINING epoch@18 ::  acc@0.924  loss@0.240
[[2236    1  101   15   11    0    1   20   74   41]
 [   0 4837    0   15    0    0    7    0   48   93]
 [  99    0 4449  144  170   18   87    7   25    1]
 [  15   14  102 4376   34  296   85   50    6   22]
 [  18    0  157   53 4587   80   14   89    2    0]
 [   1    2   31  497   89 4264   33   83    0    0]
 [   1   11  111  118   14   24 4705    0   16    0]
 [  15    0    8   63   73   54    0 4766    0   21]
 [  63   33   39   14    0    0    8    1 4813   29]
 [  27   67    1   32    0    0    0   14   24 4835]]
TESTING class wise acc@18 :: {0: [0.736], 1: [0.892], 2: [0.634], 3: [0.634], 4: [0.686], 5: [0.719], 6: [0.847], 7: [0.946], 8: [0.806], 9: [0.815]}
TESTING epoch@18 ::  acc@0.771  loss@0.966
Epoch@@19
[[736   4  40  47  19   1   7  70  39  37]
 [  4 892   3  25   0   0  10   7   8  51]
 [ 58   1 634 101  52  30  44  77   3   0]
 [ 10   3  36 634  28 128  30 119   5   7]
 [  9   0  83  33 686  49  23 117   0   0]
 [  4   0  14 111  12 719  12 126   1   1]
 [  1   3  41  60  14  25 847   6   2   1]
 [  6   0   0  15  16  16   0 946   0   1]
 [ 43  25  24  29   3   1  23  15 806  31]
 [ 13  83   4  33   1   1   5  38   7 815]]
TRAINING class wise acc@19 :: {0: [0.9008], 1: [0.9664], 2: [0.8874], 3: [0.8644], 4: [0.916], 5: [0.8468], 6: [0.9318], 7: [0.9458], 8: [0.9548], 9: [0.9582]}
TRAIINING epoch@19 ::  acc@0.918  loss@0.251
[[2252    0   82   17   14    1    0   19   69   46]
 [   1 4832    1   18    0    0    8    0   41   99]
 [ 113    1 4437  141  144   22  101   11   28    2]
 [   9   12  105 4322   53  315   76   55   15   38]
 [  30    0  146   44 4580   91   11   98    0    0]
 [   1    2   44  498   99 4234   28   89    0    5]
 [   1   13  132  132    6   36 4659    0   20    1]
 [  18    0    6   78   95   55    1 4729    0   18]
 [  65   42   43   18    0    0   16    0 4774   42]
 [  37   83    1   44    1    1    0    7   35 4791]]
TESTING class wise acc@19 :: {0: [0.724], 1: [0.907], 2: [0.718], 3: [0.678], 4: [0.793], 5: [0.809], 6: [0.878], 7: [0.905], 8: [0.899], 9: [0.91]}
TESTING epoch@19 ::  acc@0.822  loss@0.718
Epoch@@20
[[724   5  68  34  25   0   6  31  51  56]
 [  1 907   1  13   1   0   9   1  11  56]
 [ 35   0 718  63  77  36  43  20   5   3]
 [  4   0  39 678  32 162  43  33   1   8]
 [  1   0  27  32 793  66   7  73   1   0]
 [  1   0  11 113  14 809  12  37   1   2]
 [  2   0  31  39  17  27 878   4   1   1]
 [  4   0   5  30  13  39   1 905   0   3]
 [ 29  12  15  16   2   1  10   1 899  15]
 [  5  43   2  15   1   0   0   9  15 910]]
TRAINING class wise acc@20 :: {0: [0.924], 1: [0.9758], 2: [0.913], 3: [0.9058], 4: [0.9306], 5: [0.8878], 6: [0.9526], 7: [0.9632], 8: [0.9712], 9: [0.971]}
TRAIINING epoch@20 ::  acc@0.940  loss@0.189
[[2310    0   74   10   12    0    0    9   52   33]
 [   0 4879    1   14    0    0    6    0   31   69]
 [  89    1 4565   85  137   15   80    8   18    2]
 [   3    8   69 4529   26  223   69   46    4   23]
 [  16    0  141   28 4653   75    6   80    1    0]
 [   0    0   18  382   69 4439   25   65    2    0]
 [   0   12   97   91    8   17 4763    0   12    0]
 [   6    0    7   43   77   38    0 4816    0   13]
 [  56   24   17   13    1    0   14    0 4856   19]
 [  21   63    0   32    0    0    0   12   17 4855]]
TESTING class wise acc@20 :: {0: [0.72], 1: [0.833], 2: [0.805], 3: [0.68], 4: [0.756], 5: [0.657], 6: [0.663], 7: [0.863], 8: [0.935], 9: [0.949]}
TESTING epoch@20 ::  acc@0.786  loss@0.888
Epoch@@21
[[720   4  60  16   2   0   0  12 124  62]
 [  1 833   0   5   0   0   2   0  33 126]
 [ 46   0 805  42  45  15  12  10  22   3]
 [ 13   3 108 680  35  73  15  28  31  14]
 [ 16   0 121  33 756  16   3  45   8   2]
 [  6   1  52 171  36 657   6  57  10   4]
 [  4   1 133  90  27  16 663   7  58   1]
 [ 25   0  24  41  27  12   0 863   1   7]
 [ 12   4   3   7   1   1   0   1 935  36]
 [  9  16   3   5   0   0   0   2  16 949]]
TRAINING class wise acc@21 :: {0: [0.9228], 1: [0.9708], 2: [0.906], 3: [0.893], 4: [0.9236], 5: [0.8792], 6: [0.9414], 7: [0.9516], 8: [0.9682], 9: [0.9706]}
TRAIINING epoch@21 ::  acc@0.933  loss@0.208
[[2307    0   82    8    8    0    0   15   48   32]
 [   0 4854    0   17    0    0    7    0   45   77]
 [  84    0 4530  113  139   22   70   10   29    3]
 [   5    9   97 4465   29  243   78   51   10   13]
 [   7    0  181   25 4618   70    8   90    1    0]
 [   1    0   27  387   77 4396   38   72    1    1]
 [   0    8  120  111    6   28 4707    1   19    0]
 [  27    0   12   60   83   48    0 4758    0   12]
 [  52   32   22   17    0    2    7    0 4841   27]
 [  25   55    1   27    0    0    0   11   28 4853]]
TESTING class wise acc@21 :: {0: [0.886], 1: [0.876], 2: [0.757], 3: [0.74], 4: [0.792], 5: [0.729], 6: [0.877], 7: [0.8], 8: [0.875], 9: [0.89]}
TESTING epoch@21 ::  acc@0.822  loss@0.741
Epoch@@22
[[886   2  27  26   6   0   3   8  27  15]
 [ 14 876   1  15   0   0   3   1  25  65]
 [ 71   0 757  60  29  19  45  11   6   2]
 [ 14   0  53 740  40  75  46  20   4   8]
 [ 14   0  85  50 792  27  17  15   0   0]
 [  6   0  31 170  31 729  14  17   0   2]
 [  5   2  40  54   9   9 877   0   3   1]
 [ 16   0   9  57  65  49   2 800   0   2]
 [ 71   8   9   9   0   0   3   1 875  24]
 [ 26  41   4  17   1   0   0   2  19 890]]
TRAINING class wise acc@22 :: {0: [0.9436], 1: [0.9824], 2: [0.9314], 3: [0.9224], 4: [0.9498], 5: [0.9178], 6: [0.961], 7: [0.97], 8: [0.9796], 9: [0.9832]}
TRAIINING epoch@22 ::  acc@0.955  loss@0.140
[[2359    0   60    9    9    0    0   11   33   19]
 [   0 4912    0   18    0    0    4    0   24   42]
 [  75    1 4657   71   98   12   59    4   23    0]
 [   5   10   59 4612   15  185   64   33    3   14]
 [  14    0   99   19 4749   52    5   62    0    0]
 [   0    0   18  268   63 4589   19   43    0    0]
 [   1    6   68   84    6   22 4805    0    8    0]
 [  11    0    1   38   67   25    0 4850    0    8]
 [  31   18   21    7    0    0    9    0 4898   16]
 [  12   38    0   17    0    0    0    5   12 4916]]
TESTING class wise acc@22 :: {0: [0.712], 1: [0.951], 2: [0.826], 3: [0.76], 4: [0.729], 5: [0.747], 6: [0.879], 7: [0.769], 8: [0.935], 9: [0.857]}
TESTING epoch@22 ::  acc@0.817  loss@0.813
Epoch@@23
[[712   5 111  28   9   0   5  13  87  30]
 [  2 951   0   4   0   0   1   0  18  24]
 [ 17   0 826  53  28  22  43   2   9   0]
 [  8   1  68 760  18  80  48   5  10   2]
 [  1   0 133  57 729  45  17  15   2   1]
 [  3   1  35 165  16 747  22   7   2   2]
 [  1   1  43  57   2   7 879   1   8   1]
 [  4   0  14  89  55  59   3 769   1   6]
 [ 23  12  11  10   0   1   4   1 935   3]
 [  6  72   2  24   1   0   0   4  34 857]]
TRAINING class wise acc@23 :: {0: [0.9432], 1: [0.982], 2: [0.9338], 3: [0.9292], 4: [0.9502], 5: [0.9122], 6: [0.9634], 7: [0.9714], 8: [0.9778], 9: [0.9812]}
TRAIINING epoch@23 ::  acc@0.955  loss@0.136
[[2358    0   60    8    3    0    0   10   37   24]
 [   0 4910    1   15    0    0    5    0   23   46]
 [  71    0 4669   69   99    5   59    2   25    1]
 [   5    8   56 4646   15  172   45   29    8   16]
 [   8    0  102   21 4751   50    3   65    0    0]
 [   1    0   11  298   58 4561   23   47    1    0]
 [   0    7   73   68    5   16 4817    0   14    0]
 [  10    0    7   35   51   34    0 4857    0    6]
 [  29   17   19   13    0    1    7    0 4889   25]
 [  23   35    0   18    0    0    0    4   14 4906]]
TESTING class wise acc@23 :: {0: [0.75], 1: [0.918], 2: [0.807], 3: [0.553], 4: [0.695], 5: [0.722], 6: [0.921], 7: [0.885], 8: [0.892], 9: [0.917]}
TESTING epoch@23 ::  acc@0.806  loss@0.914
Epoch@@24
[[750   4 123  11   6   0  11  10  56  29]
 [  3 918   4   4   0   0   1   0  13  57]
 [ 17   2 807  20  24  13  96  12   7   2]
 [ 13   6 113 553  34 149  74  42   3  13]
 [  5   0 128  21 695  45  50  54   2   0]
 [  5   3  54  86  25 722  33  69   0   3]
 [  2   7  30  16   3  14 921   5   1   1]
 [  8   0  22  27  28  16   5 885   0   9]
 [ 29  18  22   4   0   0   4   2 892  29]
 [ 16  36   5   8   0   0   1   3  14 917]]
TRAINING class wise acc@24 :: {0: [0.9428], 1: [0.9824], 2: [0.9368], 3: [0.9288], 4: [0.948], 5: [0.9236], 6: [0.964], 7: [0.967], 8: [0.9772], 9: [0.9798]}
TRAIINING epoch@24 ::  acc@0.956  loss@0.136
[[2357    0   51    5    6    0    0    8   46   27]
 [   0 4912    1   15    0    0    2    0   18   52]
 [  53    0 4684   73   95    3   65    3   23    1]
 [   4   10   71 4644   14  161   45   27    5   19]
 [   9    0  120   14 4740   58    5   54    0    0]
 [   0    0    7  255   57 4618   18   45    0    0]
 [   0    4   72   67    6   18 4820    0   13    0]
 [  13    0    4   43   60   36    0 4835    0    9]
 [  39   18   20   12    0    0   11    0 4886   14]
 [  18   37    1   21    0    0    1    8   15 4899]]
TESTING class wise acc@24 :: {0: [0.729], 1: [0.879], 2: [0.792], 3: [0.639], 4: [0.734], 5: [0.768], 6: [0.916], 7: [0.815], 8: [0.946], 9: [0.896]}
TESTING epoch@24 ::  acc@0.811  loss@0.889
Epoch@@25
[[729   2  88  16   5   1   7  10 113  29]
 [  3 879   4   7   0   0   6   0  47  54]
 [ 22   0 792  30  43  27  67   5  12   2]
 [  9   0  96 639  26 131  76   7   7   9]
 [  9   0 120  36 734  39  35  24   3   0]
 [  2   0  33 106  25 768  43  18   5   0]
 [  0   0  40  23   6   3 916   1  11   0]
 [  9   0  24  50  41  50   1 815   3   7]
 [ 13   3  19   4   0   0   6   0 946   9]
 [  9  30   6  13   0   1   1   2  42 896]]
TRAINING class wise acc@25 :: {0: [0.9496], 1: [0.9822], 2: [0.9412], 3: [0.9382], 4: [0.9598], 5: [0.924], 6: [0.965], 7: [0.9734], 8: [0.9786], 9: [0.9816]}
TRAIINING epoch@25 ::  acc@0.960  loss@0.124
[[2374    1   53    3    7    0    0    3   42   17]
 [   1 4911    0   11    0    0    8    0   27   42]
 [  56    1 4706   60   87   10   60    3   17    0]
 [   1    7   47 4691   10  158   43   22    8   13]
 [   5    0   87   16 4799   45    4   44    0    0]
 [   1    0   11  240   57 4620   20   51    0    0]
 [   0    7   81   61    0   16 4825    0   10    0]
 [  10    0    6   38   39   34    1 4867    0    5]
 [  31   22   16    8    0    0   10    0 4893   20]
 [  10   39    1   21    0    0    0    8   13 4908]]
TESTING class wise acc@25 :: {0: [0.825], 1: [0.881], 2: [0.734], 3: [0.684], 4: [0.753], 5: [0.618], 6: [0.876], 7: [0.907], 8: [0.922], 9: [0.918]}
TESTING epoch@25 ::  acc@0.812  loss@0.889
Epoch@@26
[[825   5  42  12   7   0   2  11  68  28]
 [  8 881   0   5   0   0   2   2  35  67]
 [ 61   1 734  59  38  18  47  21  17   4]
 [ 17   4  63 684  25  62  66  34  19  26]
 [  9   0  90  39 753  28  17  60   3   1]
 [  7   2  25 220  21 618  30  66   5   6]
 [  4   3  46  32   7   3 876   4  20   5]
 [ 16   0   7  30  20  11   3 907   0   6]
 [ 42   7   5   4   0   0   0   1 922  19]
 [ 22  32   2   8   0   0   0   6  12 918]]
TRAINING class wise acc@26 :: {0: [0.9456], 1: [0.9808], 2: [0.9464], 3: [0.938], 4: [0.9572], 5: [0.928], 6: [0.967], 7: [0.9734], 8: [0.9804], 9: [0.9762]}
TRAIINING epoch@26 ::  acc@0.960  loss@0.124
[[2364    0   51    3   10    0    0    9   41   22]
 [   0 4904    1   10    0    0    5    0   24   56]
 [  64    1 4732   68   71    6   37    2   16    3]
 [   1    7   46 4690   12  158   46   22    3   15]
 [  15    0   81   20 4786   46    1   51    0    0]
 [   1    0    4  233   55 4640   19   48    0    0]
 [   0   10   57   63    3   20 4835    0   11    1]
 [   7    0    4   38   47   32    0 4867    2    3]
 [  29   16   17    7    0    0   10    0 4902   19]
 [  18   58    1   17    0    0    0    8   17 4881]]
TESTING class wise acc@26 :: {0: [0.79], 1: [0.921], 2: [0.757], 3: [0.686], 4: [0.813], 5: [0.713], 6: [0.909], 7: [0.873], 8: [0.921], 9: [0.903]}
TESTING epoch@26 ::  acc@0.829  loss@0.778
Epoch@@27
[[790   3  83  12  19   1   8   6  56  22]
 [  1 921   1   4   0   0   3   1  22  47]
 [ 36   0 757  27  72  29  53  15   9   2]
 [ 10   2  66 686  51  89  39  27  14  16]
 [  6   0  68  27 813  32  23  29   2   0]
 [  5   0  34 137  49 713   9  49   2   2]
 [  2   1  36  25   7  10 909   5   4   1]
 [ 20   0  14  23  54  10   1 873   0   5]
 [ 30   9  17   4   1   0   3   1 921  14]
 [ 20  38   5   8   2   0   1   1  22 903]]
TRAINING class wise acc@27 :: {0: [0.952], 1: [0.9858], 2: [0.949], 3: [0.9442], 4: [0.963], 5: [0.9392], 6: [0.971], 7: [0.9776], 8: [0.9822], 9: [0.982]}
TRAIINING epoch@27 ::  acc@0.965  loss@0.109
[[2380    0   47    5    7    0    0    9   30   22]
 [   0 4929    0    6    0    0    7    0   17   41]
 [  49    0 4745   59   73    7   47    3   16    1]
 [   4   10   49 4721    7  132   41   22    0   14]
 [  10    0   74   11 4815   42    3   45    0    0]
 [   0    0   12  180   48 4696   19   45    0    0]
 [   0    6   47   53    4   20 4855    0   15    0]
 [   5    0    4   28   39   30    0 4888    0    6]
 [  28   13   12    6    0    0   10    0 4911   20]
 [  18   33    1   17    0    0    0    2   19 4910]]
TESTING class wise acc@27 :: {0: [0.741], 1: [0.847], 2: [0.904], 3: [0.579], 4: [0.644], 5: [0.725], 6: [0.892], 7: [0.707], 8: [0.849], 9: [0.736]}
TESTING epoch@27 ::  acc@0.762  loss@1.479
Epoch@@28
[[741   2 191  20   9   0   9   5  16   7]
 [  8 847  14  41   0   2  50   0  20  18]
 [ 13   0 904  21  14  17  26   4   1   0]
 [  6   0 208 579  18  99  86   3   1   0]
 [ 10   0 244  25 644  16  53   8   0   0]
 [  1   0 109  85  29 725  42   9   0   0]
 [  1   0  88  14   1   1 892   3   0   0]
 [ 16   0  77  41 102  52   5 707   0   0]
 [ 57   2  64   8   0   1  17   0 849   2]
 [ 39  56  21  82   0   3  27   5  31 736]]
TRAINING class wise acc@28 :: {0: [0.95], 1: [0.9796], 2: [0.9444], 3: [0.9396], 4: [0.9564], 5: [0.9382], 6: [0.9622], 7: [0.9742], 8: [0.9766], 9: [0.9786]}
TRAIINING epoch@28 ::  acc@0.961  loss@0.127
[[2375    0   48    5    6    0    0    9   36   21]
 [   1 4898    0   21    0    0   16    0   27   37]
 [  51    1 4722   53   82    6   60    6   19    0]
 [  10   14   39 4698   15  119   49   37    8   11]
 [   7    0   88   22 4782   55    4   42    0    0]
 [   0    0    7  181   60 4691   26   35    0    0]
 [   0   10   71   66    9   26 4811    0    6    1]
 [  11    0    2   29   48   28    0 4871    0   11]
 [  34   22   26    5    0    0    7    0 4883   23]
 [  18   37    1   22    0    0    2   12   15 4893]]
TESTING class wise acc@28 :: {0: [0.825], 1: [0.893], 2: [0.68], 3: [0.679], 4: [0.689], 5: [0.617], 6: [0.466], 7: [0.789], 8: [0.883], 9: [0.966]}
TESTING epoch@28 ::  acc@0.749  loss@1.310
Epoch@@29
[[825  13  19   6   3   0   1   2  37  94]
 [  3 893   0   1   0   0   0   0  12  91]
 [117   7 680  68  44  10   4  11  29  30]
 [ 32  11  52 679  25  58   4  15  21 103]
 [ 46   3  70  64 689  15   2  69  10  32]
 [ 14   6  26 230  22 617   2  42   5  36]
 [ 11 124  57 134  15  15 466   5 114  59]
 [ 33   3   6  56  18   6   0 789   4  85]
 [ 44  21   2   6   0   0   0   0 883  44]
 [  4  23   0   1   0   0   0   0   6 966]]
TRAINING class wise acc@29 :: {0: [0.9344], 1: [0.9746], 2: [0.9316], 3: [0.9166], 4: [0.9412], 5: [0.9142], 6: [0.947], 7: [0.9614], 8: [0.9728], 9: [0.9632]}
TRAIINING epoch@29 ::  acc@0.946  loss@0.174
[[2336    0   56    8   11    1    0    9   40   39]
 [   0 4873    1   16    0    0   13    0   23   74]
 [  60    1 4658   82  104   10   61    6   14    4]
 [   8    7   59 4583   15  182   75   30    5   36]
 [  10    1  111   26 4706   54   11   75    0    6]
 [   0    0   10  265   69 4571   26   55    0    4]
 [   2   15   82  101    9   28 4735    0   15   13]
 [  11    0    6   54   74   38    0 4807    0   10]
 [  35   27   20   13    1    1   12    0 4864   27]
 [  25   63    5   48    0    0    4    8   31 4816]]
TESTING class wise acc@29 :: {0: [0.772], 1: [0.956], 2: [0.717], 3: [0.766], 4: [0.849], 5: [0.607], 6: [0.867], 7: [0.782], 8: [0.923], 9: [0.845]}
TESTING epoch@29 ::  acc@0.808  loss@0.951
Epoch@@30
[[772  10  66  14  23   1   6   6  82  20]
 [  3 956   0   1   0   0   0   0  12  28]
 [ 31   1 717  64  71  16  80   3  15   2]
 [ 14   8  52 766  54  25  49   7  11  14]
 [  9   1  52  53 849   7  17   9   2   1]
 [  5   3  26 250  57 607  33  15   3   1]
 [  2   9  31  69  11   1 867   3   5   2]
 [ 20   0  16  47 103  22   2 782   1   7]
 [ 23  24   7   7   3   0   4   0 923   9]
 [ 23  94   1   9   0   0   0   1  27 845]]
TRAINING class wise acc@30 :: {0: [0.96], 1: [0.9874], 2: [0.9592], 3: [0.9516], 4: [0.963], 5: [0.9478], 6: [0.9718], 7: [0.9746], 8: [0.9824], 9: [0.9806]}
TRAIINING epoch@30 ::  acc@0.968  loss@0.102
[[2400    0   33    2    9    0    1    7   32   16]
 [   0 4937    0   10    0    0    4    0   16   33]
 [  32    0 4796   34   62    6   56    4    9    1]
 [   3    4   27 4758    7  123   30   30    5   13]
 [  11    0   67   13 4815   34    1   59    0    0]
 [   0    0   13  162   42 4739   10   34    0    0]
 [   0    8   65   50    2   13 4859    0    3    0]
 [  10    0    1   32   50   29    0 4873    0    5]
 [  35   12   14    5    0    0    5    0 4912   17]
 [  16   45    0   17    0    0    1    4   14 4903]]
TESTING class wise acc@30 :: {0: [0.821], 1: [0.953], 2: [0.831], 3: [0.645], 4: [0.778], 5: [0.758], 6: [0.752], 7: [0.916], 8: [0.893], 9: [0.868]}
TESTING epoch@30 ::  acc@0.822  loss@0.953
Epoch@@31
[[821   9  57  19  12   0   1  14  34  33]
 [  3 953   0   5   0   0   2   0   9  28]
 [ 44   1 831  39  32  23   5  16   8   1]
 [ 17   4  87 645  44 110  20  52   6  15]
 [ 11   0  88  25 778  25   7  63   1   2]
 [  6   1  49  91  33 758   4  56   1   1]
 [  4   4 149  47  11  12 752   8  11   2]
 [ 13   0   9  19  23  16   0 916   0   4]
 [ 51  16  15   6   0   3   1   2 893  13]
 [ 17  87   4   8   0   0   0   1  15 868]]
TRAINING class wise acc@31 :: {0: [0.9708], 1: [0.9918], 2: [0.9686], 3: [0.9658], 4: [0.975], 5: [0.9602], 6: [0.9812], 7: [0.9854], 8: [0.9886], 9: [0.9868]}
TRAIINING epoch@31 ::  acc@0.978  loss@0.072
[[2427    0   27    1    4    0    0    4   23   14]
 [   1 4959    0    3    0    0    2    0   11   24]
 [  24    1 4843   38   46    6   32    2    8    0]
 [   4    2   28 4829    5   82   18   14    5   13]
 [   5    0   49    8 4875   27    3   33    0    0]
 [   0    0    7  125   34 4801   10   23    0    0]
 [   0    3   41   31    2   11 4906    0    6    0]
 [   5    0    0   16   35   15    0 4927    0    2]
 [  19   11   10    2    0    0    5    0 4943   10]
 [  15   24    0   12    0    0    0    3   12 4934]]
TESTING class wise acc@31 :: {0: [0.814], 1: [0.912], 2: [0.827], 3: [0.643], 4: [0.785], 5: [0.792], 6: [0.829], 7: [0.859], 8: [0.926], 9: [0.859]}
TESTING epoch@31 ::  acc@0.825  loss@0.910
Epoch@@32
[[814   6  73  21   5   2   1  10  52  16]
 [  6 912   1  11   0   0   4   0  32  34]
 [ 26   0 827  44  34  28  28   9   3   1]
 [ 13   1  79 643  43 151  31  27   7   5]
 [  9   1  92  23 785  48  10  31   1   0]
 [  2   1  50  77  31 792   8  39   0   0]
 [  4   1  85  39   6  28 829   4   3   1]
 [ 10   0  18  25  37  43   1 859   0   7]
 [ 30   8  14  11   1   1   0   2 926   7]
 [ 28  50   6  18   1   1   2   3  32 859]]
TRAINING class wise acc@32 :: {0: [0.9676], 1: [0.9894], 2: [0.9618], 3: [0.9576], 4: [0.9722], 5: [0.9552], 6: [0.9784], 7: [0.9828], 8: [0.9882], 9: [0.9864]}
TRAIINING epoch@32 ::  acc@0.974  loss@0.080
[[2419    0   40    3    6    0    0    4   19    9]
 [   0 4947    0    7    0    0    5    0   14   27]
 [  34    0 4809   35   62    5   43    2    9    1]
 [   5    9   34 4788    5   97   35   19    0    8]
 [   6    0   63    3 4861   35    1   31    0    0]
 [   0    0    7  133   38 4776   15   31    0    0]
 [   0    5   38   45    2   14 4892    0    4    0]
 [   5    0    2   20   29   22    0 4914    0    8]
 [  19   13    5    7    0    0    3    0 4941   12]
 [  14   19    1   15    0    0    0    7   12 4932]]
TESTING class wise acc@32 :: {0: [0.8], 1: [0.922], 2: [0.683], 3: [0.749], 4: [0.748], 5: [0.785], 6: [0.907], 7: [0.871], 8: [0.908], 9: [0.87]}
TESTING epoch@32 ::  acc@0.824  loss@0.933
Epoch@@33
[[800   4  50  40   5   0   6  22  38  35]
 [  8 922   0   7   0   0   4   2  19  38]
 [ 53   0 683  63  61  44  74  17   5   0]
 [  8   1  33 749  20 114  52  14   5   4]
 [  5   0  63  51 748  73  27  32   1   0]
 [  7   0  13 141  16 785  14  23   1   0]
 [  1   1  25  42   4  14 907   3   3   0]
 [  7   0   9  42  27  42   0 871   0   2]
 [ 40  11  11   8   0   1   3   1 908  17]
 [ 17  51   2  34   0   2   2   2  20 870]]
TRAINING class wise acc@33 :: {0: [0.9624], 1: [0.9874], 2: [0.9678], 3: [0.964], 4: [0.9688], 5: [0.9648], 6: [0.979], 7: [0.9856], 8: [0.9868], 9: [0.9842]}
TRAIINING epoch@33 ::  acc@0.976  loss@0.077
[[2406    0   33    7    4    0    0    6   28   16]
 [   1 4937    1    7    0    0    4    0    8   42]
 [  35    0 4839   27   55    4   28    0   10    2]
 [   3    9   32 4820    9   73   24   21    2    7]
 [   6    0   63   16 4844   32    5   34    0    0]
 [   0    0    4  108   23 4824   12   28    1    0]
 [   1    2   43   36    5    7 4895    0   11    0]
 [   7    0    0   20   25   13    0 4928    0    7]
 [  25    8   15    4    0    0    4    0 4934   10]
 [  13   35    0   11    0    0    0    8   12 4921]]
TESTING class wise acc@33 :: {0: [0.74], 1: [0.915], 2: [0.678], 3: [0.62], 4: [0.82], 5: [0.774], 6: [0.914], 7: [0.849], 8: [0.941], 9: [0.916]}
TESTING epoch@33 ::  acc@0.817  loss@0.976
Epoch@@34
[[740   7  39  30   8   1   8   8 100  59]
 [  2 915   0   5   0   0   4   0  27  47]
 [ 44   1 678  37  70  32 108  10  16   4]
 [  9   3  37 620  41 164  90  17  11   8]
 [ 18   0  37  31 820  28  24  39   3   0]
 [  9   0  20  81  47 774  42  21   5   1]
 [  2   2  21  29  13   7 914   1  10   1]
 [  6   0   7  41  27  58   2 849   3   7]
 [ 21   6   3   5   0   2   3   0 941  19]
 [  5  40   3  11   1   0   0   1  23 916]]
TRAINING class wise acc@34 :: {0: [0.9692], 1: [0.9894], 2: [0.9688], 3: [0.9616], 4: [0.973], 5: [0.9614], 6: [0.986], 7: [0.984], 8: [0.9916], 9: [0.9872]}
TRAIINING epoch@34 ::  acc@0.978  loss@0.071
[[2423    0   34    1    7    0    0    2   16   17]
 [   0 4947    0    9    0    0    2    0   12   30]
 [  30    1 4844   31   48    7   26    4    9    0]
 [   3    5   19 4808   13   95   28   18    1   10]
 [   9    0   50    9 4865   37    2   28    0    0]
 [   0    0    6  118   34 4807   10   25    0    0]
 [   0    2   35   24    3    4 4930    0    2    0]
 [   8    0    3   24   24   19    0 4920    0    2]
 [  16   12    4    2    0    0    3    0 4958    5]
 [   9   29    0   13    0    0    0    3   10 4936]]
TESTING class wise acc@34 :: {0: [0.747], 1: [0.876], 2: [0.785], 3: [0.72], 4: [0.766], 5: [0.811], 6: [0.856], 7: [0.755], 8: [0.903], 9: [0.873]}
TESTING epoch@34 ::  acc@0.809  loss@1.111
Epoch@@35
[[747   5 110  37  21   2   4   6  43  25]
 [  6 876   4  20   0   3   5   0  28  58]
 [ 19   0 785  62  54  38  35   1   4   2]
 [  5   1  51 720  20 157  26  10   3   7]
 [  6   0  73  62 766  58  20  15   0   0]
 [  1   0  28 117  24 811  11   7   0   1]
 [  1   1  37  71  10  17 856   2   4   1]
 [  8   0  12  49  43 127   3 755   1   2]
 [ 22   5  29  20   2   2   6   0 903  11]
 [ 15  36   5  42   0   2   2   3  22 873]]
TRAINING class wise acc@35 :: {0: [0.9692], 1: [0.991], 2: [0.9688], 3: [0.9658], 4: [0.9768], 5: [0.9706], 6: [0.9804], 7: [0.9836], 8: [0.9882], 9: [0.989]}
TRAIINING epoch@35 ::  acc@0.979  loss@0.067
[[2423    0   29    3    7    0    0    7   19   12]
 [   0 4955    0    8    0    0    0    0   11   26]
 [  34    0 4844   32   43    3   32    3    8    1]
 [   1    2   23 4829    6   76   30   16    4   13]
 [   5    0   49    9 4884   19    2   32    0    0]
 [   0    0    2   84   26 4853   12   23    0    0]
 [   0    4   37   37    2   12 4902    0    6    0]
 [   8    0    2   27   25   18    0 4918    0    2]
 [  17   13   10    4    0    0    5    0 4941   10]
 [   6   25    0   10    0    0    0    4   10 4945]]
TESTING class wise acc@35 :: {0: [0.828], 1: [0.948], 2: [0.831], 3: [0.701], 4: [0.8], 5: [0.475], 6: [0.848], 7: [0.878], 8: [0.899], 9: [0.878]}
TESTING epoch@35 ::  acc@0.809  loss@1.080
Epoch@@36
[[828   6  72  14   8   0   2   6  38  26]
 [  4 948   1   0   0   0   1   0  16  30]
 [ 43   1 831  20  42   5  32   8  13   5]
 [ 21  18  87 701  52  20  41  23  14  23]
 [  9   0  81  31 800   3  13  59   3   1]
 [  7   2  53 290  65 475  36  63   3   6]
 [  5   5  71  33  13   2 848   3  16   4]
 [ 23   1  16  39  22   5   1 878   1  14]
 [ 60  19   9   3   0   0   0   0 899  10]
 [ 27  74   2   1   0   0   0   0  18 878]]
TRAINING class wise acc@36 :: {0: [0.9696], 1: [0.9902], 2: [0.9672], 3: [0.9622], 4: [0.9756], 5: [0.961], 6: [0.9762], 7: [0.9838], 8: [0.986], 9: [0.9858]}
TRAIINING epoch@36 ::  acc@0.976  loss@0.080
[[2424    0   31    2    3    0    0    6   17   17]
 [   0 4951    0    9    0    0    1    0   15   24]
 [  26    0 4836   42   40    2   42    1    9    2]
 [   4    3   27 4811   13   88   23   11    4   16]
 [   7    0   38    3 4878   29    7   38    0    0]
 [   1    0    3  111   35 4805   20   25    0    0]
 [   0    3   54   38    1   15 4881    0    8    0]
 [  11    0    0   20   33   16    0 4919    0    1]
 [  22   12    8    5    0    0    7    0 4930   16]
 [   9   28    0   16    0    0    0    2   16 4929]]
TESTING class wise acc@36 :: {0: [0.839], 1: [0.921], 2: [0.741], 3: [0.764], 4: [0.743], 5: [0.732], 6: [0.86], 7: [0.867], 8: [0.924], 9: [0.865]}
TESTING epoch@36 ::  acc@0.826  loss@0.873
Epoch@@37
[[839   7  20  23  11   0   4  12  61  23]
 [  2 921   0  15   0   0   3   0  24  35]
 [ 93   2 741  51  37  17  37   9  12   1]
 [ 18   3  54 764  25  80  31  16   4   5]
 [ 12   0  84  78 743  30  13  37   3   0]
 [  6   1  30 154  37 732  11  26   3   0]
 [  3   1  41  63  14   8 860   4   5   1]
 [ 15   0  12  42  32  30   1 867   0   1]
 [ 34  11   3  10   0   1   3   2 924  12]
 [ 25  50   2  35   0   0   2   2  19 865]]
TRAINING class wise acc@37 :: {0: [0.9748], 1: [0.9872], 2: [0.9706], 3: [0.9654], 4: [0.9726], 5: [0.9646], 6: [0.984], 7: [0.9838], 8: [0.9888], 9: [0.9886]}
TRAIINING epoch@37 ::  acc@0.978  loss@0.074
[[2437    0   21    2    5    0    0    5   19   11]
 [   0 4936    0   16    0    0    5    0   13   30]
 [  24    1 4853   29   50    4   29    2    8    0]
 [   6   13   29 4827    8   75   15   15    1   11]
 [   6    0   45   16 4863   33    4   32    0    1]
 [   0    0    2  106   34 4823    8   27    0    0]
 [   1    8   28   26    2    8 4920    0    7    0]
 [   9    0    0   24   21   22    0 4919    0    5]
 [  21    5    9    8    0    0    3    0 4944   10]
 [  12   19    1    9    0    0    0    8    8 4943]]
TESTING class wise acc@37 :: {0: [0.743], 1: [0.934], 2: [0.814], 3: [0.722], 4: [0.791], 5: [0.792], 6: [0.913], 7: [0.782], 8: [0.88], 9: [0.858]}
TESTING epoch@37 ::  acc@0.823  loss@1.041
Epoch@@38
[[743   5 123  42  20   1   6   8  37  15]
 [  1 934   1  18   0   0   7   1  11  27]
 [ 15   0 814  47  30  37  50   2   3   2]
 [  6   0  52 722  35 113  48  14   3   7]
 [  3   0  87  46 791  36  25  11   1   0]
 [  1   0  25 111  36 792  24  10   0   1]
 [  2   0  39  32   7   5 913   2   0   0]
 [  5   0  18  53  80  56   4 782   0   2]
 [ 37  17  22  17   1   1  11   0 880  14]
 [ 15  67   6  33   0   0   4   2  15 858]]
TRAINING class wise acc@38 :: {0: [0.9748], 1: [0.9918], 2: [0.9698], 3: [0.9702], 4: [0.975], 5: [0.9698], 6: [0.9822], 7: [0.9838], 8: [0.9906], 9: [0.9914]}
TRAIINING epoch@38 ::  acc@0.980  loss@0.065
[[2437    0   24    2    2    1    0    4   21    9]
 [   0 4959    0    4    0    0    3    0    8   26]
 [  31    0 4849   26   50    3   29    1   10    1]
 [   1    5   19 4851    5   65   31   15    0    8]
 [   6    0   45    6 4875   27    3   38    0    0]
 [   0    0    3   90   24 4849   14   20    0    0]
 [   1    3   29   39    1   13 4911    0    3    0]
 [   3    0    4   21   33   16    0 4919    0    4]
 [  21    8   15    1    0    0    1    0 4953    1]
 [   8   22    0    7    0    0    0    5    1 4957]]
TESTING class wise acc@38 :: {0: [0.728], 1: [0.881], 2: [0.733], 3: [0.745], 4: [0.824], 5: [0.779], 6: [0.894], 7: [0.847], 8: [0.938], 9: [0.92]}
TESTING epoch@38 ::  acc@0.829  loss@0.931
Epoch@@39
[[728   8  69  41  23   3   6   6  80  36]
 [  3 881   0  19   0   0   3   0  24  70]
 [ 29   0 733  71  60  29  59   8   9   2]
 [  5   1  35 745  34 114  37  15   5   9]
 [  4   0  40  61 824  28  16  24   3   0]
 [  2   1   8 131  36 779  13  28   1   1]
 [  2   1  19  54  12  10 894   4   3   1]
 [  6   0   5  48  51  29   6 847   2   6]
 [ 16   7   8  12   2   0   5   0 938  12]
 [  9  24   3  17   0   0   2   0  25 920]]
TRAINING class wise acc@39 :: {0: [0.9636], 1: [0.9912], 2: [0.972], 3: [0.966], 4: [0.9746], 5: [0.9628], 6: [0.981], 7: [0.9844], 8: [0.9876], 9: [0.99]}
TRAIINING epoch@39 ::  acc@0.978  loss@0.073
[[2409    0   28    4    8    0    0    4   37   10]
 [   0 4956    0    7    0    0    3    0   11   23]
 [  32    0 4860   34   34    6   29    0    4    1]
 [   1    3   30 4830    8   82   21   15    5    5]
 [   6    0   43   12 4873   32    4   30    0    0]
 [   0    0    4  100   49 4814   13   20    0    0]
 [   0    3   38   32    4   12 4905    0    6    0]
 [   9    0    3   21   22   20    0 4922    0    3]
 [  26   12   10    4    0    0    3    0 4938    7]
 [  11   20    0    6    0    0    0    5    8 4950]]
TESTING class wise acc@39 :: {0: [0.782], 1: [0.931], 2: [0.703], 3: [0.786], 4: [0.712], 5: [0.71], 6: [0.762], 7: [0.814], 8: [0.962], 9: [0.878]}
TESTING epoch@39 ::  acc@0.804  loss@1.152
Epoch@@40
[[782  11  23  25   7   0   1   3 122  26]
 [  2 931   0   2   0   0   0   0  33  32]
 [ 55   4 703 110  21  20  29   8  46   4]
 [ 14  26  39 786   9  68  11  12  16  19]
 [ 16   0  84  87 712  37  17  31  16   0]
 [  4   3  23 210  15 710   4  19   7   5]
 [  5  57  37 106   5   3 762   1  22   2]
 [ 18   1   7  85  24  34   1 814   5  11]
 [  8  12   1   5   0   0   1   1 962  10]
 [ 14  58   0   4   0   0   0   0  46 878]]
TRAINING class wise acc@40 :: {0: [0.9688], 1: [0.9858], 2: [0.9664], 3: [0.9606], 4: [0.9716], 5: [0.961], 6: [0.9764], 7: [0.9824], 8: [0.987], 9: [0.9852]}
TRAIINING epoch@40 ::  acc@0.975  loss@0.083
[[2422    0   28    4    5    0    0    9   16   16]
 [   0 4929    1    8    0    0    5    0   21   36]
 [  29    1 4832   43   38    6   31    1   18    1]
 [   1    5   31 4803    5   81   25   30    3   16]
 [   4    0   47   15 4858   36    5   35    0    0]
 [   0    1    5  124   32 4805   13   20    0    0]
 [   0   19   36   35    4   12 4882    0   11    1]
 [   4    0    3   28   34   13    0 4912    0    6]
 [  13   17   18    3    0    0    6    0 4935    8]
 [  17   29    1   14    0    0    0    4    9 4926]]
TESTING class wise acc@40 :: {0: [0.784], 1: [0.909], 2: [0.758], 3: [0.727], 4: [0.77], 5: [0.78], 6: [0.906], 7: [0.86], 8: [0.914], 9: [0.853]}
TESTING epoch@40 ::  acc@0.826  loss@1.013
Epoch@@41
[[784   5  74  40  17   4   7  19  29  21]
 [  3 909   2  20   0   0   5   3  17  41]
 [ 32   0 758  51  49  47  51   6   6   0]
 [  4   1  47 727  32 118  49  14   4   4]
 [  3   0  51  45 770  72  33  24   2   0]
 [  0   0  22 122  28 780  20  27   1   0]
 [  0   0  25  42  10  10 906   3   3   1]
 [  6   0  11  31  28  62   1 860   0   1]
 [ 37  10  11  15   0   0   4   2 914   7]
 [ 17  57   7  40   0   1   6   5  14 853]]
TRAINING class wise acc@41 :: {0: [0.9792], 1: [0.993], 2: [0.9762], 3: [0.9752], 4: [0.9836], 5: [0.9782], 6: [0.9866], 7: [0.9876], 8: [0.9886], 9: [0.991]}
TRAIINING epoch@41 ::  acc@0.984  loss@0.051
[[2448    0   18    3    3    0    0    3   19    6]
 [   0 4965    0    4    0    0    3    0   13   15]
 [  16    0 4881   34   33    1   17    3   13    2]
 [   1    6   22 4876    4   43   22   12    1   13]
 [   5    0   28    5 4918   16    0   28    0    0]
 [   0    0    1   63   13 4891   11   21    0    0]
 [   0    2   20   27    0   13 4933    0    5    0]
 [   9    0    2   14   22   13    0 4938    0    2]
 [  19   11   11    4    0    0    3    0 4943    9]
 [   7   13    0   12    0    0    0    4    9 4955]]
TESTING class wise acc@41 :: {0: [0.669], 1: [0.889], 2: [0.646], 3: [0.682], 4: [0.872], 5: [0.83], 6: [0.885], 7: [0.819], 8: [0.896], 9: [0.885]}
TESTING epoch@41 ::  acc@0.807  loss@1.171
Epoch@@42
[[669   5 110  35  43   4   7  27  58  42]
 [  3 889   3  24   0   1   7   0  19  54]
 [ 23   0 646  48 146  62  58  12   5   0]
 [  2   0  36 682  36 168  44  20   5   7]
 [  1   0  19  21 872  59  11  17   0   0]
 [  1   1  12 101  30 830  12  13   0   0]
 [  1   0  13  44  26  26 885   2   2   1]
 [  2   0   8  39  55  72   2 819   1   2]
 [ 19  10  33  13   1   1   5   1 896  21]
 [  7  30   5  39   2   2   6   4  20 885]]
TRAINING class wise acc@42 :: {0: [0.9832], 1: [0.9918], 2: [0.976], 3: [0.9734], 4: [0.9794], 5: [0.9742], 6: [0.9832], 7: [0.9874], 8: [0.9908], 9: [0.991]}
TRAIINING epoch@42 ::  acc@0.983  loss@0.056
[[2458    0   12    0    3    0    0    2   16    9]
 [   0 4959    0    7    0    0    1    0   11   22]
 [  18    1 4880   16   41    5   29    1    9    0]
 [   2    5   19 4867    2   56   26   15    1    7]
 [   2    0   46    5 4897   25    2   23    0    0]
 [   0    0    3   75   22 4871    8   21    0    0]
 [   0    4   25   35    5   10 4916    0    5    0]
 [   1    0    1   25   20   15    0 4937    0    1]
 [  17    8   10    4    0    0    2    0 4954    5]
 [   4   18    1    8    0    0    0    5    9 4955]]
TESTING class wise acc@42 :: {0: [0.758], 1: [0.893], 2: [0.746], 3: [0.575], 4: [0.842], 5: [0.776], 6: [0.893], 7: [0.885], 8: [0.921], 9: [0.939]}
TESTING epoch@42 ::  acc@0.823  loss@1.045
Epoch@@43
[[758   7  73  19  12   2   4  14  60  51]
 [  2 893   1   5   0   0   4   0  18  77]
 [ 22   0 746  37  67  44  49  24   8   3]
 [ 11   1  49 575  48 194  59  42   7  14]
 [  7   0  40  21 842  42   8  35   3   2]
 [  1   0  23  87  40 776  19  43   6   5]
 [  4   2  28  14  19  28 893   4   4   4]
 [  5   0   8  18  34  42   1 885   1   6]
 [ 15  12   8   6   0   0   3   2 921  33]
 [ 11  22   2  11   0   0   1   5   9 939]]
TRAINING class wise acc@43 :: {0: [0.9776], 1: [0.993], 2: [0.974], 3: [0.967], 4: [0.9838], 5: [0.974], 6: [0.9826], 7: [0.988], 8: [0.9906], 9: [0.9896]}
TRAIINING epoch@43 ::  acc@0.982  loss@0.059
[[2444    0   18    1    2    0    0    7   21    7]
 [   1 4965    0    4    0    0    3    0   11   16]
 [  27    0 4870   28   38    3   23    3    7    1]
 [   1    4   16 4835    4   70   43   12    1   14]
 [   4    0   37    4 4919   16    1   19    0    0]
 [   0    0    2   81   23 4870   10   14    0    0]
 [   0    2   33   34    5   11 4913    0    2    0]
 [   6    0    2   18   16   12    0 4940    0    6]
 [  18    7   10    3    0    0    4    0 4953    5]
 [   4   18    0   16    0    0    0    6    8 4948]]
TESTING class wise acc@43 :: {0: [0.827], 1: [0.926], 2: [0.708], 3: [0.748], 4: [0.769], 5: [0.755], 6: [0.859], 7: [0.889], 8: [0.925], 9: [0.93]}
TESTING epoch@43 ::  acc@0.834  loss@0.918
Epoch@@44
[[827   3  29  23   9   0   2   9  60  38]
 [  2 926   0   5   0   0   1   0   9  57]
 [ 74   2 708  74  47  24  37  12  21   1]
 [ 16   3  35 748  31 102  23  23   8  11]
 [ 11   1  50  66 769  30  18  53   2   0]
 [  4   2  14 155  32 755   3  33   2   0]
 [  3   3  28  74   9  11 859   4   7   2]
 [ 10   1   7  31  32  25   3 889   0   2]
 [ 32  13   3   7   0   0   1   3 925  16]
 [ 13  27   1  10   0   0   0   4  15 930]]
TRAINING class wise acc@44 :: {0: [0.984], 1: [0.9944], 2: [0.9824], 3: [0.976], 4: [0.9842], 5: [0.9776], 6: [0.9886], 7: [0.9902], 8: [0.994], 9: [0.9928]}
TRAIINING epoch@44 ::  acc@0.987  loss@0.046
[[2460    0   12    2    3    0    0    0   10   13]
 [   0 4972    1    3    0    0    3    0   10   11]
 [  13    1 4912   22   22    0   21    2    7    0]
 [   2    6   20 4880    8   48   17   12    2    5]
 [   4    0   29    3 4921   25    1   17    0    0]
 [   0    0    5   60   22 4888    4   21    0    0]
 [   0    1   22   24    2    6 4943    0    2    0]
 [   1    0    1   12   17   16    0 4951    0    2]
 [   9    7    5    3    0    0    2    0 4970    4]
 [   9   10    0    9    0    0    0    1    7 4964]]
TESTING class wise acc@44 :: {0: [0.741], 1: [0.929], 2: [0.756], 3: [0.801], 4: [0.781], 5: [0.782], 6: [0.853], 7: [0.861], 8: [0.901], 9: [0.83]}
TESTING epoch@44 ::  acc@0.823  loss@1.056
Epoch@@45
[[741   8  91  62  14   1   5  18  33  27]
 [  2 929   1  21   1   1   5   1  11  28]
 [ 18   0 756 106  45  30  26  14   5   0]
 [  4   1  29 801  26  99  23  14   2   1]
 [  2   0  57  57 781  49  13  40   1   0]
 [  1   0  13 161  19 782   3  21   0   0]
 [  1   0  26  79  17  22 853   1   1   0]
 [  3   0  11  59  23  40   2 861   1   0]
 [ 27  12  22  23   0   2   5   2 901   6]
 [ 14  55   2  68   0   0   3  10  18 830]]
TRAINING class wise acc@45 :: {0: [0.9656], 1: [0.9896], 2: [0.9694], 3: [0.9628], 4: [0.9684], 5: [0.963], 6: [0.9772], 7: [0.982], 8: [0.9882], 9: [0.9862]}
TRAIINING epoch@45 ::  acc@0.976  loss@0.079
[[2414    0   28    6    7    0    0    5   21   19]
 [   0 4948    0   11    0    0    1    1   13   26]
 [  28    1 4847   29   50    4   35    0    4    2]
 [   4    5   24 4814   13   82   26   19    1   12]
 [   6    0   51   16 4842   36   11   38    0    0]
 [   0    0    3  114   27 4815   17   24    0    0]
 [   0    2   40   44   12   11 4886    0    5    0]
 [   6    0    1   28   35   13    0 4910    0    7]
 [  24   11    7    4    0    0    4    0 4941    9]
 [  11   23    1   11    0    0    1   10   12 4931]]
TESTING class wise acc@45 :: {0: [0.821], 1: [0.906], 2: [0.772], 3: [0.744], 4: [0.758], 5: [0.719], 6: [0.886], 7: [0.883], 8: [0.958], 9: [0.836]}
TESTING epoch@45 ::  acc@0.828  loss@1.008
Epoch@@46
[[821   2  46  18   5   0   3   5  85  15]
 [  4 906   0   5   0   1   1   0  62  21]
 [ 62   1 772  58  35  12  40   6  14   0]
 [ 16   3  49 744  21  84  41  21  13   8]
 [ 21   0  83  64 758  20  22  29   3   0]
 [  5   1  29 151  26 719  28  39   2   0]
 [  5   3  36  47   8   2 886   2  11   0]
 [ 21   0  13  33  24  20   3 883   0   3]
 [ 20   3   4  10   0   0   3   0 958   2]
 [ 33  56   2  10   0   1   0   3  59 836]]
TRAINING class wise acc@46 :: {0: [0.976], 1: [0.9942], 2: [0.9746], 3: [0.9768], 4: [0.9846], 5: [0.9754], 6: [0.9864], 7: [0.9868], 8: [0.9924], 9: [0.992]}
TRAIINING epoch@46 ::  acc@0.984  loss@0.054
[[2440    0   20    4    7    0    0    4   13   12]
 [   0 4971    0    3    0    0    2    0   10   14]
 [  26    0 4873   27   42    3   25    1    2    1]
 [   3    3   14 4884    6   52   16   17    1    4]
 [   3    0   32    5 4923   16    4   16    1    0]
 [   0    0    3   67   21 4877   13   19    0    0]
 [   0    3   26   22    4   10 4932    0    3    0]
 [   7    0    0   22   17   18    0 4934    0    2]
 [  10   12    5    3    0    0    2    0 4962    6]
 [   9   12    0   10    0    0    0    4    5 4960]]
TESTING class wise acc@46 :: {0: [0.661], 1: [0.923], 2: [0.794], 3: [0.776], 4: [0.753], 5: [0.697], 6: [0.855], 7: [0.751], 8: [0.952], 9: [0.807]}
TESTING epoch@46 ::  acc@0.797  loss@1.245
Epoch@@47
[[661   4 175  26  18   1   4   3  96  12]
 [  4 923   2   4   0   0   3   1  40  23]
 [  7   0 794  65  31  27  55   3  18   0]
 [  7   3  66 776  26  77  24   5  11   5]
 [  1   0 102  52 753  57  23  11   1   0]
 [  1   0  28 223  19 697  20   9   3   0]
 [  2   3  39  66   9   8 855   1  16   1]
 [ 11   0  17  91  53  70   3 751   4   0]
 [ 11   6  15   9   1   0   2   0 952   4]
 [ 33  89   5  20   0   0   2   3  41 807]]
TRAINING class wise acc@47 :: {0: [0.966], 1: [0.991], 2: [0.966], 3: [0.965], 4: [0.972], 5: [0.9686], 6: [0.9852], 7: [0.983], 8: [0.989], 9: [0.989]}
TRAIINING epoch@47 ::  acc@0.978  loss@0.076
[[2415    0   24    4    8    1    0    7   22   19]
 [   0 4955    1    5    0    0    6    0   16   17]
 [  31    2 4830   43   48    5   29    5    7    0]
 [   7    2   39 4825    5   55   30   24    3   10]
 [   8    0   63   11 4860   25    2   31    0    0]
 [   0    0   11   88   14 4843    7   37    0    0]
 [   0    3   30   27    4    6 4926    0    4    0]
 [   8    0    4   25   24   18    0 4915    0    6]
 [  16   12    9    3    0    0    2    0 4945   13]
 [  17   18    0   10    0    0    0    2    8 4945]]
TESTING class wise acc@47 :: {0: [0.772], 1: [0.938], 2: [0.781], 3: [0.748], 4: [0.88], 5: [0.742], 6: [0.863], 7: [0.78], 8: [0.913], 9: [0.903]}
TESTING epoch@47 ::  acc@0.832  loss@1.032
Epoch@@48
[[772  10  58  35   9   0   2   2  54  58]
 [  3 938   1   9   0   0   2   0  15  32]
 [ 31   0 781  49  65  25  41   1   6   1]
 [ 13   2  64 748  47  79  23   7  10   7]
 [  7   0  41  38 880  16  10   7   1   0]
 [  2   0  37 150  46 742  10  13   0   0]
 [  3   1  39  55  23  11 863   1   3   1]
 [ 16   2  17  55  81  41   1 780   1   6]
 [ 25  18   9  13   1   0   2   0 913  19]
 [  5  52   4  23   1   0   0   0  12 903]]
TRAINING class wise acc@48 :: {0: [0.9868], 1: [0.9928], 2: [0.9836], 3: [0.9832], 4: [0.9862], 5: [0.9856], 6: [0.9898], 7: [0.9898], 8: [0.9926], 9: [0.9932]}
TRAIINING epoch@48 ::  acc@0.988  loss@0.037
[[2467    0   14    0    2    0    0    1    9    7]
 [   0 4964    0    3    0    0    1    0   12   20]
 [  18    0 4918   17   24    2   16    0    4    1]
 [   1    1   16 4916    3   36   12    9    1    5]
 [   2    0   27    3 4931   13    2   22    0    0]
 [   0    0    1   34   16 4928    9   12    0    0]
 [   0    2   21   19    2    6 4949    0    1    0]
 [   3    0    0   14   25    8    0 4949    0    1]
 [  11   11    5    3    0    0    1    0 4963    6]
 [   3   19    0    2    0    0    0    2    8 4966]]
TESTING class wise acc@48 :: {0: [0.732], 1: [0.931], 2: [0.783], 3: [0.743], 4: [0.728], 5: [0.795], 6: [0.868], 7: [0.886], 8: [0.901], 9: [0.84]}
TESTING epoch@48 ::  acc@0.821  loss@1.065
Epoch@@49
[[732   7  69  62   6   1   5  19  64  35]
 [  1 931   1  20   0   1   4   0  13  29]
 [ 33   0 783  71  30  32  36   8   5   2]
 [  5   3  67 743  18 112  31  11   4   6]
 [  5   0 117  64 728  25  20  39   2   0]
 [  1   0  20 125  15 795  10  34   0   0]
 [  1   0  50  54   8  15 868   2   2   0]
 [  3   0  14  33  35  25   2 886   0   2]
 [ 24  25  15  15   0   3   4   3 901  10]
 [  5  80   4  49   0   3   2   2  15 840]]
TRAINING class wise acc@49 :: {0: [0.9788], 1: [0.9936], 2: [0.9836], 3: [0.9768], 4: [0.9842], 5: [0.9794], 6: [0.9886], 7: [0.9888], 8: [0.9926], 9: [0.9916]}
TRAIINING epoch@49 ::  acc@0.986  loss@0.048
[[2447    0   11    2    4    0    0    7   23    6]
 [   0 4968    0    4    0    0    2    0    6   20]
 [  12    0 4918   26   27    1   10    1    4    1]
 [   1    4   16 4884    6   48   21   12    2    6]
 [   6    0   22    9 4921   19    4   19    0    0]
 [   0    0    1   59   15 4897    8   20    0    0]
 [   0    2   16   24    2    6 4943    0    7    0]
 [   5    0    0   12   19   18    0 4944    0    2]
 [  21    3    2    2    0    0    4    0 4963    5]
 [   8   23    0    6    0    0    0    2    3 4958]]
TESTING class wise acc@49 :: {0: [0.815], 1: [0.936], 2: [0.741], 3: [0.753], 4: [0.825], 5: [0.734], 6: [0.893], 7: [0.836], 8: [0.935], 9: [0.917]}
TESTING epoch@49 ::  acc@0.838  loss@0.914
[[815   6  37  22   8   0   4   5  56  47]
 [  1 936   0   4   0   0   1   0  17  41]
 [ 65   2 741  63  44  23  45   4   9   4]
 [ 10   4  43 753  44  74  35  13  11  13]
 [ 17   1  49  54 825  17  23  11   3   0]
 [  5   1  22 156  35 734  21  21   3   2]
 [  3   4  29  42  15   7 893   1   5   1]
 [ 18   1  14  46  58  22   1 836   0   4]
 [ 30  11   4   9   0   1   2   0 935   8]
 [  6  49   0   3   0   0   0   3  22 917]]
