

Fri Jan 15 18:16:35 2021
imbal_test_imbal123456_rand_cifar10_vgg_Adam's set level: 10
imbal_test_imbal123456_rand_cifar10_vgg_Adam logger is ready
imbal_test with imbalance_ratio: [0.5 0.5 0.5 0.5 0.5 0.5 1.  1.  1.  1. ]
parallel mode is False
initial count: cifar10: [0 1 2 3 4 5 6 7 8 9] class, each has [5000 5000 5000 5000 5000 5000 5000 5000 5000 5000]
cifar10: [0 1 2 3 4 5 6 7 8 9] class, each has [2500 2500 2500 2500 2500 2500 5000 5000 5000 5000]
Epoch@@0
Files already downloaded and verified
TRAINING class wise acc@0 :: {0: [0.0], 1: [0.0016], 2: [0.0096], 3: [0.0], 4: [0.0332], 5: [0.0008], 6: [0.1958], 7: [0.2344], 8: [0.3492], 9: [0.338]}
TRAIINING epoch@0 ::  acc@0.163  loss@2.418
[[   0    5    2    0   40    2  132  566  889  864]
 [   1    4    0    0   53    2  123  570  888  859]
 [   5    4   24    1   81    3  421  578  728  655]
 [   0    3    3    0   40    2  210  591  811  840]
 [   3    3   25    0   83    1  485  546  711  643]
 [   2    6    7    0   42    2  193  589  875  784]
 [   3    9   42    0  145   11  979 1056 1435 1320]
 [   1   12    5    0   86    2  404 1172 1701 1617]
 [   0    7    3    0   95    0  230 1137 1746 1782]
 [   1    9    2    0   97    0  275 1192 1734 1690]]
TESTING class wise acc@0 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.0], 4: [0.223], 5: [0.0], 6: [0.388], 7: [0.074], 8: [0.0], 9: [0.963]}
TESTING epoch@0 ::  acc@0.165  loss@2.234
Epoch@@1
[[  0   0   0   0  11   0  30   6   0 953]
 [  0   0   0   0   1   0  30  10   0 959]
 [  0   0   0   0 163   0 246  31   0 560]
 [  0   0   0   0  48   0 216  53   0 683]
 [  0   0   0   0 223   0 348  51   0 378]
 [  0   0   0   0  33   0 213  50   0 704]
 [  0   0   0   0 264   0 388  46   0 302]
 [  0   0   0   0  30   0 208  74   0 688]
 [  0   0   0   0   3   0  21   6   0 970]
 [  0   0   0   0   0   0  26  11   0 963]]
TRAINING class wise acc@1 :: {0: [0.0], 1: [0.0], 2: [0.0052], 3: [0.0], 4: [0.0112], 5: [0.0028], 6: [0.573], 7: [0.4914], 8: [0.7124], 9: [0.3026]}
TRAIINING epoch@1 ::  acc@0.298  loss@1.936
[[   0    0    0    0    0    2   65  220 1607  606]
 [   0    0    2    0    0    0   51  270 1458  719]
 [   0    0   13    0   13    3  921  697  430  423]
 [   0    0    2    0    4   13  720  994  327  440]
 [   0    0   16    0   28    3 1270  658  241  284]
 [   0    0    1    0    4    7  671 1031  312  474]
 [   0    0   12    0   63   16 2865 1381  240  423]
 [   0    0    0    0    7    9 1008 2457  538  981]
 [   0    0    1    0    0    0   56  315 3562 1066]
 [   0    0    0    0    0    4   91  815 2577 1513]]
TESTING class wise acc@1 :: {0: [0.0], 1: [0.0], 2: [0.002], 3: [0.0], 4: [0.0], 5: [0.0], 6: [0.51], 7: [0.593], 8: [0.719], 9: [0.326]}
TESTING epoch@1 ::  acc@0.215  loss@2.008
Epoch@@2
[[  0   0   0   0   0   0 100  78 461 361]
 [  0   0   1   0   0   0  31  22 722 224]
 [  0   0   2   0   0   0 457 309  71 161]
 [  0   0   0   0   0   0 354 384  38 224]
 [  0   0   0   0   0   0 412 412  41 135]
 [  0   0   0   0   0   0 321 484  36 159]
 [  0   0   2   0   0   0 510 328  22 138]
 [  0   0   0   0   0   0 129 593  30 248]
 [  0   0   0   0   0   0  72  22 719 187]
 [  0   0   0   0   0   0  40  37 597 326]]
TRAINING class wise acc@2 :: {0: [0.0], 1: [0.0], 2: [0.0096], 3: [0.012], 4: [0.0384], 5: [0.006], 6: [0.7108], 7: [0.6246], 8: [0.7406], 9: [0.5556]}
TRAIINING epoch@2 ::  acc@0.381  loss@1.732
[[   0    0    1    8    2    3  156  211 1138  981]
 [   1    0    0    2    0    0   95  105 1182 1115]
 [   2    0   24   15   82   13 1207  600  162  395]
 [   1    0    5   30    8   22 1400  628   85  321]
 [   0    0   23   16   96   12 1291  711   94  257]
 [   0    0    3   47    9   15 1326  762   79  259]
 [   0    0   26   43   82   35 3554  867   84  309]
 [   1    0    0   27   31   19 1042 3123  109  648]
 [   1    0    1    7    0    3  162   93 3703 1030]
 [   1    0    2   10    0    6  264  437 1502 2778]]
TESTING class wise acc@2 :: {0: [0.115], 1: [0.0], 2: [0.0], 3: [0.24], 4: [0.026], 5: [0.0], 6: [0.558], 7: [0.747], 8: [0.627], 9: [0.806]}
TESTING epoch@2 ::  acc@0.312  loss@1.793
Epoch@@3
[[115   0   0 132   0   0  38  91 362 262]
 [  8   0   0  17   0   0   2  38  96 839]
 [ 25   0   0 195  18   0 369 271  37  85]
 [ 10   0   0 240   2   0 246 375  11 116]
 [ 15   0   0 114  26   0 405 364  19  57]
 [ 12   0   0 206   4   0 189 500   8  81]
 [  3   0   0 156   4   0 558 227   8  44]
 [  9   0   0  58   4   0  59 747   3 120]
 [ 43   0   0  42   0   0  10  18 627 260]
 [  7   0   0  19   0   0   4  90  74 806]]
TRAINING class wise acc@3 :: {0: [0.0732], 1: [0.0024], 2: [0.0112], 3: [0.158], 4: [0.0528], 5: [0.1888], 6: [0.7046], 7: [0.677], 8: [0.797], 9: [0.7726]}
TRAIINING epoch@3 ::  acc@0.456  loss@1.503
[[ 183    0   11   76    2   59  133   97 1488  451]
 [  22    6    5    5    4    5   44   89  408 1912]
 [  88    0   28  245   54  181 1102  374  276  152]
 [  69    0   19  395   20  376  932  430  109  150]
 [  48    0   28  133  132  102 1195  638  105  119]
 [  70    0   13  348   19  472  759  643   60  116]
 [  55    1   35  278  125  202 3523  475   96  210]
 [  72    0   17  193   65  218  549 3385   74  427]
 [ 140    3   11   58    0   35  104   35 3985  629]
 [  60    3    9   36    3   29  125  322  550 3863]]
TESTING class wise acc@3 :: {0: [0.027], 1: [0.002], 2: [0.058], 3: [0.0], 4: [0.192], 5: [0.292], 6: [0.405], 7: [0.883], 8: [0.607], 9: [0.842]}
TESTING epoch@3 ::  acc@0.331  loss@1.814
Epoch@@4
[[ 27   2  95   0  15  72  11 162 380 236]
 [  1   2   2   0   7   5   3  77  11 892]
 [  3   0  58   0 159 138 104 455  46  37]
 [  1   0  19   0  81 219  47 576   8  49]
 [  2   0  12   0 192  44 103 612  14  21]
 [  4   0  15   0  46 292  19 596   8  20]
 [  0   0   7   0 255  45 405 256   2  30]
 [  1   0   3   0  26  38   3 883   3  43]
 [ 15  13  35   0   5  19  10  42 607 254]
 [  2   1   0   0   5   1   2 130  17 842]]
TRAINING class wise acc@4 :: {0: [0.2204], 1: [0.262], 2: [0.0872], 3: [0.1272], 4: [0.1296], 5: [0.3952], 6: [0.7868], 7: [0.7368], 8: [0.814], 9: [0.7914]}
TRAIINING epoch@4 ::  acc@0.534  loss@1.285
[[ 551   23   87   43    5   62   78   86 1258  307]
 [  25  655   11    3    7    5   56   37  252 1449]
 [ 220    1  218  279  134  330  689  342  210   77]
 [ 125    8  186  318   99  644  597  359   86   78]
 [  99    3  112  143  324  155  792  724   61   87]
 [ 110    6  142  345   77  988  299  456   31   46]
 [  66   27  131  176  158  176 3934  136   91  105]
 [ 128    2   88  122  165  333  168 3684   48  262]
 [ 344  127   52   30    3   24   68   28 4070  254]
 [  86  310   33   17   15   10   87  173  312 3957]]
TESTING class wise acc@4 :: {0: [0.298], 1: [0.659], 2: [0.072], 3: [0.255], 4: [0.127], 5: [0.533], 6: [0.781], 7: [0.686], 8: [0.852], 9: [0.74]}
TESTING epoch@4 ::  acc@0.500  loss@1.307
Epoch@@5
[[298  26  20  45   1  33  18  30 424 105]
 [  6 659   7   3   1   0  10   6  88 220]
 [ 54  12  72 321  31 172 146  88  84  20]
 [ 45  11  67 255  18 301 149  70  48  36]
 [ 31   9  56 177 127  81 173 290  25  31]
 [ 16   4  32 221  13 533  52  94  19  16]
 [  6   8  38  90  27  13 781   5  23   9]
 [ 18   4  16  65  26 112   8 686   9  56]
 [ 45  47  10   2   0   8   8   4 852  24]
 [ 18 153   5   3   1   2   3  10  65 740]]
TRAINING class wise acc@5 :: {0: [0.5124], 1: [0.6292], 2: [0.1256], 3: [0.1468], 4: [0.3012], 5: [0.4592], 6: [0.8192], 7: [0.752], 8: [0.8172], 9: [0.8104]}
TRAIINING epoch@5 ::  acc@0.612  loss@1.107
[[1281   51   86   43   15   41   50   94  600  239]
 [  33 1573   11    0   12    2   56   16  184  613]
 [ 317    8  314  298  262  259  551  295  139   57]
 [ 113   11  240  367  146  669  539  267   84   64]
 [  89    6  174  102  753  107  512  641   49   67]
 [  76    6  146  340  131 1148  212  394   25   22]
 [  40   41  160  161  224   88 4096   57   96   37]
 [ 112   10  143  100  284  311   68 3760   33  179]
 [ 408  134   48   23    2   12   78   22 4086  187]
 [ 159  387   32    7   38    6   40  105  174 4052]]
TESTING class wise acc@5 :: {0: [0.692], 1: [0.68], 2: [0.082], 3: [0.194], 4: [0.354], 5: [0.206], 6: [0.687], 7: [0.838], 8: [0.671], 9: [0.905]}
TESTING epoch@5 ::  acc@0.531  loss@1.355
Epoch@@6
[[692  12  14  28   4   2   7  53  66 122]
 [ 10 680   0   0   1   0   9   4  45 251]
 [146   6  82 181 115  24 124 250  18  54]
 [ 59   7  70 194  62  64 118 237  56 133]
 [ 44   0  41  33 354   2  85 400   4  37]
 [ 62   6  38 194  36 206  42 339  13  64]
 [ 11  26  35  33  79   1 687  23  47  58]
 [ 28   1   2  28  26  15   3 838   0  59]
 [186  28   9   3   0   1   2   6 671  94]
 [ 17  43   2   1   2   0   1  18  11 905]]
TRAINING class wise acc@6 :: {0: [0.6328], 1: [0.7372], 2: [0.2436], 3: [0.2092], 4: [0.4628], 5: [0.4792], 6: [0.8306], 7: [0.7828], 8: [0.8586], 9: [0.854]}
TRAIINING epoch@6 ::  acc@0.673  loss@0.955
[[1582   23  139   51   10   22   41   79  369  184]
 [  22 1843   19    1    9    0   50    8  162  386]
 [ 315   14  609  289  302  178  438  223   88   44]
 [ 103   12  317  523  138  635  430  232   62   48]
 [  82    4  222   99 1157   93  317  442   23   61]
 [  48    2  167  422  115 1198  152  358   16   22]
 [  25   42  207  167  193   69 4153   35   84   25]
 [ 100    2  155  105  277  265   32 3914   20  130]
 [ 285  108   79   15    4    3   51   13 4293  149]
 [ 126  246   62    8   24    7   27   93  137 4270]]
TESTING class wise acc@6 :: {0: [0.732], 1: [0.759], 2: [0.255], 3: [0.257], 4: [0.407], 5: [0.609], 6: [0.647], 7: [0.852], 8: [0.553], 9: [0.773]}
TESTING epoch@6 ::  acc@0.584  loss@1.238
Epoch@@7
[[732  21  71  12   1  16   1  85  16  45]
 [  9 759  46   2   4   1  16  17   5 141]
 [130   2 255 101 107 159  84 151   6   5]
 [ 42   0 159 257  31 352  44 105   4   6]
 [ 18   1 108  19 407  98  71 273   1   4]
 [ 19   0  79 140  23 609   6 121   1   2]
 [  8   1 100 141  36  55 647  10   0   2]
 [  6   0  19   8  19  92   0 852   0   4]
 [227  57  56   9   2   4   9  18 553  65]
 [ 32  56  24   4   6   5   1  98   1 773]]
TRAINING class wise acc@7 :: {0: [0.6972], 1: [0.7856], 2: [0.33], 3: [0.2412], 4: [0.542], 5: [0.4936], 6: [0.8356], 7: [0.8166], 8: [0.8794], 9: [0.8784]}
TRAIINING epoch@7 ::  acc@0.708  loss@0.852
[[1743   16  179   34    3   15   17   69  278  146]
 [  22 1964   24    3    4    1   36    1  133  312]
 [ 280    6  825  263  331  125  366  183   89   32]
 [  78    1  390  603  118  673  368  181   50   38]
 [  62    5  253   74 1355   71  239  385   18   38]
 [  28    3  202  487  110 1234  121  291   16    8]
 [  25   29  226  190  194   62 4178   18   53   25]
 [  80    3  166  109  241  195   27 4083   17   79]
 [ 231   94   82   23    5    3   33    9 4397  123]
 [ 115  215   69    4   12    2   22   60  109 4392]]
TESTING class wise acc@7 :: {0: [0.817], 1: [0.598], 2: [0.338], 3: [0.015], 4: [0.739], 5: [0.278], 6: [0.704], 7: [0.775], 8: [0.923], 9: [0.816]}
TESTING epoch@7 ::  acc@0.600  loss@1.289
Epoch@@8
[[817   2  37   0   6   0   4  11 116   7]
 [ 38 598   0   0   1   0   1   0 197 165]
 [159   1 338   3 256  19  86  66  51  21]
 [ 64   9 252  15 225  97  82 112  92  52]
 [ 41   2  95   0 739   0  24  71  19   9]
 [ 36   1 167  16 191 278  26 215  30  40]
 [ 11  26  71   2 129   2 704   7  37  11]
 [ 27   0  44   0 104   8   0 775   8  34]
 [ 57   2   7   0   0   0   0   2 923   9]
 [ 75  11   9   0   2   0   1   3  83 816]]
TRAINING class wise acc@8 :: {0: [0.7324], 1: [0.8248], 2: [0.4156], 3: [0.2892], 4: [0.6032], 5: [0.5232], 6: [0.8522], 7: [0.8424], 8: [0.9004], 9: [0.8978]}
TRAIINING epoch@8 ::  acc@0.741  loss@0.765
[[1831   10  186   32    5    7   11   62  242  114]
 [  20 2062   19    0    3    1   33    2  102  258]
 [ 271    6 1039  244  274   90  312  167   73   24]
 [  72    2  421  723  119  626  304  153   43   37]
 [  37    1  301   73 1508   56  187  304    8   25]
 [  21    2  201  498  102 1308  102  250    8    8]
 [  16   35  253  176  123   52 4261   18   52   14]
 [  62    2  182   94  189  159   12 4212   13   75]
 [ 194   70   92   11    3    3   29    6 4502   90]
 [ 111  173   71    3    8    3   18   37   87 4489]]
TESTING class wise acc@8 :: {0: [0.791], 1: [0.781], 2: [0.322], 3: [0.322], 4: [0.793], 5: [0.403], 6: [0.738], 7: [0.903], 8: [0.908], 9: [0.812]}
TESTING epoch@8 ::  acc@0.677  loss@0.984
Epoch@@9
[[791   2  55   3  12   0   1  36  78  22]
 [ 21 781  10   0   0   0   1   4  96  87]
 [120   1 322  64 280  14  50 117  20  12]
 [ 43   2 186 322 134 104  38 134  29   8]
 [ 11   0  34   9 793   6  22 114   8   3]
 [ 12   0  73 227  91 403  11 173   7   3]
 [  9   4  91  54  81   1 738   7  14   1]
 [  5   0  15   9  51  10   0 903   2   5]
 [ 42   7  16   3   4   0   1   7 908  12]
 [ 54  49  16   0   3   0   0  30  36 812]]
TRAINING class wise acc@9 :: {0: [0.7608], 1: [0.8348], 2: [0.4964], 3: [0.3476], 4: [0.6556], 5: [0.5336], 6: [0.8658], 7: [0.8568], 8: [0.9136], 9: [0.9044]}
TRAIINING epoch@9 ::  acc@0.765  loss@0.691
[[1902    7  187   23    3    2    8   60  202  106]
 [  15 2087   23    1    0    0   22    2   80  270]
 [ 244    7 1241  200  237   85  269  122   57   38]
 [  63    3  429  869   99  565  269  143   39   21]
 [  31    2  283   65 1639   57  140  256    7   20]
 [  17    1  163  565   90 1334   87  230    7    6]
 [  15   23  248  194  108   28 4329    7   41    7]
 [  55    0  169   83  174  161   11 4284    4   59]
 [ 149   56   74   18    1    2   27    5 4568  100]
 [  83  177   70    5   10    0    6   36   91 4522]]
TESTING class wise acc@9 :: {0: [0.714], 1: [0.761], 2: [0.719], 3: [0.174], 4: [0.427], 5: [0.596], 6: [0.856], 7: [0.554], 8: [0.865], 9: [0.638]}
TESTING epoch@9 ::  acc@0.630  loss@1.106
Epoch@@10
[[714   1 154   5   2   3   3   6 109   3]
 [ 14 761  36   2   1   1  18   1 143  23]
 [ 40   0 719  32  32  37 103  12  25   0]
 [ 22   0 379 174  27 240 124  11  23   0]
 [  5   1 394   5 427  24 125   7  12   0]
 [  4   0 201  91  37 596  51  13   7   0]
 [  2   0  96  17   9   6 856   0  14   0]
 [  4   0 194   2 152  72  17 554   3   2]
 [ 56   2  52  10   2   1  10   0 865   2]
 [ 53  95 107   2  13   5  13   5  69 638]]
TRAINING class wise acc@10 :: {0: [0.7696], 1: [0.858], 2: [0.5428], 3: [0.4284], 4: [0.6944], 5: [0.568], 6: [0.8724], 7: [0.8684], 8: [0.9242], 9: [0.9142]}
TRAIINING epoch@10 ::  acc@0.787  loss@0.640
[[1924    4  204   27    3    7    3   52  181   95]
 [  14 2145   21    2    0    0   17    2   79  220]
 [ 214    9 1357  214  203   63  251  118   46   25]
 [  63    3  388 1071   98  480  224  122   34   17]
 [  28    1  275   54 1736   48  121  214    5   18]
 [  16    0  154  529   89 1420   69  215    3    5]
 [  12   22  260  165   81   35 4362    9   42   12]
 [  58    1  162   79  160  133   14 4342    8   43]
 [ 149   51   65    5    0    2   30    2 4621   75]
 [  74  146   74    4   10    0    9   31   81 4571]]
TESTING class wise acc@10 :: {0: [0.813], 1: [0.863], 2: [0.607], 3: [0.433], 4: [0.654], 5: [0.389], 6: [0.913], 7: [0.859], 8: [0.814], 9: [0.817]}
TESTING epoch@10 ::  acc@0.716  loss@0.867
Epoch@@11
[[813   4  90   5   4   0   0  19  43  22]
 [  6 863  22   0   0   0  20   4  37  48]
 [ 87   0 607  50  70   9 137  39   1   0]
 [ 28   1 234 433  55  61 140  39   6   3]
 [ 11   1 143  22 654  11 108  49   0   1]
 [  5   0 146 290  51 389  45  73   1   0]
 [  2   0  56  15   8   1 913   2   3   0]
 [ 10   0  61  18  36   9   5 859   0   2]
 [ 75  20  44   3   1   0  15   8 814  20]
 [ 32  56  50   0   2   0   8  26   9 817]]
TRAINING class wise acc@11 :: {0: [0.8012], 1: [0.876], 2: [0.578], 3: [0.4772], 4: [0.7144], 5: [0.596], 6: [0.8858], 7: [0.8872], 8: [0.9334], 9: [0.9254]}
TRAIINING epoch@11 ::  acc@0.808  loss@0.584
[[2003    7  176   30    5    2    7   44  133   93]
 [   9 2190   22    0    2    1   15    1   74  186]
 [ 200    6 1445  197  192   56  224  102   46   32]
 [  60    4  370 1193   82  466  184  102   23   16]
 [  33    1  279   61 1786   41  102  180   10    7]
 [  14    0  146  507   88 1490   74  173    2    6]
 [  14   23  239  138   83   26 4429    7   37    4]
 [  48    1  134   79  141  125    2 4436    2   32]
 [ 125   42   75   15    1    0   19    1 4667   55]
 [  59  123   84    4    3    0    4   32   64 4627]]
TESTING class wise acc@11 :: {0: [0.857], 1: [0.832], 2: [0.357], 3: [0.222], 4: [0.723], 5: [0.355], 6: [0.779], 7: [0.911], 8: [0.791], 9: [0.954]}
TESTING epoch@11 ::  acc@0.678  loss@1.074
Epoch@@12
[[857   8  12   2   5   0   0  16  21  79]
 [  6 832   1   1   0   0   1   0  22 137]
 [208   7 357  14 151  17  54  85   8  99]
 [134  12 166 222  79  71  85 133  14  84]
 [ 31   4  59   3 723   1   8 148   3  20]
 [ 42   5  85 103  45 355  28 298   3  36]
 [ 16  16  50   8 103   1 779   4   2  21]
 [ 17   0  15   4  15   0   0 911   0  38]
 [126  12   6   1   1   0   2   2 791  59]
 [ 12  23   1   0   2   0   1   2   5 954]]
TRAINING class wise acc@12 :: {0: [0.8148], 1: [0.8948], 2: [0.64], 3: [0.5396], 4: [0.732], 5: [0.6292], 6: [0.8952], 7: [0.9032], 8: [0.936], 9: [0.9292]}
TRAIINING epoch@12 ::  acc@0.827  loss@0.528
[[2037    6  160   30    7    2    2   43  138   75]
 [  10 2237   17    1    0    0   14    0   54  167]
 [ 163    7 1600  163  167   66  197   79   45   13]
 [  51    1  340 1349   72  381  164  109   19   14]
 [  24    1  275   43 1830   59   87  166    4   11]
 [  11    0  142  485   86 1573   47  154    1    1]
 [   8   17  215  142   67   25 4476    5   37    8]
 [  40    0  116   75  112  101    7 4516    1   32]
 [ 116   36   62    8    0    0   24    1 4680   73]
 [  72  116   66    1    8    0    7   31   53 4646]]
TESTING class wise acc@12 :: {0: [0.714], 1: [0.886], 2: [0.684], 3: [0.529], 4: [0.665], 5: [0.521], 6: [0.782], 7: [0.894], 8: [0.943], 9: [0.827]}
TESTING epoch@12 ::  acc@0.744  loss@0.803
Epoch@@13
[[714   7 109  12   5   0   0  11 119  23]
 [  5 886  18   1   0   0   1   1  52  36]
 [ 41   1 684 102  47  19  31  41  24  10]
 [ 23   1 166 529  30 112  44  63  28   4]
 [  6   1 186  20 665  12  14  85   9   2]
 [  5   2  86 224  20 521   5 122  11   4]
 [  1   4 102  69  16   4 782   4  17   1]
 [  5   1  51  22  11  10   0 894   1   5]
 [ 25   7  19   1   1   0   0   0 943   4]
 [ 15  59  24   2   2   0   1   6  64 827]]
TRAINING class wise acc@13 :: {0: [0.8308], 1: [0.9012], 2: [0.6832], 3: [0.5764], 4: [0.7724], 5: [0.6492], 6: [0.906], 7: [0.9158], 8: [0.942], 9: [0.9346]}
TRAIINING epoch@13 ::  acc@0.844  loss@0.483
[[2077    3  158   30    2    4    0   29  124   73]
 [  10 2253   20    1    1    0   10    0   50  155]
 [ 149    3 1708  163  144   50  149   65   43   26]
 [  50    0  321 1441   69  361  140   86   23    9]
 [  14    1  220   47 1931   59   60  157    3    8]
 [   7    0  130  460   73 1623   52  148    5    2]
 [   9   16  208  122   51   27 4530    4   31    2]
 [  38    0   94   64  109   80    3 4579    2   31]
 [ 106   35   67   12    0    0   20    1 4710   49]
 [  47  107   73    2    5    0    4   31   58 4673]]
TESTING class wise acc@13 :: {0: [0.563], 1: [0.896], 2: [0.636], 3: [0.394], 4: [0.739], 5: [0.359], 6: [0.957], 7: [0.693], 8: [0.946], 9: [0.761]}
TESTING epoch@13 ::  acc@0.694  loss@1.072
Epoch@@14
[[563   6 145   8   3   0  13   5 235  22]
 [  1 896  14   0   0   0  20   0  48  21]
 [ 20   3 636  17  62   6 216   4  34   2]
 [  7   5 206 394  47  37 270   3  30   1]
 [  2   1 123   9 739   2 106  10   8   0]
 [  1   1 162 211  53 359 195  11   7   0]
 [  0   1  21   5   9   1 957   0   6   0]
 [  5   2 139  18  99  14  28 693   0   2]
 [  3   9  16   1   2   0  18   0 946   5]
 [ 11 112  42   1   5   0   9   1  58 761]]
TRAINING class wise acc@14 :: {0: [0.8576], 1: [0.9128], 2: [0.72], 3: [0.6176], 4: [0.7956], 5: [0.6728], 6: [0.914], 7: [0.9238], 8: [0.9492], 9: [0.9474]}
TRAIINING epoch@14 ::  acc@0.860  loss@0.429
[[2144    1  124   27    3    3    3   29  107   59]
 [   6 2282   16    1    0    0   12    0   54  129]
 [ 129    7 1800  147  128   40  146   51   33   19]
 [  46    0  280 1544   47  348  136   81   12    6]
 [   9    0  206   40 1989   48   69  125    3   11]
 [   6    1  102  470   58 1682   39  137    2    3]
 [   5   14  207   97   54   27 4570    2   23    1]
 [  17    0   96   57   92   93    0 4619    3   23]
 [  97   28   48    8    2    0   15    0 4746   56]
 [  47   94   61    1    3    1    1   16   39 4737]]
TESTING class wise acc@14 :: {0: [0.813], 1: [0.895], 2: [0.644], 3: [0.723], 4: [0.491], 5: [0.681], 6: [0.709], 7: [0.798], 8: [0.821], 9: [0.706]}
TESTING epoch@14 ::  acc@0.728  loss@0.990
Epoch@@15
[[813   6  81  44   0   2   0  16  30   8]
 [  5 895  45  11   0   1  10   0  17  16]
 [ 51   2 644 156  29  63  31  18   4   2]
 [ 15   2  91 723  10 124  19  10   6   0]
 [  8   0 144 141 491 110  23  82   1   0]
 [  4   0  34 256   6 681   5  13   1   0]
 [  5   3  79 184   5  12 709   0   3   0]
 [ 14   0  32  58   9  87   1 798   0   1]
 [ 83   6  35  39   0   1   5   2 821   8]
 [ 41 104  93  22   2   8   1  11  12 706]]
TRAINING class wise acc@15 :: {0: [0.8644], 1: [0.9176], 2: [0.7444], 3: [0.6332], 4: [0.8052], 5: [0.7004], 6: [0.9112], 7: [0.9274], 8: [0.9516], 9: [0.9452]}
TRAIINING epoch@15 ::  acc@0.867  loss@0.411
[[2161    1  109   40    3    0    1   25   95   65]
 [   2 2294   16    1    1    0   10    1   43  132]
 [ 117    6 1861  123  136   45  122   43   31   16]
 [  45    0  259 1583   52  347  120   68   21    5]
 [  12    0  195   35 2013   51   63  117    1   13]
 [   9    1   99  398   70 1751   44  125    1    2]
 [   3   18  191  116   56   26 4556    1   29    4]
 [  23    1   81   53   87   79    5 4637    2   32]
 [ 102   26   43   14    0    0   21    0 4758   36]
 [  36  103   56    1    4    0    1   23   50 4726]]
TESTING class wise acc@15 :: {0: [0.813], 1: [0.718], 2: [0.778], 3: [0.629], 4: [0.719], 5: [0.33], 6: [0.801], 7: [0.831], 8: [0.889], 9: [0.85]}
TESTING epoch@15 ::  acc@0.736  loss@0.874
Epoch@@16
[[813   1  70  18   4   0   3  13  64  14]
 [ 21 718  32   5   0   0  17   2  82 123]
 [ 57   0 778  39  53   4  30  28   6   5]
 [ 19   1 213 629  27  21  47  30  10   3]
 [ 17   0 171  26 719   9  22  33   2   1]
 [  7   0 170 414  21 330  15  41   2   0]
 [  7   0 131  39  17   0 801   1   4   0]
 [ 14   0  64  43  39   8   1 831   0   0]
 [ 52   1  32   8   0   0   5   1 889  12]
 [ 47  12  32   6   1   0   7  14  31 850]]
TRAINING class wise acc@16 :: {0: [0.8812], 1: [0.9292], 2: [0.7968], 3: [0.6856], 4: [0.84], 5: [0.728], 6: [0.9298], 7: [0.9444], 8: [0.9588], 9: [0.953]}
TRAIINING epoch@16 ::  acc@0.888  loss@0.355
[[2203    2   87   28    0    1    2   33  101   43]
 [   5 2323   14    0    0    0   10    1   33  114]
 [ 103    4 1992   90   93   25  111   46   23   13]
 [  39    1  207 1714   45  301  110   73    9    1]
 [   4    1  171   20 2100   52   53   93    3    3]
 [   6    1   69  393   63 1820   32  111    3    2]
 [   2   13  167   82   33   26 4649    2   22    4]
 [  20    0   57   45   65   73    0 4722    0   18]
 [  86   22   41   13    0    0   18    1 4794   25]
 [  34   93   43    1    8    0    0   20   36 4765]]
TESTING class wise acc@16 :: {0: [0.782], 1: [0.762], 2: [0.765], 3: [0.685], 4: [0.692], 5: [0.465], 6: [0.861], 7: [0.877], 8: [0.813], 9: [0.878]}
TESTING epoch@16 ::  acc@0.758  loss@0.899
Epoch@@17
[[782   1  92  31   4   1   8  22  26  33]
 [ 11 762  42   7   2   1  31   4  10 130]
 [ 41   0 765  62  40   8  56  24   1   3]
 [ 22   0 132 685  34  47  50  23   4   3]
 [  7   0 142  39 692  11  52  55   0   2]
 [  5   0 118 280  56 465  15  61   0   0]
 [  2   0  55  65  12   2 861   1   2   0]
 [  8   0  41  38  27   7   2 877   0   0]
 [ 79   8  35  20   1   0   9   1 813  34]
 [ 19  17  51   8   2   0  12  10   3 878]]
TRAINING class wise acc@17 :: {0: [0.902], 1: [0.938], 2: [0.806], 3: [0.722], 4: [0.8608], 5: [0.7616], 6: [0.9416], 7: [0.9518], 8: [0.9642], 9: [0.959]}
TRAIINING epoch@17 ::  acc@0.902  loss@0.308
[[2255    0   90   21    1    1    0   17   72   43]
 [   3 2345   15    0    1    0    9    0   30   97]
 [  93    7 2015  104   95   23   89   34   23   17]
 [  37    0  185 1805   33  275   91   58   14    2]
 [   4    1  172   11 2152   45   37   75    0    3]
 [   3    0   64  355   52 1904   21  100    0    1]
 [   1   14  135   75   33   15 4708    1   18    0]
 [  23    0   49   33   58   58    1 4759    0   19]
 [  60   23   30   15    0    0   12    0 4821   39]
 [  35   74   45    1    3    1    1   14   31 4795]]
TESTING class wise acc@17 :: {0: [0.715], 1: [0.783], 2: [0.535], 3: [0.648], 4: [0.638], 5: [0.588], 6: [0.791], 7: [0.846], 8: [0.9], 9: [0.95]}
TESTING epoch@17 ::  acc@0.739  loss@0.939
Epoch@@18
[[715   4  29  14   1   0   2   7 144  84]
 [  6 783   5   2   1   0   2   0  13 188]
 [104   3 535 112  67  41  59  31  29  19]
 [ 35   4  83 648  21  89  43  35  27  15]
 [ 30   1 104  82 638  39  31  60  12   3]
 [  9   2  50 248  28 588  26  40   7   2]
 [  8   6  56  90  17   8 791   3  15   6]
 [ 22   0  18  39  20  38   1 846   3  13]
 [ 23  11  10   6   0   0   2   2 900  46]
 [  7  14   7   2   1   0   0   7  12 950]]
TRAINING class wise acc@18 :: {0: [0.8972], 1: [0.9352], 2: [0.818], 3: [0.746], 4: [0.866], 5: [0.7764], 6: [0.9406], 7: [0.952], 8: [0.964], 9: [0.962]}
TRAIINING epoch@18 ::  acc@0.905  loss@0.295
[[2243    0   88   33    0    0    0   16   79   41]
 [   2 2338   12    0    0    0    9    0   25  114]
 [  84    1 2045   94   94   22   83   35   29   13]
 [  42    1  153 1865   26  273   79   51    7    3]
 [   2    1  143   20 2165   43   44   79    0    3]
 [   8    0   45  324   58 1941   20  104    0    0]
 [   4   14  137   68   42   10 4703    1   21    0]
 [  17    0   46   30   66   66    0 4760    0   15]
 [  64   22   41    3    0    0   14    1 4820   35]
 [  32   76   34    1    3    0    0   15   29 4810]]
TESTING class wise acc@18 :: {0: [0.78], 1: [0.849], 2: [0.806], 3: [0.573], 4: [0.667], 5: [0.449], 6: [0.874], 7: [0.874], 8: [0.915], 9: [0.873]}
TESTING epoch@18 ::  acc@0.766  loss@0.823
Epoch@@19
[[780   1 126   8   4   0   4  13  53  11]
 [  7 849  21   2   1   0   2   1  37  80]
 [ 33   0 806  23  26   4  65  31   8   4]
 [ 14   1 198 573  28  51  89  28  14   4]
 [  8   1 176  16 667  18  64  46   4   0]
 [  1   0 162 281  23 449  38  40   4   2]
 [  4   0  77  30   6   0 874   2   7   0]
 [  8   0  57  15  18  21   4 874   0   3]
 [ 38   8  16   5   0   0   6   2 915  10]
 [ 26  31  30   0   1   0   3   5  31 873]]
TRAINING class wise acc@19 :: {0: [0.9164], 1: [0.9596], 2: [0.85], 3: [0.7688], 4: [0.8848], 5: [0.8024], 6: [0.9368], 7: [0.9582], 8: [0.9704], 9: [0.9696]}
TRAIINING epoch@19 ::  acc@0.918  loss@0.258
[[2291    1   64   23    1    1    1   15   59   44]
 [   1 2399    7    0    1    0    4    0   21   67]
 [  78    2 2125   63   71   13   91   28   19   10]
 [  30    0  144 1922   24  246   84   42    7    1]
 [   5    0  118   12 2212   45   33   68    2    5]
 [   4    0   50  290   50 2006   25   75    0    0]
 [   3    9  139   87   37   15 4684    2   22    2]
 [  21    0   38   32   39   65    0 4791    0   14]
 [  48   23   29   12    0    0   16    0 4852   20]
 [  29   55   26    0    4    0    0   15   23 4848]]
TESTING class wise acc@19 :: {0: [0.831], 1: [0.918], 2: [0.637], 3: [0.479], 4: [0.72], 5: [0.719], 6: [0.867], 7: [0.874], 8: [0.807], 9: [0.837]}
TESTING epoch@19 ::  acc@0.769  loss@0.897
Epoch@@20
[[831   4  79  13   7   0   7  20  26  13]
 [ 10 918  12   1   0   0   5   1  17  36]
 [ 57   4 637  59  65  55  82  36   1   4]
 [ 32   4  94 479  40 215  58  64   6   8]
 [ 10   2  91  32 720  43  52  49   1   0]
 [  4   3  42  92  39 719   7  89   1   4]
 [  5   3  41  50   9  16 867   6   2   1]
 [ 11   0  35   7  47  22   0 874   0   4]
 [111  20  29   4   0   0   8   4 807  17]
 [ 39  85  19   2   3   0   2   8   5 837]]
TRAINING class wise acc@20 :: {0: [0.9324], 1: [0.9584], 2: [0.8584], 3: [0.7868], 4: [0.8996], 5: [0.8248], 6: [0.9506], 7: [0.9602], 8: [0.9722], 9: [0.968]}
TRAIINING epoch@20 ::  acc@0.926  loss@0.234
[[2331    0   61   15    1    0    0   13   54   25]
 [   0 2396    8    0    0    0    5    0   21   70]
 [  70    2 2146   73   70   19   62   27   19   12]
 [  26    0  118 1967   30  241   78   29   10    1]
 [   1    1  106   15 2249   41   29   52    1    5]
 [   2    0   53  249   37 2062   20   76    1    0]
 [   0    8  119   64   25   16 4753    0   14    1]
 [  16    0   42   26   49   51    0 4801    0   15]
 [  47   19   23   12    0    0   10    0 4861   28]
 [  39   61   31    1    2    0    0    9   17 4840]]
TESTING class wise acc@20 :: {0: [0.795], 1: [0.827], 2: [0.728], 3: [0.302], 4: [0.722], 5: [0.51], 6: [0.847], 7: [0.918], 8: [0.935], 9: [0.905]}
TESTING epoch@20 ::  acc@0.749  loss@1.044
Epoch@@21
[[795   0  51   2  12   1   1  16  98  24]
 [ 18 827  15   0   0   0   4   3  38  95]
 [ 76   0 728   4  48   8  42  58  22  14]
 [ 51   2 208 302  65 123  91 115  26  17]
 [ 21   0 123   3 722   7  21  89   8   6]
 [  7   0 123  40  70 510  31 206   8   5]
 [  5   7  79   8  19   6 847   4  20   5]
 [ 13   0  33   1  25   1   0 918   2   7]
 [ 32   6   9   0   0   2   2   3 935  11]
 [ 18  19  11   0   2   1   4  12  28 905]]
TRAINING class wise acc@21 :: {0: [0.93], 1: [0.9532], 2: [0.8524], 3: [0.7976], 4: [0.8944], 5: [0.8364], 6: [0.9572], 7: [0.9662], 8: [0.9708], 9: [0.9714]}
TRAIINING epoch@21 ::  acc@0.928  loss@0.226
[[2325    0   57   19    1    0    0   20   61   17]
 [   2 2383    7    0    0    0   10    0   26   72]
 [  67    4 2131   82   85   24   61   17   15   14]
 [  25    0  127 1994   15  230   67   33    8    1]
 [   5    1  118   15 2236   38   24   57    1    5]
 [   2    0   37  242   39 2091   19   69    0    1]
 [   2   10   87   60   24   12 4786    0   19    0]
 [  17    0   29   18   42   47    0 4831    0   16]
 [  44   22   33    8    0    0   10    0 4854   29]
 [  23   55   22    0    5    0    0   14   24 4857]]
TESTING class wise acc@21 :: {0: [0.846], 1: [0.863], 2: [0.499], 3: [0.574], 4: [0.553], 5: [0.743], 6: [0.926], 7: [0.863], 8: [0.881], 9: [0.833]}
TESTING epoch@21 ::  acc@0.758  loss@1.170
Epoch@@22
[[846   3  35  19   1   3  11  10  54  18]
 [  5 863   8   3   0   1  20   1  34  65]
 [ 93   2 499  92  34  79 163  29   7   2]
 [ 24   1  39 574  23 174 126  28  11   0]
 [ 31   1  75  45 553  95 131  65   3   1]
 [  2   0  12 136  15 743  45  42   3   2]
 [  3   0  11  33   2  16 926   3   6   0]
 [ 16   0  11  28  13  49  14 863   1   5]
 [ 69   7   6  13   0   2   9   2 881  11]
 [ 31  43  23   7   7   4  14  12  26 833]]
TRAINING class wise acc@22 :: {0: [0.9324], 1: [0.9632], 2: [0.8796], 3: [0.8284], 4: [0.9152], 5: [0.8532], 6: [0.9578], 7: [0.971], 8: [0.9766], 9: [0.9752]}
TRAIINING epoch@22 ::  acc@0.938  loss@0.198
[[2331    0   50   26    0    0    0   17   49   27]
 [   0 2408   11    0    0    0    7    0   21   53]
 [  65    4 2199   47   63   16   54   22   18   12]
 [  31    0  102 2071   14  187   52   31    9    3]
 [   2    0   93    8 2288   35   23   48    0    3]
 [   4    0   33  206   33 2133   21   68    1    1]
 [   1   11  101   50   20   14 4789    1   13    0]
 [  15    0   26   12   39   44    0 4855    0    9]
 [  47    8   18   12    0    0    8    0 4883   24]
 [  22   44   29    3    1    0    1    9   15 4876]]
TESTING class wise acc@22 :: {0: [0.709], 1: [0.865], 2: [0.673], 3: [0.61], 4: [0.639], 5: [0.659], 6: [0.873], 7: [0.89], 8: [0.926], 9: [0.94]}
TESTING epoch@22 ::  acc@0.778  loss@0.919
Epoch@@23
[[709   8  62  18   2   1   3  10 128  59]
 [  2 865   4   2   0   0   0   0  22 105]
 [ 48   9 673  76  37  36  54  34  15  18]
 [ 25   5 102 610  25 115  42  43  16  17]
 [  5   6 113  40 639  29  30 118   8  12]
 [  2   3  55 185  24 659   8  54   5   5]
 [  2   9  40  41  11  11 873   3   8   2]
 [ 10   0  18  21   2  29   0 890   3  27]
 [ 21  13   9   2   0   0   5   2 926  22]
 [  5  23   9   1   1   0   1   1  19 940]]
TRAINING class wise acc@23 :: {0: [0.9264], 1: [0.9576], 2: [0.896], 3: [0.8396], 4: [0.9216], 5: [0.8644], 6: [0.9572], 7: [0.9724], 8: [0.9766], 9: [0.9754]}
TRAIINING epoch@23 ::  acc@0.941  loss@0.193
[[2316    1   61   26    0    0    1   11   56   28]
 [   0 2394    9    0    0    0    3    0   19   75]
 [  50    1 2240   51   47   15   60   16    8   12]
 [  37    0   88 2099   11  163   61   31    9    1]
 [   3    0   88    4 2304   23   25   46    1    6]
 [   2    0   25  191   40 2161   14   67    0    0]
 [   0   11  100   52   19   11 4786    0   19    2]
 [   4    0   18   15   37   53    1 4862    0   10]
 [  52   16   13    6    0    1    9    0 4883   20]
 [  18   52   20    1    2    0    1   12   17 4877]]
TESTING class wise acc@23 :: {0: [0.864], 1: [0.903], 2: [0.607], 3: [0.503], 4: [0.744], 5: [0.539], 6: [0.947], 7: [0.831], 8: [0.87], 9: [0.91]}
TESTING epoch@23 ::  acc@0.772  loss@1.031
Epoch@@24
[[864   7  21   5   3   0  10   6  51  33]
 [  8 903   3   2   1   0  10   0  16  57]
 [ 95   2 607  31  67  26 128  29   7   8]
 [ 44   4 125 503  37  66 168  30  10  13]
 [ 24   1  72  19 744  15  87  34   4   0]
 [ 14   2  72 175  42 539  84  64   2   6]
 [  3   1  24   7  10   2 947   2   3   1]
 [ 22   1  34   8  56  14  10 831   1  23]
 [ 61  18  13   1   1   0   8   3 870  25]
 [  9  52   8   0   1   0   3   1  16 910]]
TRAINING class wise acc@24 :: {0: [0.9472], 1: [0.972], 2: [0.8992], 3: [0.8604], 4: [0.9344], 5: [0.88], 6: [0.9614], 7: [0.9736], 8: [0.9816], 9: [0.9774]}
TRAIINING epoch@24 ::  acc@0.949  loss@0.161
[[2368    0   39   15    0    0    0    9   39   30]
 [   0 2430    8    0    0    0    6    0   17   39]
 [  34    1 2248   51   49   10   51   19   16   21]
 [  22    1   77 2151   12  156   49   27    5    0]
 [   0    1   62    2 2336   36   19   42    0    2]
 [   1    0   23  173   30 2200   14   58    0    1]
 [   0   10   85   49   21   15 4807    0   13    0]
 [   9    0   19   13   32   48    0 4868    0   11]
 [  31   14   21    5    0    0   10    0 4908   11]
 [  22   43   22    0    2    0    1    7   16 4887]]
TESTING class wise acc@24 :: {0: [0.791], 1: [0.817], 2: [0.731], 3: [0.661], 4: [0.719], 5: [0.482], 6: [0.854], 7: [0.88], 8: [0.928], 9: [0.926]}
TESTING epoch@24 ::  acc@0.779  loss@0.942
Epoch@@25
[[791   2  54  12   4   0   4  11  85  37]
 [  8 817  16   1   0   0   6   1  46 105]
 [ 54   0 731  62  56  10  39  22  16  10]
 [ 16   2 117 661  37  42  56  39  18  12]
 [ 12   1 121  39 719  20  34  48   5   1]
 [  3   0  64 315  38 482  21  69   5   3]
 [  2   1  63  35  22   3 854   4  14   2]
 [  9   0  30  31  27   8   1 880   1  13]
 [ 26   5  14   4   0   0   2   1 928  20]
 [ 10  20  18   2   2   0   0   4  18 926]]
TRAINING class wise acc@25 :: {0: [0.9428], 1: [0.9632], 2: [0.906], 3: [0.8668], 4: [0.932], 5: [0.88], 6: [0.9656], 7: [0.9744], 8: [0.9776], 9: [0.979]}
TRAIINING epoch@25 ::  acc@0.949  loss@0.164
[[2357    0   44   15    0    0    0    9   56   19]
 [   0 2408    8    0    2    0    8    0   23   51]
 [  52    1 2265   48   35   11   54   12   12   10]
 [  22    1   82 2167    8  148   49   16    6    1]
 [   2    0   60    6 2330   33   21   44    0    4]
 [   1    0   25  164   34 2200   16   60    0    0]
 [   2    8   80   36   20   14 4828    0   12    0]
 [   8    0   17   14   38   41    0 4872    0   10]
 [  49   17   13    4    0    0   11    0 4888   18]
 [  18   34   20    0    4    0    0   12   17 4895]]
TESTING class wise acc@25 :: {0: [0.771], 1: [0.854], 2: [0.719], 3: [0.507], 4: [0.782], 5: [0.696], 6: [0.911], 7: [0.862], 8: [0.893], 9: [0.86]}
TESTING epoch@25 ::  acc@0.785  loss@1.010
Epoch@@26
[[771   1  91  24   9   1  12  14  49  28]
 [  5 854  17   5   1   0  25   1  38  54]
 [ 40   2 719  28  73  26  82  21   9   0]
 [ 15   2 113 507  43 148 128  33   8   3]
 [  7   1  85  24 782  13  43  41   2   2]
 [  3   0  70  90  51 696  47  42   1   0]
 [  1   0  44  18  13   7 911   3   3   0]
 [  9   0  29  20  43  24  10 862   0   3]
 [ 39   4  24   8   0   1  20   1 893  10]
 [ 25  37  37   2   4   2  11   3  19 860]]
TRAINING class wise acc@26 :: {0: [0.9564], 1: [0.9664], 2: [0.9164], 3: [0.8864], 4: [0.93], 5: [0.896], 6: [0.9682], 7: [0.9766], 8: [0.984], 9: [0.9772]}
TRAIINING epoch@26 ::  acc@0.955  loss@0.149
[[2391    0   37   12    0    0    0    8   36   16]
 [   0 2416    3    0    0    0    8    0   16   57]
 [  50    1 2291   36   38   12   39   10   13   10]
 [  19    0   64 2216    7  130   39   19    6    0]
 [   0    0   73    2 2325   30   21   41    0    8]
 [   0    1   17  142   36 2240   13   51    0    0]
 [   0    9   70   36   14   12 4841    0   18    0]
 [  12    0   15   16   27   37    0 4883    0   10]
 [  27   12   15    7    0    0    8    1 4920   10]
 [  16   46   28    0    3    0    0   11   10 4886]]
TESTING class wise acc@26 :: {0: [0.845], 1: [0.858], 2: [0.664], 3: [0.703], 4: [0.599], 5: [0.711], 6: [0.839], 7: [0.887], 8: [0.817], 9: [0.903]}
TESTING epoch@26 ::  acc@0.783  loss@1.014
Epoch@@27
[[845   1  51  33   5   2   3  13  23  24]
 [  8 858  31   9   0   0   8   1  12  73]
 [ 63   0 664 113  29  38  49  34   3   7]
 [ 14   2  74 703  13 126  36  23   4   5]
 [ 11   1 126  67 599  80  27  87   2   0]
 [  8   0  33 179   8 711   5  54   1   1]
 [  5   0  39  75   6  28 839   4   4   0]
 [ 18   0  13  51   5  18   3 887   0   5]
 [ 64  14  39  14   1   1  12   3 817  35]
 [ 24  34  14   4   1   0   1  11   8 903]]
TRAINING class wise acc@27 :: {0: [0.9612], 1: [0.9792], 2: [0.9404], 3: [0.9156], 4: [0.9464], 5: [0.9232], 6: [0.9774], 7: [0.9836], 8: [0.9844], 9: [0.9848]}
TRAIINING epoch@27 ::  acc@0.966  loss@0.113
[[2403    0   30    9    0    0    0    7   37   14]
 [   0 2448    4    0    0    0    4    0    8   36]
 [  30    0 2351   22   38    6   27    8   10    8]
 [   7    0   45 2289    3  100   41   11    4    0]
 [   0    1   53    1 2366   40   13   22    0    4]
 [   2    0   21   95   28 2308   13   33    0    0]
 [   0    6   42   33   13   12 4887    0    7    0]
 [   6    0   11    9   16   30    0 4918    0   10]
 [  35    8   11    5    0    0    7    0 4922   12]
 [  10   34   16    0    2    0    0    8    6 4924]]
TESTING class wise acc@27 :: {0: [0.85], 1: [0.858], 2: [0.639], 3: [0.587], 4: [0.748], 5: [0.709], 6: [0.792], 7: [0.847], 8: [0.917], 9: [0.906]}
TESTING epoch@27 ::  acc@0.785  loss@1.052
Epoch@@28
[[850   1  25  16   9   1   2   8  70  18]
 [  8 858   7   1   0   1   4   2  36  83]
 [ 93   2 639  69  63  43  27  25  20  19]
 [ 29   3 101 587  39 120  26  45  35  15]
 [ 17   1  99  27 748  34  16  41  12   5]
 [  7   1  44 141  31 709   4  52   7   4]
 [  4   5  60  55  32  23 792   8  19   2]
 [ 20   0  23  23  37  27   0 847   3  20]
 [ 41   4   6   5   0   1   4   2 917  20]
 [ 24  29   9   1   2   1   0   6  22 906]]
TRAINING class wise acc@28 :: {0: [0.9616], 1: [0.9756], 2: [0.9296], 3: [0.8916], 4: [0.9428], 5: [0.91], 6: [0.9718], 7: [0.976], 8: [0.9846], 9: [0.9842]}
TRAIINING epoch@28 ::  acc@0.960  loss@0.130
[[2404    1   29   16    1    0    1    9   29   10]
 [   0 2439    3    0    0    0    1    0   17   40]
 [  40    1 2324   28   45   10   22   11    8   11]
 [  19    0   58 2229    1  130   43   11    9    0]
 [   0    0   56    4 2357   22   18   40    1    2]
 [   1    0   14  130   27 2275    9   44    0    0]
 [   1    5   53   37   19   12 4859    0   14    0]
 [   4    0   24   15   35   35    0 4880    0    7]
 [  23   12   11    6    0    0    8    0 4923   17]
 [  11   38   15    1    0    0    0    5    9 4921]]
TESTING class wise acc@28 :: {0: [0.8], 1: [0.927], 2: [0.753], 3: [0.484], 4: [0.781], 5: [0.751], 6: [0.856], 7: [0.858], 8: [0.895], 9: [0.875]}
TESTING epoch@28 ::  acc@0.798  loss@0.920
Epoch@@29
[[800   4  86  13   6   3   4   7  40  37]
 [  5 927  11   0   0   1   3   1  11  41]
 [ 36   5 753  24  68  40  38  21   5  10]
 [ 17   5 128 484  47 222  38  41  12   6]
 [  6   1 105  12 781  31  28  34   2   0]
 [  5   2  74  71  38 751  10  45   1   3]
 [  7   6  54  27  19  23 856   2   6   0]
 [ 11   0  34   7  45  33   4 858   1   7]
 [ 41  16  23   4   0   0   4   1 895  16]
 [ 10  75  15   0   3   1   1   5  15 875]]
TRAINING class wise acc@29 :: {0: [0.9664], 1: [0.98], 2: [0.9396], 3: [0.918], 4: [0.9548], 5: [0.93], 6: [0.9768], 7: [0.9848], 8: [0.985], 9: [0.9824]}
TRAIINING epoch@29 ::  acc@0.968  loss@0.109
[[2416    1   28   10    2    0    0    4   28   11]
 [   1 2450    5    0    0    0    2    0    8   34]
 [  33    1 2349   29   31    5   20   10    8   14]
 [  16    0   42 2295    4   85   39   14    5    0]
 [   0    1   53    0 2387   22   12   24    0    1]
 [   1    0   15   88   22 2325   15   34    0    0]
 [   2    3   43   35   11    8 4884    0   14    0]
 [   6    0    9   13   23   17    0 4924    0    8]
 [  25    9   10    6    0    0    9    0 4925   16]
 [  10   34   16    0    2    0    1   10   15 4912]]
TESTING class wise acc@29 :: {0: [0.749], 1: [0.779], 2: [0.738], 3: [0.431], 4: [0.722], 5: [0.654], 6: [0.89], 7: [0.88], 8: [0.922], 9: [0.95]}
TESTING epoch@29 ::  acc@0.771  loss@1.096
Epoch@@30
[[749   0  83  17   6   2   2  18  77  46]
 [  5 779  10   0   1   1   6   0  28 170]
 [ 27   0 738  33  52  35  70  17  11  17]
 [ 18   2 191 431  36 144  83  53  15  27]
 [  6   0 128  13 722  29  36  58   3   5]
 [  2   0 106  99  27 654  19  74   4  15]
 [  2   2  53  19   8  14 890   5   4   3]
 [  8   0  35   7  15  15   1 880   2  37]
 [ 23   4  11   2   1   0   7   0 922  30]
 [  8  11  10   1   4   1   1   1  13 950]]
TRAINING class wise acc@30 :: {0: [0.9624], 1: [0.9772], 2: [0.932], 3: [0.91], 4: [0.9524], 5: [0.9288], 6: [0.9758], 7: [0.9838], 8: [0.9844], 9: [0.9842]}
TRAIINING epoch@30 ::  acc@0.966  loss@0.113
[[2406    0   29   12    0    0    0   11   27   15]
 [   0 2443    7    0    0    0    3    0   15   32]
 [  34    2 2330   36   28   10   33    9   10    8]
 [  20    0   60 2275    2   91   35    9    7    1]
 [   0    0   44    4 2381   18   14   37    0    2]
 [   0    0    9   92   29 2322    6   41    1    0]
 [   0   10   46   31   18    7 4879    1    8    0]
 [   6    0   10    9   27   24    0 4919    0    5]
 [  25   15   10    3    0    0   10    0 4922   15]
 [  10   28   20    0    2    0    0    5   14 4921]]
TESTING class wise acc@30 :: {0: [0.857], 1: [0.887], 2: [0.623], 3: [0.577], 4: [0.483], 5: [0.647], 6: [0.877], 7: [0.824], 8: [0.911], 9: [0.887]}
TESTING epoch@30 ::  acc@0.757  loss@1.303
Epoch@@31
[[857   6  20  11   1   0   5   3  70  27]
 [  7 887   6   2   0   0   3   0  32  63]
 [124   4 623  68  18  22  85  20  21  15]
 [ 57   5 109 577  15  90  78  28  33   8]
 [ 35   2 174  34 483  56 137  64  10   5]
 [ 19   3  59 164  11 647  46  36  12   3]
 [ 12   2  27  51   1   8 877   2  17   3]
 [ 51   0  38  23   5  25   6 824   1  27]
 [ 52  10   5   7   0   0   3   1 911  11]
 [ 20  42  13   2   0   0   3   0  33 887]]
TRAINING class wise acc@31 :: {0: [0.9596], 1: [0.9776], 2: [0.9444], 3: [0.9184], 4: [0.9572], 5: [0.94], 6: [0.9752], 7: [0.981], 8: [0.986], 9: [0.9842]}
TRAIINING epoch@31 ::  acc@0.968  loss@0.104
[[2399    0   30   11    0    0    0    9   36   15]
 [   0 2444    0    0    0    0    3    0   11   42]
 [  35    0 2361   20   23    3   28   12   11    7]
 [  15    0   43 2296    2   91   31   19    3    0]
 [   1    0   34    4 2393   22   13   31    1    1]
 [   0    0    8   84   18 2350   11   29    0    0]
 [   0    5   40   43   19    8 4876    0    8    1]
 [   9    0   17    9   21   24    0 4905    1   14]
 [  27   11   13    4    0    0    6    0 4930    9]
 [  14   26   21    0    3    0    0    7    8 4921]]
TESTING class wise acc@31 :: {0: [0.791], 1: [0.84], 2: [0.704], 3: [0.617], 4: [0.688], 5: [0.647], 6: [0.866], 7: [0.847], 8: [0.935], 9: [0.936]}
TESTING epoch@31 ::  acc@0.787  loss@1.123
Epoch@@32
[[791   1  48  14   1   0   3   3 100  39]
 [  8 840   4   1   0   1   2   0  51  93]
 [ 63   4 704  73  39  23  57  11  16  10]
 [ 39   5 118 617  25  82  52  28  23  11]
 [ 17   3 127  41 688  12  57  39  12   4]
 [  8   1  75 176  22 647  24  32   6   9]
 [ 10   4  41  43   8   8 866   3  14   3]
 [ 24   0  39  23  29  19   0 847   2  17]
 [ 29   3  10   4   0   0   4   1 935  14]
 [ 13  11  10   1   1   0   0   0  28 936]]
TRAINING class wise acc@32 :: {0: [0.9608], 1: [0.9804], 2: [0.9292], 3: [0.9176], 4: [0.9516], 5: [0.9328], 6: [0.975], 7: [0.985], 8: [0.986], 9: [0.9882]}
TRAIINING epoch@32 ::  acc@0.967  loss@0.106
[[2402    0   33   15    0    0    0    4   33   13]
 [   0 2451    4    0    0    0    4    0   10   31]
 [  33    5 2323   29   35    7   34   14   10   10]
 [  16    0   51 2294    5   86   37    9    1    1]
 [   1    0   55    2 2379   21   18   22    0    2]
 [   0    0   17   91   23 2332    5   32    0    0]
 [   0    5   54   37   14    4 4875    0   11    0]
 [  11    0   11    9   19   22    0 4925    0    3]
 [  24    9   13    6    0    0    6    0 4930   12]
 [   8   23   16    0    0    0    0    5    7 4941]]
TESTING class wise acc@32 :: {0: [0.737], 1: [0.853], 2: [0.68], 3: [0.515], 4: [0.704], 5: [0.532], 6: [0.92], 7: [0.951], 8: [0.879], 9: [0.925]}
TESTING epoch@32 ::  acc@0.770  loss@1.200
Epoch@@33
[[737   7  84  28   6   0  10  39  48  41]
 [  2 853   9   1   3   1  10   4  20  97]
 [ 36   1 680  25  77  11  91  62   5  12]
 [  8   1 100 515  59  46 135 123   7   6]
 [  4   1  94  25 704   3  64  99   1   5]
 [  1   0  46  82 121 532  54 163   1   0]
 [  0   0  27  20  14   3 920  13   2   1]
 [  3   0  10   7  16   4   3 951   0   6]
 [ 33   6  29  10   1   0  15   5 879  22]
 [  5  30  11   0   2   0   6   9  12 925]]
TRAINING class wise acc@33 :: {0: [0.9644], 1: [0.9832], 2: [0.9476], 3: [0.9408], 4: [0.9596], 5: [0.948], 6: [0.979], 7: [0.9868], 8: [0.9852], 9: [0.9888]}
TRAIINING epoch@33 ::  acc@0.973  loss@0.090
[[2411    0   17   11    0    0    0    7   38   16]
 [   0 2458    3    0    1    0    1    0   11   26]
 [  21    1 2369   22   28    9   27    6    7   10]
 [  15    0   28 2352    3   59   32    4    6    1]
 [   0    0   30    2 2399   22   17   28    0    2]
 [   0    0    7   65   22 2370    8   28    0    0]
 [   1    1   44   30   13    9 4895    0    7    0]
 [   3    0   11    9   22   16    0 4934    0    5]
 [  32   12   12    2    0    0    5    0 4926   11]
 [   9   21   12    0    0    0    0    4   10 4944]]
TESTING class wise acc@33 :: {0: [0.753], 1: [0.862], 2: [0.723], 3: [0.506], 4: [0.781], 5: [0.765], 6: [0.901], 7: [0.857], 8: [0.842], 9: [0.886]}
TESTING epoch@33 ::  acc@0.788  loss@1.167
Epoch@@34
[[753   4 113  34  11   4   3  10  42  26]
 [  3 862  32   0   2   2  17   2  10  70]
 [ 33   0 723  24  59  51  79  22   3   6]
 [  6   0 123 506  67 184  85  23   4   2]
 [  8   1  93  15 781  33  43  25   1   0]
 [  1   0  45  85  47 765  27  30   0   0]
 [  2   0  39  16  22  16 901   2   2   0]
 [  5   0  20  14  49  52   2 857   0   1]
 [ 28  25  39   9   4   4  17   2 842  30]
 [ 10  34  35   3  11   1   4  10   6 886]]
TRAINING class wise acc@34 :: {0: [0.9664], 1: [0.9828], 2: [0.9536], 3: [0.9416], 4: [0.9704], 5: [0.9444], 6: [0.9832], 7: [0.988], 8: [0.9894], 9: [0.988]}
TRAIINING epoch@34 ::  acc@0.975  loss@0.083
[[2416    0   25   10    0    0    0   10   21   18]
 [   0 2457    3    0    0    0    3    0    5   32]
 [  27    2 2384   21   19    9   19    5    7    7]
 [  16    0   28 2354    0   68   27    5    2    0]
 [   0    0   30    1 2426   21    9   12    0    1]
 [   0    0   16   71   25 2361    8   19    0    0]
 [   1    2   32   27    6    6 4916    0   10    0]
 [  11    0    6    4   18   18    0 4940    0    3]
 [  20    9    6    3    0    0    6    0 4947    9]
 [  13   26   14    0    0    0    0    3    4 4940]]
TESTING class wise acc@34 :: {0: [0.82], 1: [0.887], 2: [0.717], 3: [0.566], 4: [0.709], 5: [0.575], 6: [0.926], 7: [0.894], 8: [0.908], 9: [0.906]}
TESTING epoch@34 ::  acc@0.791  loss@1.168
Epoch@@35
[[820   4  73  11   7   0   4  11  50  20]
 [  6 887   7   2   0   0   7   1  26  64]
 [ 34   0 717  39  42  32  83  33  12   8]
 [ 20   3 110 566  34  88  96  52  20  11]
 [ 11   2  95  33 709  13  56  75   4   2]
 [  6   1  77 172  33 575  43  83   8   2]
 [  4   1  31  20   8   1 926   0   8   1]
 [ 10   1  23  17   9  22   8 894   1  15]
 [ 48  10  11   2   0   0   8   1 908  12]
 [ 16  38  12   2   1   0   3   4  18 906]]
TRAINING class wise acc@35 :: {0: [0.968], 1: [0.9832], 2: [0.9504], 3: [0.9456], 4: [0.972], 5: [0.9472], 6: [0.9858], 7: [0.9872], 8: [0.9876], 9: [0.9874]}
TRAIINING epoch@35 ::  acc@0.976  loss@0.082
[[2420    0   24    7    0    0    1    3   35   10]
 [   0 2458    2    0    0    0    3    0    9   28]
 [  22    1 2376   28   19   10   18   11    9    6]
 [  12    0   36 2364    1   57   15   10    4    1]
 [   0    0   25    0 2430   16    6   22    0    1]
 [   1    0   20   67    9 2368   10   25    0    0]
 [   0    3   31   20    6    4 4929    0    7    0]
 [   6    0   15    3   17   18    0 4936    0    5]
 [  28    5    8    4    0    0    7    0 4938   10]
 [  15   21    8    0    1    0    0    8   10 4937]]
TESTING class wise acc@35 :: {0: [0.848], 1: [0.828], 2: [0.671], 3: [0.457], 4: [0.573], 5: [0.698], 6: [0.869], 7: [0.882], 8: [0.823], 9: [0.968]}
TESTING epoch@35 ::  acc@0.762  loss@1.250
Epoch@@36
[[848   4  35   7   2   2   2   9  25  66]
 [  5 828   2   0   0   1   4   0   4 156]
 [ 83   1 671  40  31  40  65  31  12  26]
 [ 57   5 106 457  19 178  78  49  15  36]
 [ 24   1 143  42 573  78  66  59   4  10]
 [ 14   1  61 106   9 698  33  62   3  13]
 [ 11   3  49  33   7   9 869   6   6   7]
 [ 18   0  22  10  10  29   0 882   1  28]
 [ 60  11  12   4   0   0   6   2 823  82]
 [  3  16   6   1   2   0   0   1   3 968]]
TRAINING class wise acc@36 :: {0: [0.972], 1: [0.9764], 2: [0.9564], 3: [0.944], 4: [0.9608], 5: [0.946], 6: [0.9812], 7: [0.9848], 8: [0.9852], 9: [0.9842]}
TRAIINING epoch@36 ::  acc@0.973  loss@0.090
[[2430    0   12   15    1    0    0    6   29    7]
 [   0 2441    3    0    0    0    2    0   17   37]
 [  17    0 2391   15   26    6   23   10    9    3]
 [  15    0   35 2360    1   54   21   11    2    1]
 [   1    0   34    0 2402   25   17   18    0    3]
 [   1    0   16   60   19 2365    7   32    0    0]
 [   0    5   36   21   14   11 4906    0    7    0]
 [  10    0   10   10   16   24    0 4924    0    6]
 [  32   16    4    3    0    0    8    0 4926   11]
 [   8   46    9    0    1    0    0    7    8 4921]]
TESTING class wise acc@36 :: {0: [0.786], 1: [0.917], 2: [0.723], 3: [0.579], 4: [0.567], 5: [0.717], 6: [0.905], 7: [0.84], 8: [0.876], 9: [0.875]}
TESTING epoch@36 ::  acc@0.778  loss@1.225
Epoch@@37
[[786  12  65  27   0   3   8  10  41  48]
 [  1 917   7   1   0   1   7   0  10  56]
 [ 42   3 723  60  27  38  80  13   9   5]
 [ 14   2  90 579   7 165 106  21  10   6]
 [ 18   2 152  53 567  64 110  31   3   0]
 [  2   0  52 131  16 717  51  29   2   0]
 [  5   3  34  31   4  12 905   2   3   1]
 [  9   2  40  23  22  50   9 840   2   3]
 [ 46  27  14  13   0   0   5   2 876  17]
 [  8  67  20   3   1   0   5   7  14 875]]
TRAINING class wise acc@37 :: {0: [0.9672], 1: [0.98], 2: [0.9472], 3: [0.9332], 4: [0.9556], 5: [0.942], 6: [0.9758], 7: [0.9844], 8: [0.9874], 9: [0.9858]}
TRAIINING epoch@37 ::  acc@0.971  loss@0.098
[[2418    0   18   14    0    0    0   10   25   15]
 [   1 2450    1    0    0    0    6    0   11   31]
 [  16    2 2368   24   32    7   28   10    5    8]
 [  13    0   31 2333    3   72   31   10    7    0]
 [   2    0   34    1 2389   24   24   24    0    2]
 [   0    0   15   60   36 2355    9   24    0    1]
 [   0    7   45   32   18    8 4879    0   11    0]
 [  13    0   13   11   18   17    1 4922    0    5]
 [  21   12   10    2    0    0    7    0 4937   11]
 [  12   25   12    0    3    0    0    5   14 4929]]
TESTING class wise acc@37 :: {0: [0.834], 1: [0.896], 2: [0.737], 3: [0.601], 4: [0.73], 5: [0.738], 6: [0.809], 7: [0.912], 8: [0.897], 9: [0.9]}
TESTING epoch@37 ::  acc@0.805  loss@0.985
Epoch@@38
[[834   7  65   9   9   2   0  23  36  15]
 [  4 896  11   2   3   0   5   1  18  60]
 [ 44   0 737  40  58  43  25  38   7   8]
 [ 23   1 100 601  27 165  35  34  10   4]
 [ 12   0  79  33 730  57  14  73   1   1]
 [  2   0  39 123  32 738   8  56   1   1]
 [  5   2  84  36  33  18 809  10   2   1]
 [  9   0  14  13  16  34   1 912   0   1]
 [ 45  12  19   6   0   1   2   3 897  15]
 [ 20  33  13   2   2   1   0  12  17 900]]
TRAINING class wise acc@38 :: {0: [0.9756], 1: [0.986], 2: [0.9584], 3: [0.9472], 4: [0.9728], 5: [0.9556], 6: [0.9842], 7: [0.9884], 8: [0.9888], 9: [0.9894]}
TRAIINING epoch@38 ::  acc@0.978  loss@0.073
[[2439    0   20    5    0    0    0    9   17   10]
 [   1 2465    2    0    0    0    2    0    5   25]
 [  20    0 2396   17   25    5   13    9   12    3]
 [   8    0   28 2368    2   56   24    8    6    0]
 [   1    1   30    0 2432   17    7   10    0    2]
 [   0    0    8   60   11 2389   10   22    0    0]
 [   0    2   31   22   12    5 4921    0    7    0]
 [   8    0    6    7   17   18    0 4942    0    2]
 [  18    7   12    2    0    0    7    0 4944   10]
 [   8   18   11    0    1    0    0    2   13 4947]]
TESTING class wise acc@38 :: {0: [0.874], 1: [0.859], 2: [0.694], 3: [0.519], 4: [0.736], 5: [0.719], 6: [0.878], 7: [0.871], 8: [0.933], 9: [0.909]}
TESTING epoch@38 ::  acc@0.799  loss@1.083
Epoch@@39
[[874   2  43   6   1   1   1   3  59  10]
 [  8 859   4   1   0   1   7   1  44  75]
 [ 67   1 694  29  60  29  70  21  21   8]
 [ 40   2 117 519  42 147  66  34  22  11]
 [ 24   1  78  25 736  57  38  30  11   0]
 [ 11   1  66  92  31 719  31  41   4   4]
 [ 15   1  34  23  19  11 878   2  16   1]
 [ 23   0  24  13  25  33   1 871   1   9]
 [ 37   5   9   3   0   1   1   0 933  11]
 [ 27  25   8   1   2   0   2   2  24 909]]
TRAINING class wise acc@39 :: {0: [0.974], 1: [0.9864], 2: [0.9592], 3: [0.95], 4: [0.9704], 5: [0.96], 6: [0.9824], 7: [0.9868], 8: [0.9914], 9: [0.9918]}
TRAIINING epoch@39 ::  acc@0.979  loss@0.070
[[2435    0   20    7    0    1    0    6   19   12]
 [   0 2466    2    0    0    0    2    0    7   23]
 [  23    2 2398   20   19    2   21    6    2    7]
 [   9    0   36 2375    2   48   16    8    6    0]
 [   2    0   20    3 2426   11   12   24    0    2]
 [   0    0    9   57   10 2400    4   20    0    0]
 [   1    2   38   15   15    9 4912    0    8    0]
 [   5    0    7   10   21   20    0 4934    0    3]
 [  21    7    4    3    0    0    6    0 4957    2]
 [   6   19    8    0    0    0    0    2    6 4959]]
TESTING class wise acc@39 :: {0: [0.857], 1: [0.875], 2: [0.745], 3: [0.509], 4: [0.749], 5: [0.559], 6: [0.885], 7: [0.898], 8: [0.919], 9: [0.864]}
TESTING epoch@39 ::  acc@0.786  loss@1.170
Epoch@@40
[[857   2  42   9   3   1   2   7  60  17]
 [  7 875   8   0   0   0   7   1  57  45]
 [ 87   3 745  20  40  12  51  20  15   7]
 [ 38   7 170 509  47  66  94  45  19   5]
 [ 19   2 131  13 749   4  42  34   6   0]
 [ 10   2 103 154  44 559  33  88   6   1]
 [  6   2  59  16  10   2 885   5  15   0]
 [ 19   0  37  13  22   6   1 898   1   3]
 [ 45   3  14   5   0   1   3   1 919   9]
 [ 31  49  16   0   3   1   1   1  34 864]]
TRAINING class wise acc@40 :: {0: [0.9768], 1: [0.9884], 2: [0.96], 3: [0.9532], 4: [0.9672], 5: [0.958], 6: [0.9816], 7: [0.9858], 8: [0.9894], 9: [0.9896]}
TRAIINING epoch@40 ::  acc@0.978  loss@0.078
[[2442    0   25    6    0    0    0    5   19    3]
 [   0 2471    1    0    0    0    2    0    9   17]
 [  23    0 2400   19   15    6   19    9    3    6]
 [  16    0   32 2383    3   29   15   17    5    0]
 [   0    1   27    2 2418   23   12   17    0    0]
 [   1    0   12   45   18 2395    9   20    0    0]
 [   0    3   43   15   12    5 4908    0   13    1]
 [   6    0   12   14   15   21    0 4929    0    3]
 [  18    6    5    1    0    0    9    0 4947   14]
 [   5   13   18    1    1    0    0    4   10 4948]]
TESTING class wise acc@40 :: {0: [0.818], 1: [0.9], 2: [0.665], 3: [0.633], 4: [0.744], 5: [0.597], 6: [0.907], 7: [0.927], 8: [0.79], 9: [0.914]}
TESTING epoch@40 ::  acc@0.789  loss@1.141
Epoch@@41
[[818   5  42  17   8   0   3  18  22  67]
 [  1 900   3   1   1   1   8   1   1  83]
 [ 59   2 665  44  55  22  88  54   1  10]
 [ 17   4  78 633  51  66  79  64   2   6]
 [ 13   0  84  42 744   8  40  67   1   1]
 [  2   2  31 176  56 597  37  97   0   2]
 [  4   1  33  30  14   3 907   7   1   0]
 [  8   0  12  15  23   7   1 927   0   7]
 [ 62  41  14  17   0   0   8   8 790  60]
 [ 11  34  14   4   2   0   2  15   4 914]]
TRAINING class wise acc@41 :: {0: [0.9748], 1: [0.9864], 2: [0.9564], 3: [0.958], 4: [0.9692], 5: [0.968], 6: [0.9844], 7: [0.9874], 8: [0.9898], 9: [0.9912]}
TRAIINING epoch@41 ::  acc@0.980  loss@0.069
[[2437    0   18   10    0    0    1    4   24    6]
 [   1 2466    3    0    0    0    4    0    6   20]
 [  17    2 2391   14   28    2   25    8    5    8]
 [  10    0   19 2395    3   39   23    8    3    0]
 [   0    0   39    2 2423   12    7   16    0    1]
 [   0    0    6   31   14 2420    8   21    0    0]
 [   0    5   28   25    8    7 4922    0    5    0]
 [  11    0    9    5   15   17    0 4937    0    6]
 [  28    4    7    4    0    0    1    0 4949    7]
 [   8   15    8    0    1    0    0    5    7 4956]]
TESTING class wise acc@41 :: {0: [0.78], 1: [0.844], 2: [0.703], 3: [0.567], 4: [0.764], 5: [0.629], 6: [0.919], 7: [0.853], 8: [0.927], 9: [0.893]}
TESTING epoch@41 ::  acc@0.788  loss@1.229
Epoch@@42
[[780   1  90  13  12   2   7   8  79   8]
 [  7 844  20   2   1   0  13   0  39  74]
 [ 48   0 703  35  73  26  92  13   7   3]
 [ 14   2 122 567  57 120  86  17  11   4]
 [  5   1  74  24 764  37  63  30   2   0]
 [  2   0  89 131  57 629  52  35   3   2]
 [  4   0  31  22  12   5 919   3   4   0]
 [ 14   1  32  20  54  20   4 853   1   1]
 [ 27   7  20   4   0   0   9   0 927   6]
 [ 27  21  17   1   3   1   4   3  30 893]]
TRAINING class wise acc@42 :: {0: [0.9796], 1: [0.9868], 2: [0.9604], 3: [0.9592], 4: [0.9708], 5: [0.9576], 6: [0.9854], 7: [0.9886], 8: [0.991], 9: [0.9908]}
TRAIINING epoch@42 ::  acc@0.980  loss@0.066
[[2449    0   14    5    0    0    0    6   19    7]
 [   1 2467    3    0    0    0    2    0    5   22]
 [  17    2 2401   19   21    6   15    6    6    7]
 [  10    0   28 2398    1   36   17    8    2    0]
 [   0    0   24    1 2427   23    6   18    0    1]
 [   0    0   11   50   18 2394   11   16    0    0]
 [   0    4   29   18    9    8 4927    0    3    2]
 [   6    0   13    6   15   11    0 4943    0    6]
 [  19    5    7    2    0    0    5    0 4955    7]
 [   6   17    6    0    0    0    0    8    9 4954]]
TESTING class wise acc@42 :: {0: [0.821], 1: [0.882], 2: [0.652], 3: [0.629], 4: [0.763], 5: [0.68], 6: [0.851], 7: [0.888], 8: [0.924], 9: [0.912]}
TESTING epoch@42 ::  acc@0.800  loss@1.140
Epoch@@43
[[821   4  32  13   7   2   1   6  94  20]
 [  1 882   2   3   3   0   2   0  26  81]
 [ 56   2 652  73  62  37  50  31  21  16]
 [ 19   3  79 629  41 108  45  41  27   8]
 [ 15   1  66  37 763  29  24  57   6   2]
 [  4   0  47 162  37 680  18  46   2   4]
 [  6   8  44  43  18  13 851   5   9   3]
 [ 17   0  23  17  36  10   0 888   3   6]
 [ 29  10  13   2   0   0   5   1 924  16]
 [ 14  30  13   0   1   1   1   5  23 912]]
TRAINING class wise acc@43 :: {0: [0.9796], 1: [0.9884], 2: [0.9656], 3: [0.9656], 4: [0.9756], 5: [0.97], 6: [0.9856], 7: [0.99], 8: [0.9918], 9: [0.9908]}
TRAIINING epoch@43 ::  acc@0.983  loss@0.059
[[2449    1   14    5    0    0    0    5   14   12]
 [   0 2471    0    0    1    0    1    0    7   20]
 [  14    1 2414   15   17    2   22    6    4    5]
 [   3    0   17 2414    2   35   22    3    3    1]
 [   0    2   22    0 2439   12    7   17    0    1]
 [   0    0    3   35    8 2425    7   22    0    0]
 [   0    2   34   15    9    8 4928    0    4    0]
 [   4    0    5    4   19   15    0 4950    0    3]
 [  13    4    9    5    0    0    4    0 4959    6]
 [   7   14   16    0    0    0    0    2    7 4954]]
TESTING class wise acc@43 :: {0: [0.86], 1: [0.908], 2: [0.68], 3: [0.648], 4: [0.591], 5: [0.649], 6: [0.842], 7: [0.875], 8: [0.924], 9: [0.866]}
TESTING epoch@43 ::  acc@0.784  loss@1.348
Epoch@@44
[[860   4  28   4   5   1   0   4  73  21]
 [  7 908   4   3   0   0   2   0  42  34]
 [ 78   1 680  65  24  39  62  24  18   9]
 [ 62   4  75 648  12  89  34  40  25  11]
 [ 18   1 119  90 591  57  49  64   9   2]
 [ 16   0  52 184  13 649  23  52   5   6]
 [  9   4  38  73   1   6 842   2  22   3]
 [ 23   0  24  29  12  20   1 875   2  14]
 [ 45   5   5   8   0   0   1   1 924  11]
 [ 19  69   7   2   1   0   1   4  31 866]]
TRAINING class wise acc@44 :: {0: [0.9708], 1: [0.9828], 2: [0.9592], 3: [0.9504], 4: [0.9704], 5: [0.9604], 6: [0.9842], 7: [0.9872], 8: [0.9898], 9: [0.9874]}
TRAIINING epoch@44 ::  acc@0.978  loss@0.078
[[2427    1   23   10    0    0    0    6   19   14]
 [   0 2457    5    0    0    0    1    0   13   24]
 [  15    0 2398   20   22    4   14    9    9    9]
 [  14    0   19 2376    2   50   22    8    8    1]
 [   2    0   33    1 2426   10    9   18    0    1]
 [   0    0   10   50   16 2401    5   18    0    0]
 [   0    2   26   27    9    7 4921    0    7    1]
 [   6    0   14    6   18   15    0 4936    0    5]
 [  19   10    9    2    0    0    5    0 4949    6]
 [  14   25   12    0    1    0    1    5    5 4937]]
TESTING class wise acc@44 :: {0: [0.765], 1: [0.823], 2: [0.774], 3: [0.618], 4: [0.763], 5: [0.443], 6: [0.846], 7: [0.802], 8: [0.921], 9: [0.932]}
TESTING epoch@44 ::  acc@0.769  loss@1.271
Epoch@@45
[[765   2  67  21   3   0   4   7  75  56]
 [  8 823   6   2   0   0   4   0  34 123]
 [ 41   3 774  39  60   6  33  10  12  22]
 [ 16   2 177 618  41  45  51  15  19  16]
 [ 12   1 117  27 763  15  29  25   5   6]
 [  5   1 168 246  53 443  29  29   9  17]
 [  3   1  76  39  21   2 846   1   7   4]
 [  9   2  66  26  42  11   0 802   3  39]
 [ 29   7  16   6   0   0   3   0 921  18]
 [  1  20   6   5   2   0   1   1  32 932]]
TRAINING class wise acc@45 :: {0: [0.9724], 1: [0.9908], 2: [0.966], 3: [0.9608], 4: [0.978], 5: [0.9636], 6: [0.987], 7: [0.9914], 8: [0.988], 9: [0.994]}
TRAIINING epoch@45 ::  acc@0.982  loss@0.062
[[2431    0   18   11    1    0    1    3   27    8]
 [   0 2477    2    0    0    0    1    0    8   12]
 [  20    0 2415   13   20    4   10    4    9    5]
 [  11    0   20 2402    2   42   13    6    4    0]
 [   0    0   24    1 2445   10    8   12    0    0]
 [   0    0    9   51   12 2409    3   16    0    0]
 [   0    2   24   18    9    7 4935    1    4    0]
 [   4    0    3    5   11   14    0 4957    0    6]
 [  30    3    8    5    0    0    5    0 4940    9]
 [   4    8    8    0    0    0    0    4    6 4970]]
TESTING class wise acc@45 :: {0: [0.821], 1: [0.907], 2: [0.706], 3: [0.491], 4: [0.774], 5: [0.732], 6: [0.926], 7: [0.858], 8: [0.9], 9: [0.911]}
TESTING epoch@45 ::  acc@0.803  loss@1.179
Epoch@@46
[[821   6  63   9   6   3   7  12  40  33]
 [  2 907  10   1   0   1   7   0  15  57]
 [ 36   3 706  22  69  35  98  22   4   5]
 [ 14   7 104 491  57 180 104  25  10   8]
 [ 11   2  75  19 774  39  46  31   1   2]
 [  3   1  45  72  49 732  56  38   1   3]
 [  2   1  22  14  16  10 926   1   6   2]
 [ 12   1  28   7  38  41   3 858   1  11]
 [ 34  16  19   5   0   1   8   2 900  15]
 [ 11  37  14   1   3   1   2   2  18 911]]
TRAINING class wise acc@46 :: {0: [0.9852], 1: [0.9848], 2: [0.9744], 3: [0.9652], 4: [0.9844], 5: [0.9704], 6: [0.9908], 7: [0.9924], 8: [0.9912], 9: [0.9912]}
TRAIINING epoch@46 ::  acc@0.985  loss@0.051
[[2463    1   11    3    0    0    0    2   12    8]
 [   0 2462    2    0    0    0    2    0    9   25]
 [   9    0 2436   13   11    5   13    5    4    4]
 [  13    0   20 2413    0   36    8    4    6    0]
 [   0    1    7    1 2461   14    4   11    0    1]
 [   0    0    5   36   10 2426    6   17    0    0]
 [   0    4   22   12    3    5 4954    0    0    0]
 [   4    0    7    3    9   11    0 4962    0    4]
 [  18    7    8    4    0    0    1    0 4956    6]
 [   8   19    6    0    1    0    0    2    8 4956]]
TESTING class wise acc@46 :: {0: [0.88], 1: [0.887], 2: [0.74], 3: [0.513], 4: [0.697], 5: [0.622], 6: [0.912], 7: [0.934], 8: [0.933], 9: [0.86]}
TESTING epoch@46 ::  acc@0.798  loss@1.239
Epoch@@47
[[880   1  31   8   1   2   6  12  52   7]
 [ 12 887   2   1   0   0   7   2  46  43]
 [ 63   1 740  23  34  16  58  45  13   7]
 [ 37   3 106 513  37 103  89  86  19   7]
 [ 17   1 125  15 697  12  44  83   6   0]
 [  7   0  68  95  36 622  44 122   4   2]
 [  6   0  43  16   6   6 912   4   6   1]
 [ 13   0  19   4  18   4   5 934   1   2]
 [ 33   3  12   1   0   0   6   4 933   8]
 [ 24  52  13   2   2   0   1  14  32 860]]
TRAINING class wise acc@47 :: {0: [0.9764], 1: [0.9876], 2: [0.9712], 3: [0.9692], 4: [0.9768], 5: [0.978], 6: [0.9866], 7: [0.991], 8: [0.9878], 9: [0.9912]}
TRAIINING epoch@47 ::  acc@0.984  loss@0.058
[[2441    0   18    8    0    0    0    2   23    8]
 [   0 2469    1    0    1    0    3    0    9   17]
 [  17    1 2428    9    7    4   14    9    7    4]
 [  10    0   17 2423    1   25   16    5    3    0]
 [   1    0   21    0 2442   12    7   16    0    1]
 [   0    0    3   21    9 2445    3   18    1    0]
 [   0    8   23   16    6    7 4933    0    7    0]
 [   1    0    7   10   13    9    0 4955    1    4]
 [  25    5    9    6    0    0    5    0 4939   11]
 [   6   14    6    0    2    0    1    6    9 4956]]
TESTING class wise acc@47 :: {0: [0.834], 1: [0.905], 2: [0.698], 3: [0.651], 4: [0.721], 5: [0.618], 6: [0.924], 7: [0.852], 8: [0.916], 9: [0.898]}
TESTING epoch@47 ::  acc@0.802  loss@1.175
Epoch@@48
[[834   7  55  16   3   0   5   7  49  24]
 [  4 905   5   1   0   0   6   1  18  60]
 [ 47   1 698  51  57  17 100  11  10   8]
 [ 25   5  97 651  33  58  88  19  15   9]
 [  8   1  94  45 721  14  74  37   4   2]
 [  7   2  66 196  33 618  45  30   1   2]
 [  3   1  24  35   5   2 924   1   5   0]
 [ 14   0  26  34  41  17   6 852   0  10]
 [ 37   9   8   5   1   0   9   0 916  15]
 [ 14  42  14   3   2   0   1   2  24 898]]
TRAINING class wise acc@48 :: {0: [0.9832], 1: [0.99], 2: [0.9704], 3: [0.966], 4: [0.9796], 5: [0.9708], 6: [0.988], 7: [0.991], 8: [0.9914], 9: [0.9926]}
TRAIINING epoch@48 ::  acc@0.985  loss@0.053
[[2458    0   10    6    0    0    0    7   16    3]
 [   0 2475    1    0    0    0    3    0    6   15]
 [   9    0 2426   11   12    5   20    4    7    6]
 [  11    0   21 2415    0   35   13    4    1    0]
 [   0    0   18    2 2449   15    4   11    1    0]
 [   0    0    3   34   15 2427    9   12    0    0]
 [   0    4   19   16   10    6 4940    0    5    0]
 [   9    0    6    5   11   11    0 4955    0    3]
 [  12    6    9    1    0    0    4    0 4957   11]
 [   6   14    7    0    1    0    0    0    9 4963]]
TESTING class wise acc@48 :: {0: [0.881], 1: [0.891], 2: [0.739], 3: [0.715], 4: [0.686], 5: [0.634], 6: [0.84], 7: [0.878], 8: [0.927], 9: [0.882]}
TESTING epoch@48 ::  acc@0.807  loss@1.284
Epoch@@49
[[881   1  33  12   1   1   3  10  51   7]
 [  7 891  10   3   0   0   2   1  42  44]
 [ 68   1 739  66  33  26  40  17   6   4]
 [ 32   4  73 715  24  69  31  30  15   7]
 [ 22   1 131  46 686  24  44  37   7   2]
 [  8   0  55 236  20 634  10  35   2   0]
 [  8   0  61  59   8  11 840   3  10   0]
 [ 16   0  25  30  23  22   1 878   2   3]
 [ 40   3  11   5   0   0   2   3 927   9]
 [ 16  44  18   4   2   2   1   2  29 882]]
TRAINING class wise acc@49 :: {0: [0.9784], 1: [0.9872], 2: [0.9708], 3: [0.97], 4: [0.9796], 5: [0.9672], 6: [0.9878], 7: [0.9912], 8: [0.993], 9: [0.9916]}
TRAIINING epoch@49 ::  acc@0.984  loss@0.055
[[2446    0   14    2    0    0    0    5   19   14]
 [   0 2468    2    0    0    0    3    0    6   21]
 [  15    1 2427   13   17    6    7    5    4    5]
 [   5    0   18 2425    2   31   12    4    3    0]
 [   0    0   18    0 2449   12    7   13    0    1]
 [   0    0   10   33   15 2418    9   15    0    0]
 [   0    2   19   18    7   10 4939    0    5    0]
 [   7    0   13    3    9    8    0 4956    0    4]
 [  14    4    8    2    0    0    3    0 4965    4]
 [   9   17    8    0    0    0    0    5    3 4958]]
TESTING class wise acc@49 :: {0: [0.837], 1: [0.875], 2: [0.711], 3: [0.688], 4: [0.673], 5: [0.687], 6: [0.856], 7: [0.924], 8: [0.889], 9: [0.892]}
TESTING epoch@49 ::  acc@0.803  loss@1.168
[[837   1  59  28   2   1   2  22  33  15]
 [ 13 875  19   5   2   0   1   2  21  62]
 [ 50   0 711  58  44  40  46  46   2   3]
 [ 20   4  68 688  28 114  31  43   3   1]
 [  9   1 105  61 673  46  34  69   2   0]
 [  4   1  46 191  16 687   4  51   0   0]
 [  3   1  44  47  11  30 856   5   3   0]
 [  7   0  10  27  11  20   0 924   0   1]
 [ 44   9  25  17   1   0   3   4 889   8]
 [ 19  28  18   8   1   1   1  14  18 892]]
