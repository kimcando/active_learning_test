

Fri Jan 15 18:33:54 2021
imbal_test_imbal282851010101010_rand_cifar10_vgg_Adam's set level: 10
imbal_test_imbal282851010101010_rand_cifar10_vgg_Adam logger is ready
imbal_test with imbalance_ratio: [0.2 0.8 0.2 0.8 0.5 1.  1.  1.  1.  1. ]
parallel mode is False
initial count: cifar10: [0 1 2 3 4 5 6 7 8 9] class, each has [5000 5000 5000 5000 5000 5000 5000 5000 5000 5000]
cifar10: [0 1 2 3 4 5 6 7 8 9] class, each has [1000 4000 1000 4000 2500 5000 5000 5000 5000 5000]
Epoch@@0
Files already downloaded and verified
TRAINING class wise acc@0 :: {0: [0.0], 1: [0.00375], 2: [0.0], 3: [0.01525], 4: [0.004], 5: [0.0892], 6: [0.3184], 7: [0.1884], 8: [0.211], 9: [0.1864]}
TRAIINING epoch@0 ::  acc@0.135  loss@2.446
[[   0    1    0    6    1  103  339  168  191  191]
 [   0   15    1   15   10  349 1278  726  890  716]
 [   0    1    0    7    6   91  309  175  218  193]
 [   0    5    0   61   14  357 1229  762  817  755]
 [   1    5    0   16   10  211  766  487  531  473]
 [   0    9    0   34   13  446 1522  961 1064  951]
 [   0    3    0   39   17  476 1592  873 1012  988]
 [   2    6    0   41   18  474 1539  942 1046  932]
 [   0   13    0   16   22  454 1603  907 1055  930]
 [   0   10    0   11   14  499 1536  929 1069  932]]
TESTING class wise acc@0 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.025], 4: [0.0], 5: [0.0], 6: [0.0], 7: [0.993], 8: [0.0], 9: [0.0]}
TESTING epoch@0 ::  acc@0.102  loss@2.429
Epoch@@1
[[  0   0   0   1   0   0   0 999   0   0]
 [  0   0   0  11   0   0   0 989   0   0]
 [  0   0   0  15   0   0   0 985   0   0]
 [  0   0   0  25   0   0   0 975   0   0]
 [  0   0   0  14   0   0   0 986   0   0]
 [  0   0   0  10   0   0   0 990   0   0]
 [  0   0   0  12   0   0   0 988   0   0]
 [  0   0   0   7   0   0   0 993   0   0]
 [  0   0   0   1   0   0   0 999   0   0]
 [  0   0   0   3   0   0   0 997   0   0]]
TRAINING class wise acc@1 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.0305], 4: [0.0], 5: [0.24], 6: [0.2038], 7: [0.157], 8: [0.1022], 9: [0.265]}
TRAIINING epoch@1 ::  acc@0.132  loss@2.195
[[   0    0    0    6    0  245  178  139  124  308]
 [   0    0    0   37    0 1017  769  620  451 1106]
 [   0    0    0   18    0  241  193  160  105  283]
 [   0    0    0  122    0  944  776  687  419 1052]
 [   0    0    0   31    0  621  489  376  285  698]
 [   0    0    0   53    0 1200  949  799  545 1454]
 [   0    0    0   80    0 1156 1019  788  626 1331]
 [   0    0    0   74    0 1275  981  785  544 1341]
 [   0    0    0   21    0 1281  964  797  511 1426]
 [   0    0    0   20    0 1311  953  796  595 1325]]
TESTING class wise acc@1 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.008], 4: [0.0], 5: [0.015], 6: [0.005], 7: [0.0], 8: [0.0], 9: [0.994]}
TESTING epoch@1 ::  acc@0.102  loss@2.456
Epoch@@2
[[  0   0   0   1   0   4   1   0   0 994]
 [  0   0   0   3   0  13   9   0   0 975]
 [  0   0   0   9   0  18  11   0   0 962]
 [  0   0   0   8   0  35  24   0   0 933]
 [  0   0   0   9   0  16   9   0   0 966]
 [  0   0   0   3   0  15  12   0   0 970]
 [  0   0   0   6   0  16   5   0   0 973]
 [  0   0   0   4   0   7  10   0   0 979]
 [  0   0   0   0   0   2   1   0   0 997]
 [  0   0   0   2   0   3   1   0   0 994]]
TRAINING class wise acc@2 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.01925], 4: [0.0], 5: [0.2276], 6: [0.0408], 7: [0.1522], 8: [0.2282], 9: [0.362]}
TRAIINING epoch@2 ::  acc@0.137  loss@2.194
[[   0    0    0    4    0  224   41  182  192  357]
 [   0    0    0   34    0  949  137  618  861 1401]
 [   0    0    0   12    0  211   42  184  225  326]
 [   0    0    0   77    0  909  196  683  758 1377]
 [   0    0    0   24    0  596  110  379  530  861]
 [   0    0    0   44    0 1138  186  849 1072 1711]
 [   0    0    0   75    0 1174  204  820  994 1733]
 [   0    0    0   59    0 1153  208  761 1054 1765]
 [   0    0    0   13    0 1137  155  750 1141 1804]
 [   0    0    0   12    0 1118  168  755 1137 1810]]
TESTING class wise acc@2 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.005], 4: [0.0], 5: [0.923], 6: [0.094], 7: [0.0], 8: [0.0], 9: [0.0]}
TESTING epoch@2 ::  acc@0.102  loss@2.462
Epoch@@3
[[  0   0   0   1   0 987  12   0   0   0]
 [  0   0   0   1   0 956  43   0   0   0]
 [  0   0   0   4   0 929  67   0   0   0]
 [  0   0   0   5   0 876 119   0   0   0]
 [  0   0   0   8   0 937  55   0   0   0]
 [  0   0   0   2   0 923  75   0   0   0]
 [  0   0   0   6   0 900  94   0   0   0]
 [  0   0   0   2   0 945  53   0   0   0]
 [  0   0   0   0   0 989  11   0   0   0]
 [  0   0   0   2   0 979  19   0   0   0]]
TRAINING class wise acc@3 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.0105], 4: [0.0124], 5: [0.2068], 6: [0.4144], 7: [0.192], 8: [0.4494], 9: [0.2948]}
TRAIINING epoch@3 ::  acc@0.210  loss@2.021
[[   0    0    0    3    0  104   47  145  416  285]
 [   0    0    0    7    0  453  221  428 1737 1154]
 [   0    0    0    7    9  182  304  153  185  160]
 [   0    0    0   42   13  765  987  712  791  690]
 [   0    0    0   16   31  469  904  355  409  316]
 [   0    0    0   62   21 1034 1229  906  918  830]
 [   0    0    0   51   56  895 2072  749  608  569]
 [   0    0    0   70   21 1020 1036  960 1007  886]
 [   0    0    0    3    0  527  221  523 2247 1479]
 [   0    0    0    9    0  579  266  632 2040 1474]]
TESTING class wise acc@3 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.142], 4: [0.0], 5: [0.0], 6: [0.786], 7: [0.195], 8: [0.63], 9: [0.292]}
TESTING epoch@3 ::  acc@0.204  loss@2.010
Epoch@@4
[[  0   0   0  63   0   0  63 185 397 292]
 [  0   0   0  16   0   0  12 113 620 239]
 [  0   0   0 105   0   0 635 150  33  77]
 [  0   0   0 142   0   0 643 150  20  45]
 [  0   0   0 101   0   0 719 111  26  43]
 [  0   0   0 126   0   0 722 109   7  36]
 [  0   0   0  88   0   0 786  87   2  37]
 [  0   0   0 177   0   0 545 195  21  62]
 [  0   0   0  27   0   0  26 107 630 210]
 [  0   0   0  46   0   0  19 153 490 292]]
TRAINING class wise acc@4 :: {0: [0.0], 1: [0.001], 2: [0.0], 3: [0.036], 4: [0.0], 5: [0.2756], 6: [0.5762], 7: [0.4484], 8: [0.7638], 9: [0.2296]}
TRAIINING epoch@4 ::  acc@0.310  loss@1.731
[[   0    1    0    6    0   43   16  157  537  240]
 [   0    4    0    7    0   47   26  295 2917  704]
 [   0    1    0   27    0  209  273  349   49   92]
 [   0    0    0  144    0 1017 1179 1288   90  282]
 [   0    2    0   94    0  559  925  676   79  165]
 [   0    2    0  195    0 1378 1488 1663   82  192]
 [   0    0    0  120    0  898 2881  877   57  167]
 [   0    3    0  139    0 1109  820 2242  203  484]
 [   0    3    0    6    0   49   33  345 3819  745]
 [   0    4    0    8    0   74   38  655 3073 1148]]
TESTING class wise acc@4 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.0], 4: [0.0], 5: [0.778], 6: [0.545], 7: [0.262], 8: [0.814], 9: [0.198]}
TESTING epoch@4 ::  acc@0.260  loss@1.959
Epoch@@5
[[  0   0   0   0   0 120   5 148 509 218]
 [  0   0   0   0   0  22   1  48 784 145]
 [  0   0   0   0   0 609 156 118  30  87]
 [  0   0   0   0   0 637 127 159  23  54]
 [  0   0   0   0   0 601 190 139  23  47]
 [  0   0   0   0   0 778  65 116  10  31]
 [  0   0   0   0   0 362 545  77   5  11]
 [  0   0   0   0   0 609  23 262  27  79]
 [  0   0   0   0   0  24   3  43 814 116]
 [  0   0   0   0   0  27   1  78 696 198]]
TRAINING class wise acc@5 :: {0: [0.0], 1: [0.04975], 2: [0.0], 3: [0.06425], 4: [0.0], 5: [0.4296], 6: [0.6906], 7: [0.5132], 8: [0.5238], 9: [0.3406]}
TRAIINING epoch@5 ::  acc@0.345  loss@1.629
[[   0   23    0    7    0   56   10  232  353  319]
 [   0  199    0    6    0   40   12  273 2153 1317]
 [   0    1    0   64    0  299  185  359   28   64]
 [   0    1    0  257    0 1392  710 1436   69  135]
 [   0    1    0  182    0  834  636  698   53   96]
 [   0    2    0  323    0 2148  511 1888   36   92]
 [   0    1    0  180    0  751 3453  501   39   75]
 [   0    6    0  187    0 1584  221 2566  154  282]
 [   0  184    0   13    0   87   17  405 2619 1675]
 [   0  198    0    7    0   83   13  535 2461 1703]]
TESTING class wise acc@5 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.0], 4: [0.0], 5: [0.491], 6: [0.418], 7: [0.641], 8: [0.947], 9: [0.0]}
TESTING epoch@5 ::  acc@0.250  loss@1.998
Epoch@@6
[[  0   0   0   0   0  34   2 257 707   0]
 [  0   0   0   0   0   1   0  22 977   0]
 [  0   0   0   0   0 406  56 419 119   0]
 [  0   0   0   0   0 371  43 443 143   0]
 [  0   0   0   0   0 463  54 375 108   0]
 [  0   0   0   0   0 491  14 442  53   0]
 [  0   0   0   0   0 349 418 175  58   0]
 [  0   0   0   0   0 160   5 641 194   0]
 [  0   0   0   0   0   3   0  50 947   0]
 [  0   0   0   0   0   4   0  24 972   0]]
TRAINING class wise acc@6 :: {0: [0.0], 1: [0.1155], 2: [0.0], 3: [0.04675], 4: [0.0], 5: [0.468], 6: [0.742], 7: [0.5574], 8: [0.4278], 9: [0.5806]}
TRAIINING epoch@6 ::  acc@0.387  loss@1.556
[[   0   35    0    4    0   48    7  268  422  216]
 [   0  462    0    1    0   36    6  157  805 2533]
 [   0    2    0   41    0  364  180  337   62   14]
 [   0    2    0  187    0 1557  702 1353  159   40]
 [   0    1    0  168    0  923  575  698  101   34]
 [   0    3    0  293    0 2340  413 1809  121   21]
 [   0    3    0  152    0  652 3710  381   69   33]
 [   0    6    0  146    0 1504  127 2787  349   81]
 [   0  407    0    3    0   87   18  437 2139 1909]
 [   0  504    0    1    0   50    9  319 1214 2903]]
TESTING class wise acc@6 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.143], 4: [0.0], 5: [0.0], 6: [0.579], 7: [0.672], 8: [0.58], 9: [0.866]}
TESTING epoch@6 ::  acc@0.284  loss@1.898
Epoch@@7
[[  0   0   0   3   0   0   1 173 610 213]
 [  0   0   0   5   0   0   1  13  79 902]
 [  0   0   0 167   0   0  72 602 141  18]
 [  0   0   0 143   0   0  50 666 122  19]
 [  0   0   0 223   0   0  96 577  95   9]
 [  0   0   0  72   0   0   6 819  94   9]
 [  0   0   0 178   0   0 579 193  43   7]
 [  0   0   0  28   0   0   3 672 260  37]
 [  0   0   0   2   0   0   0  66 580 352]
 [  0   0   0   1   0   0   0  22 111 866]]
TRAINING class wise acc@7 :: {0: [0.0], 1: [0.1015], 2: [0.0], 3: [0.106], 4: [0.0], 5: [0.4674], 6: [0.7462], 7: [0.5428], 8: [0.7816], 9: [0.6918]}
TRAIINING epoch@7 ::  acc@0.453  loss@1.473
[[   0    5    0    5    0   53    3  207  620  107]
 [   0  406    0    6    0   18    4   70  557 2939]
 [   0    0    0   90    0  347  178  284   94    7]
 [   0    2    0  424    0 1517  653 1125  256   23]
 [   0    0    0  244    0  992  459  641  156    8]
 [   0    0    0  518    0 2337  365 1581  182   17]
 [   0    1    0  246    0  612 3731  297   97   16]
 [   0    1    0  174    0 1361   99 2714  592   59]
 [   0   32    0   10    0   71   10  329 3908  640]
 [   0  539    0    4    0   36    1  145  816 3459]]
TESTING class wise acc@7 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.0], 4: [0.0], 5: [0.802], 6: [0.787], 7: [0.279], 8: [0.884], 9: [0.846]}
TESTING epoch@7 ::  acc@0.360  loss@1.747
Epoch@@8
[[  0   0   0   0   0 104   7 112 654 123]
 [  0   0   0   0   0   8   0   9 103 880]
 [  0   0   0   0   0 631 149 111 105   4]
 [  0   0   0   0   0 657 136 104  91  12]
 [  0   0   0   0   0 660 179  94  65   2]
 [  0   0   0   0   0 802  58  94  41   5]
 [  0   0   0   0   0 180 787  20  13   0]
 [  0   0   0   0   0 553  18 279 133  17]
 [  0   0   0   0   0  21   0  30 884  65]
 [  0   0   0   0   0   8   0  10 136 846]]
TRAINING class wise acc@8 :: {0: [0.0], 1: [0.13075], 2: [0.0], 3: [0.08225], 4: [0.0], 5: [0.5118], 6: [0.7548], 7: [0.5902], 8: [0.8504], 9: [0.7034]}
TRAIINING epoch@8 ::  acc@0.477  loss@1.422
[[   0    4    0    1    0   46    8  183  684   74]
 [   0  523    0    2    0   16    2   59  440 2958]
 [   0    0    0   81    0  381  160  269  104    5]
 [   0    0    0  329    1 1701  637 1053  266   13]
 [   0    0    0  227    0 1049  420  638  162    4]
 [   0    0    0  452    0 2559  359 1454  164   12]
 [   0    0    0  174    0  675 3774  251  110   16]
 [   0    0    0  132    0 1294   65 2951  521   37]
 [   0   17    0   13    0   61    8  262 4252  387]
 [   0  630    0    3    0   31    2  129  688 3517]]
TESTING class wise acc@8 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.206], 4: [0.0], 5: [0.0], 6: [0.42], 7: [0.704], 8: [0.896], 9: [0.828]}
TESTING epoch@8 ::  acc@0.305  loss@2.006
Epoch@@9
[[  0   0   0  11   0   0   0 193 714  82]
 [  0   0   0   0   0   0   0  13 203 784]
 [  0   0   0 187   0   0  75 541 188   9]
 [  0   0   0 206   0   0  60 541 160  33]
 [  0   0   0 207   0   0  93 540 139  21]
 [  0   0   0 335   0   0  24 559  68  14]
 [  0   0   0 133   0   0 420 301 109  37]
 [  0   0   0  65   0   0   2 704 178  51]
 [  0   0   0   3   0   0   0  44 896  57]
 [  0   0   0   0   0   0   0  22 150 828]]
TRAINING class wise acc@9 :: {0: [0.0], 1: [0.066], 2: [0.0], 3: [0.08725], 4: [0.0], 5: [0.5426], 6: [0.7722], 7: [0.624], 8: [0.8676], 9: [0.7902]}
TRAIINING epoch@9 ::  acc@0.496  loss@1.386
[[   0    2    0    5    0   39    5  191  686   72]
 [   0  264    0    0    0   17    2   44  381 3292]
 [   0    0    0   74    1  363  150  313   95    4]
 [   0    0    0  349    0 1791  595 1031  210   24]
 [   0    0    0  248    0 1034  367  726  118    7]
 [   0    0    0  427    0 2713  281 1452  118    9]
 [   0    3    0  196    4  596 3861  233   91   16]
 [   0    2    0  110    0 1202   48 3120  488   30]
 [   0   12    0    8    0   57    4  255 4338  326]
 [   0  270    0    3    0   23    2  108  643 3951]]
TESTING class wise acc@9 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.025], 4: [0.0], 5: [0.441], 6: [0.734], 7: [0.436], 8: [0.891], 9: [0.914]}
TESTING epoch@9 ::  acc@0.344  loss@1.830
Epoch@@10
[[  0   0   0   1   0  24   1  96 786  92]
 [  0   0   0   0   0   0   1   3  52 944]
 [  0   0   0  39   0 303 108 313 221  16]
 [  0   0   0  25   0 373 114 284 176  28]
 [  0   0   0  32   0 371  87 330 167  13]
 [  0   0   0  31   0 441  35 372 107  14]
 [  0   0   0  41   0 136 734  48  34   7]
 [  0   0   0   5   0 103   6 436 425  25]
 [  0   0   0   0   0   4   2  12 891  91]
 [  0   0   0   0   0   0   0   3  83 914]]
TRAINING class wise acc@10 :: {0: [0.0], 1: [0.112], 2: [0.0], 3: [0.14], 4: [0.0], 5: [0.5318], 6: [0.7786], 7: [0.7086], 8: [0.8824], 9: [0.759]}
TRAIINING epoch@10 ::  acc@0.515  loss@1.337
[[   0    5    0   11    0   43    2  170  710   59]
 [   0  448    0    3    0   16    1   38  338 3156]
 [   0    0    0  120    0  341  145  296   94    4]
 [   0    1    0  560    0 1766  581  879  192   21]
 [   0    0    0  303    0  995  303  781  118    0]
 [   0    0    0  787    0 2659  266 1190   93    5]
 [   0    1    0  282    0  546 3893  200   65   13]
 [   0    1    0  189    0  870   30 3543  341   26]
 [   0   12    0   12    0   30    3  247 4412  284]
 [   0  458    0    0    0   14    0   95  638 3795]]
TESTING class wise acc@10 :: {0: [0.0], 1: [0.0], 2: [0.0], 3: [0.0], 4: [0.0], 5: [0.824], 6: [0.681], 7: [0.45], 8: [0.946], 9: [0.798]}
TESTING epoch@10 ::  acc@0.370  loss@1.681
Epoch@@11
[[  0   0   0   0   0  78   1 114 771  36]
 [  0   0   0   0   0   3   0   6 139 852]
 [  0   0   0   0   0 598 125 151 119   7]
 [  0   0   0   0   0 666 103 136  86   9]
 [  0   0   0   0   0 712  91 142  53   2]
 [  0   0   0   0   0 824  33  97  43   3]
 [  0   0   0   0   0 243 681  50  24   2]
 [  0   0   0   0   0 452   4 450  87   7]
 [  0   0   0   0   0  12   0  25 946  17]
 [  0   0   0   0   0   3   0  15 184 798]]
TRAINING class wise acc@11 :: {0: [0.0], 1: [0.02775], 2: [0.0], 3: [0.113], 4: [0.0024], 5: [0.5898], 6: [0.7732], 7: [0.7408], 8: [0.8926], 9: [0.84]}
TRAIINING epoch@11 ::  acc@0.527  loss@1.308
[[   0    0    0    4    0   46    4  206  683   57]
 [   0  111    0    3    0    8    0   43  279 3556]
 [   0    0    0   78    3  388  136  302   89    4]
 [   0    0    0  452   13 2019  522  837  146   11]
 [   0    0    0  239    6 1077  276  799   98    5]
 [   0    1    0  554   13 2949  254 1132   81   16]
 [   0    0    0  235    9  640 3866  179   59   12]
 [   0    0    0   58    2  855   22 3704  340   19]
 [   0    2    0    6    0   32    3  239 4463  255]
 [   0  144    0    3    0   10    3   88  552 4200]]
TESTING class wise acc@11 :: {0: [0.0], 1: [0.721], 2: [0.0], 3: [0.061], 4: [0.0], 5: [0.747], 6: [0.648], 7: [0.585], 8: [0.879], 9: [0.229]}
TESTING epoch@11 ::  acc@0.387  loss@1.672
Epoch@@12
[[  0   2   0   1   0  60   2 188 685  62]
 [  0 721   0   1   0   3   0   3  66 206]
 [  0   0   0  54   0 491  75 239 136   5]
 [  0   1   0  61   0 600  71 180  78   9]
 [  0   0   0  63   0 611  75 194  56   1]
 [  0   0   0  60   0 747  25 129  35   4]
 [  0   0   0  79   0 192 648  47  31   3]
 [  0   1   0   4   0 265   6 585 125  14]
 [  0   3   0   1   0   8   2  42 879  65]
 [  0 673   0   0   0   1   0   7  90 229]]
TRAINING class wise acc@12 :: {0: [0.0], 1: [0.20775], 2: [0.0], 3: [0.12375], 4: [0.0], 5: [0.614], 6: [0.7898], 7: [0.7718], 8: [0.8956], 9: [0.7052]}
TRAIINING epoch@12 ::  acc@0.539  loss@1.272
[[   0    6    0    3    0   44    1  205  687   54]
 [   0  831    0    1    0    8    1   25  260 2874]
 [   0    0    0   80    0  415  114  318   70    3]
 [   0    1    0  495    0 2058  521  779  133   13]
 [   0    0    0  210    0 1113  220  856   97    4]
 [   0    1    0  653    0 3070  263  930   76    7]
 [   0    0    0  215    0  616 3949  150   60   10]
 [   0    1    0   68    0  734   17 3859  300   21]
 [   0    9    0    4    0   27    0  244 4478  238]
 [   0  865    0    3    0   16    0   66  524 3526]]
TESTING class wise acc@12 :: {0: [0.0], 1: [0.639], 2: [0.0], 3: [0.493], 4: [0.0], 5: [0.124], 6: [0.776], 7: [0.88], 8: [0.816], 9: [0.363]}
TESTING epoch@12 ::  acc@0.409  loss@1.698
Epoch@@13
[[  0   6   0  15   0  14   1 272 624  68]
 [  0 639   0   7   0   1   1  35  51 266]
 [  0   0   0 328   0  82  73 441  74   2]
 [  0   0   0 493   0 100 106 277  21   3]
 [  0   0   0 345   0  83  64 486  22   0]
 [  0   0   0 529   0 124  21 313  13   0]
 [  0   0   0 175   0  11 776  32   6   0]
 [  0   0   0  65   0  24   5 880  24   2]
 [  0   4   0   6   0   4   2  88 816  80]
 [  0 470   0   4   0   4   0  47 112 363]]
TRAINING class wise acc@13 :: {0: [0.0], 1: [0.16875], 2: [0.0], 3: [0.15825], 4: [0.0], 5: [0.6], 6: [0.7976], 7: [0.8146], 8: [0.9038], 9: [0.7482]}
TRAIINING epoch@13 ::  acc@0.550  loss@1.234
[[   0    2    0    5    0   31    3  200  709   50]
 [   0  675    0    1    0   11    0   29  219 3065]
 [   0    0    0  123    0  403  105  303   64    2]
 [   0    0    0  633    0 2084  443  710  117   13]
 [   0    0    0  256    0 1040  161  950   89    4]
 [   0    0    0  849    0 3000  225  861   58    7]
 [   0    0    0  276    0  557 3988  140   36    3]
 [   0    1    0   95    0  585   14 4073  217   15]
 [   0    7    0    5    0   27    1  208 4519  233]
 [   0  704    0    3    0    8    1   73  470 3741]]
TESTING class wise acc@13 :: {0: [0.0], 1: [0.631], 2: [0.0], 3: [0.0], 4: [0.0], 5: [0.809], 6: [0.871], 7: [0.749], 8: [0.877], 9: [0.313]}
TESTING epoch@13 ::  acc@0.425  loss@1.891
Epoch@@14
[[  0   0   0   0   0  84  12 237 647  20]
 [  0 631   0   0   0  16   1  32  94 226]
 [  0   0   0   0   0 574 152 215  58   1]
 [  0   0   0   0   0 674 181 128  17   0]
 [  0   0   0   0   0 595 133 256  16   0]
 [  0   0   0   0   0 809  76 108   7   0]
 [  0   0   0   0   0 115 871  11   3   0]
 [  0   0   0   0   0 229   8 749  14   0]
 [  0   2   0   0   0  30   4  69 877  18]
 [  0 428   0   0   0  28   7  42 182 313]]
TRAINING class wise acc@14 :: {0: [0.0], 1: [0.183], 2: [0.0], 3: [0.1325], 4: [0.0], 5: [0.6296], 6: [0.7924], 7: [0.8334], 8: [0.9106], 9: [0.7364]}
TRAIINING epoch@14 ::  acc@0.554  loss@1.210
[[   0    3    0    5    0   34    1  214  705   38]
 [   0  732    0    0    0    1    0   23  190 3054]
 [   0    0    0   96    0  427   99  310   68    0]
 [   0    0    0  530    0 2304  390  667   98   11]
 [   0    0    0  201    0 1116  141  976   63    3]
 [   0    0    0  755    0 3148  209  829   52    7]
 [   0    0    0  237    0  609 3962  144   40    8]
 [   0    1    0   82    0  565    8 4167  167   10]
 [   0    6    0    5    0   23    2  217 4553  194]
 [   0  806    0    5    0   10    2   64  431 3682]]
TESTING class wise acc@14 :: {0: [0.0], 1: [0.869], 2: [0.0], 3: [0.0], 4: [0.0], 5: [0.38], 6: [0.321], 7: [0.794], 8: [0.905], 9: [0.163]}
TESTING epoch@14 ::  acc@0.343  loss@2.048
Epoch@@15
[[  0   8   0   0   0  13   0 156 726  97]
 [  0 869   0   0   0   0   0   0  20 111]
 [  0   4   0   0   0 322  12 479 162  21]
 [  0  10   0   0   0 374   7 408 154  47]
 [  0   2   0   0   0 258   1 628  87  24]
 [  0   5   0   0   0 380   1 504  89  21]
 [  0   9   0   0   0 342 321 179  97  52]
 [  0   4   0   0   0  29   0 794 138  35]
 [  0  11   0   0   0   3   0  14 905  67]
 [  0 790   0   0   0   0   0   4  43 163]]
TRAINING class wise acc@15 :: {0: [0.0], 1: [0.2955], 2: [0.0], 3: [0.11725], 4: [0.0016], 5: [0.682], 6: [0.8068], 7: [0.8456], 8: [0.9078], 9: [0.692]}
TRAIINING epoch@15 ::  acc@0.569  loss@1.185
[[   0    2    0    2    0   34    0  248  657   57]
 [   0 1182    0    2    0    2    0   18  182 2614]
 [   0    0    0   76    1  455   89  318   60    1]
 [   0    0    0  469    3 2393  390  643   92   10]
 [   0    0    0  153    4 1136  133  995   74    5]
 [   0    0    0  574    4 3410  176  788   44    4]
 [   0    0    0  232    1  570 4034  114   39   10]
 [   0    0    0   42    2  539    9 4228  161   19]
 [   0    5    0    2    0   22    3  218 4539  211]
 [   0 1064    0    0    0   10    0   58  408 3460]]
TESTING class wise acc@15 :: {0: [0.0], 1: [0.863], 2: [0.0], 3: [0.0], 4: [0.0], 5: [0.519], 6: [0.935], 7: [0.745], 8: [0.913], 9: [0.15]}
TESTING epoch@15 ::  acc@0.412  loss@1.760
Epoch@@16
[[  0   2   0   0   0  54   8 239 654  43]
 [  0 863   0   0   0   2   3   7  34  91]
 [  0   1   0   0   0 436 287 190  75  11]
 [  0   4   0   0   0 393 436 117  40  10]
 [  0   1   0   0   0 539 197 233  29   1]
 [  0   0   0   0   0 519 365  87  26   3]
 [  0   0   0   0   0  42 935  13   8   2]
 [  0   0   0   0   0 168  28 745  53   6]
 [  0  12   0   0   0   5   3  28 913  39]
 [  0 750   0   0   0   4   1   7  88 150]]
TRAINING class wise acc@16 :: {0: [0.0], 1: [0.34825], 2: [0.0], 3: [0.14675], 4: [0.0], 5: [0.648], 6: [0.7916], 7: [0.8528], 8: [0.9138], 9: [0.6408]}
TRAIINING epoch@16 ::  acc@0.566  loss@1.185
[[   0    0    0    5    0   24    0  234  692   45]
 [   0 1393    0    4    0    7    0   17  164 2415]
 [   0    0    0   99    0  417   86  336   61    1]
 [   0    0    0  587    0 2318  358  619  110    8]
 [   0    0    0  188    0 1118  106 1020   64    4]
 [   0    0    0  775    0 3240  181  752   47    5]
 [   0    0    0  228    0  604 3958  151   47   12]
 [   0    0    0   77    0  496    4 4264  146   13]
 [   0    7    0    6    0   15    1  194 4569  208]
 [   0 1284    0    0    0   11    0   60  441 3204]]
TESTING class wise acc@16 :: {0: [0.0], 1: [0.85], 2: [0.0], 3: [0.411], 4: [0.0], 5: [0.235], 6: [0.879], 7: [0.67], 8: [0.858], 9: [0.199]}
TESTING epoch@16 ::  acc@0.410  loss@1.839
Epoch@@17
[[  0   4   0  32   0  72  12 109 700  71]
 [  0 850   0   2   0   2   1   1  28 116]
 [  0   0   0 284   0 269 212 128 101   6]
 [  0   3   0 411   0 184 303  63  27   9]
 [  0   0   0 331   0 276 197 167  26   3]
 [  0   0   0 521   0 235 180  48  14   2]
 [  0   1   0  70   0  24 879  14  12   0]
 [  0   0   0  92   0 191  13 670  31   3]
 [  0  11   0  12   0  26   3  35 858  55]
 [  0 698   0   2   0   5   3  10  83 199]]
TRAINING class wise acc@17 :: {0: [0.0], 1: [0.5645], 2: [0.0], 3: [0.12525], 4: [0.0], 5: [0.6904], 6: [0.811], 7: [0.8684], 8: [0.913], 9: [0.6442]}
TRAIINING epoch@17 ::  acc@0.597  loss@1.136
[[   0    1    0    1    0   31    1  230  692   44]
 [   0 2258    0    1    0    3    0   16  115 1607]
 [   0    0    0   84    0  468   86  314   46    2]
 [   0    0    0  501    0 2487  355  575   67   15]
 [   0    0    0  176    0 1122   86 1064   49    3]
 [   0    0    0  678    0 3452  175  647   42    6]
 [   0    1    0  218    0  585 4055  111   25    5]
 [   0    0    0   53    0  457    3 4342  132   13]
 [   0    5    0    6    0   29    0  180 4565  215]
 [   0 1340    0    1    0    4    0   49  385 3221]]
TESTING class wise acc@17 :: {0: [0.0], 1: [0.353], 2: [0.0], 3: [0.0], 4: [0.0], 5: [0.848], 6: [0.791], 7: [0.875], 8: [0.861], 9: [0.651]}
TESTING epoch@17 ::  acc@0.438  loss@1.740
Epoch@@18
[[  0   0   0   0   0  41   2 318 622  17]
 [  0 353   0   0   0  12   3  29 112 491]
 [  0   0   0   0   0 539  87 320  52   2]
 [  0   0   0   0   0 758  77 156   8   1]
 [  0   0   0   0   0 534  36 421   9   0]
 [  0   0   0   0   0 848  15 132   5   0]
 [  0   0   0   0   0 188 791  17   4   0]
 [  0   0   0   0   0 116   3 875   6   0]
 [  0   1   0   0   0  16   1 101 861  20]
 [  0  12   0   0   0  18   2  70 247 651]]
TRAINING class wise acc@18 :: {0: [0.0], 1: [0.79925], 2: [0.0], 3: [0.16575], 4: [0.0068], 5: [0.6682], 6: [0.832], 7: [0.8736], 8: [0.9044], 9: [0.7994]}
TRAIINING epoch@18 ::  acc@0.647  loss@1.076
[[   0    9    0    5    0   25    1  233  676   51]
 [   0 3197    0    0    0    2    0   15   75  711]
 [   0    0    0  104    3  439   69  331   52    2]
 [   0    3    0  663    9 2420  319  508   65   13]
 [   0    0    0  207   17  977   81 1168   49    1]
 [   0    0    0  857   16 3341  156  594   32    4]
 [   0    2    0  195    2  516 4160   97   22    6]
 [   0    2    0   75    8  408    3 4368  120   16]
 [   0   29    0    5    0   12    0  172 4522  260]
 [   0  632    0    0    0    2    0   49  320 3997]]
TESTING class wise acc@18 :: {0: [0.0], 1: [0.803], 2: [0.0], 3: [0.0], 4: [0.0], 5: [0.87], 6: [0.875], 7: [0.766], 8: [0.905], 9: [0.76]}
TESTING epoch@18 ::  acc@0.498  loss@1.713
Epoch@@19
[[  0   3   0   0   0  68   6 257 631  35]
 [  0 803   0   0   0   8   3  15  35 136]
 [  0   0   0   0   0 593 110 249  47   1]
 [  0   0   0   0   0 741 149  87  19   4]
 [  0   0   0   0   0 592  54 333  20   1]
 [  0   0   0   0   0 870  43  83   4   0]
 [  0   0   0   0   0 115 875   7   2   1]
 [  0   0   0   0   0 205   3 766  21   5]
 [  0   6   0   0   0  10   2  52 905  25]
 [  0 106   0   0   0  15   3  16 100 760]]
TRAINING class wise acc@19 :: {0: [0.0], 1: [0.819], 2: [0.0], 3: [0.1365], 4: [0.0436], 5: [0.7026], 6: [0.8256], 7: [0.8728], 8: [0.897], 9: [0.8464]}
TRAIINING epoch@19 ::  acc@0.657  loss@1.044
[[   0    0    0    5    2   18    0  257  667   51]
 [   0 3276    0    1    3    2    1    5   85  627]
 [   0    1    0   90   41  388   92  338   49    1]
 [   1    1    2  546   60 2517  257  520   78   18]
 [   0    0    3  203  109  789  110 1233   51    2]
 [   0    0    1  657   46 3513  135  608   34    6]
 [   0    2    2  215   62  456 4128  101   30    4]
 [   0    2    0   66   34  395    8 4364  116   15]
 [   0   37    0    2    4   16    1  161 4485  294]
 [   0  441    0    0    1    1    0   38  287 4232]]
TESTING class wise acc@19 :: {0: [0.0], 1: [0.44], 2: [0.0], 3: [0.002], 4: [0.123], 5: [0.896], 6: [0.887], 7: [0.662], 8: [0.866], 9: [0.74]}
TESTING epoch@19 ::  acc@0.462  loss@1.955
Epoch@@20
[[  0   0   0   0  30  67  14 282 586  21]
 [  0 440   0   0   5  13   5  15  60 462]
 [  0   0   0   3 119 433 229 165  50   1]
 [  0   0   0   2  22 745 179  47   4   1]
 [  0   0   0   1 123 468 191 201  16   0]
 [  0   0   0   0   9 896  55  38   2   0]
 [  0   0   0   0  12  91 887   6   4   0]
 [  0   0   0   0  18 298  17 662   5   0]
 [  0   1   0   0  15  19   6  62 866  31]
 [  0   3   0   0  12  29  12  52 152 740]]
TRAINING class wise acc@20 :: {0: [0.048], 1: [0.86875], 2: [0.006], 3: [0.2975], 4: [0.4256], 5: [0.6966], 6: [0.8734], 7: [0.8748], 8: [0.935], 9: [0.8916]}
TRAIINING epoch@20 ::  acc@0.724  loss@0.775
[[  48    3    1    6  114    3    2   97  676   50]
 [   2 3475    0    0    3    0    0    4   77  439]
 [  20    0    6  212  373   95  111  130   49    4]
 [   8    1    6 1190  454 1681  309  289   55    7]
 [  15    0   20  378 1064  155  121  698   49    0]
 [   6    0    2  746  259 3483  100  385   14    5]
 [   7    0   14  295  167  105 4367   21   24    0]
 [  11    0    2  119  226  203    3 4374   42   20]
 [  49   47    0    6   61    0    3   36 4675  123]
 [   7  309    0    1   10    0    0   36  179 4458]]
TESTING class wise acc@20 :: {0: [0.101], 1: [0.876], 2: [0.0], 3: [0.619], 4: [0.393], 5: [0.532], 6: [0.83], 7: [0.83], 8: [0.908], 9: [0.906]}
TESTING epoch@20 ::  acc@0.600  loss@1.140
Epoch@@21
[[101  13   0  30  67   0   1  31 679  78]
 [  4 876   0   1   3   0   1   1  20  94]
 [ 54   4   0 416 239  45  87  52  91  12]
 [ 26   2   0 619  77 135  54  39  34  14]
 [ 27   0   0 334 393   8  41 152  41   4]
 [  8   1   0 357  32 532   9  45  11   5]
 [  3   0   1 135  16   2 830   0  12   1]
 [ 17   0   0  72  37  25   2 830   6  11]
 [ 12  24   0   5   7   0   2   5 908  37]
 [  3  50   0   3   4   0   2   6  26 906]]
TRAINING class wise acc@21 :: {0: [0.2], 1: [0.90225], 2: [0.003], 3: [0.41225], 4: [0.5556], 5: [0.6952], 6: [0.8928], 7: [0.8864], 8: [0.9326], 9: [0.9126]}
TRAIINING epoch@21 ::  acc@0.759  loss@0.672
[[ 200    2    0    7  160    0    1   75  488   67]
 [   1 3609    0    0    1    0    0    2   64  323]
 [  36    0    3  233  432   83   87   95   29    2]
 [  13    1    5 1649  456 1382  256  211   20    7]
 [  49    0   10  371 1389   80   93  473   33    2]
 [  11    0    0  925  223 3476   50  301   10    4]
 [   8    0    5  306  128   59 4464    9   20    1]
 [  25    0    0  102  248  162    2 4432   13   16]
 [  97   42    0    0   60    0    6   22 4663  110]
 [  19  253    0    0    8    1    0   29  127 4563]]
TESTING class wise acc@21 :: {0: [0.007], 1: [0.783], 2: [0.0], 3: [0.207], 4: [0.593], 5: [0.568], 6: [0.663], 7: [0.937], 8: [0.975], 9: [0.875]}
TESTING epoch@21 ::  acc@0.561  loss@1.376
Epoch@@22
[[  7   6   0   2  92   0   1  45 799  48]
 [  0 783   0   0   4   0   1   1  88 123]
 [  3   1   0 108 472  56  15 199 137   9]
 [  2   1   0 207 217 291  23 197  54   8]
 [  1   0   0  42 593  13   6 292  50   3]
 [  2   0   0  73  71 568   1 256  23   6]
 [  0   0   0 115 166  12 663  25  17   2]
 [  4   0   0   2  21  12   0 937  18   6]
 [  1   2   0   1  10   0   0   6 975   5]
 [  4  20   0   0   6   0   0   6  89 875]]
TRAINING class wise acc@22 :: {0: [0.325], 1: [0.91525], 2: [0.0], 3: [0.4695], 4: [0.648], 5: [0.702], 6: [0.8934], 7: [0.902], 8: [0.9324], 9: [0.925]}
TRAIINING epoch@22 ::  acc@0.780  loss@0.620
[[ 325    6    0    4  155    1    2   53  382   72]
 [   2 3661    0    2    1    0    0    2   67  265]
 [  31    0    0  245  451   57   98   84   33    1]
 [  18    2    4 1878  470 1218  226  154   24    6]
 [  39    1    4  312 1620   64   81  344   32    3]
 [  10    0    2  954  206 3510   44  269    4    1]
 [   5    0    6  319  137   42 4467    6   17    1]
 [  22    0    0   72  215  158    0 4510    6   17]
 [ 126   46    0    1   61    1    3   15 4662   85]
 [  22  224    0    0   10    1    0   21   97 4625]]
TESTING class wise acc@22 :: {0: [0.062], 1: [0.918], 2: [0.0], 3: [0.497], 4: [0.633], 5: [0.723], 6: [0.728], 7: [0.79], 8: [0.928], 9: [0.876]}
TESTING epoch@22 ::  acc@0.615  loss@1.138
Epoch@@23
[[ 62  16   0  21 121   0   0  15 711  54]
 [  3 918   0   1   1   1   0   0  20  56]
 [ 11   3   0 322 383  92  47  39  92  11]
 [ 15   3   0 497 111 284  18  41  17  14]
 [  7   0   0 228 633  24  14  58  32   4]
 [  5   1   0 153  47 723   1  52   8  10]
 [  2   2   0 181  54  15 728   5  10   3]
 [ 10   0   0  54  82  46   0 790   5  13]
 [  4  26   0   3  13   0   1   4 928  21]
 [  4  82   0   3   2   0   1   4  28 876]]
TRAINING class wise acc@23 :: {0: [0.401], 1: [0.92425], 2: [0.001], 3: [0.53975], 4: [0.696], 5: [0.7232], 6: [0.897], 7: [0.902], 8: [0.9426], 9: [0.935]}
TRAIINING epoch@23 ::  acc@0.800  loss@0.574
[[ 401    4    0    3  163    1    0   37  315   76]
 [   4 3697    0    0    1    0    0    1   58  239]
 [  31    0    1  247  494   53   82   69   22    1]
 [  18    0    2 2159  403 1022  229  154    5    8]
 [  41    0    4  299 1740   34   76  286   17    3]
 [   6    0    0  925  170 3616   34  241    5    3]
 [   3    0    3  306  150   27 4485    9   17    0]
 [  23    0    0   79  208  151    1 4510    1   27]
 [ 113   37    0    1   48    1    3   14 4713   70]
 [  31  186    0    1   10    0    1   23   73 4675]]
TESTING class wise acc@23 :: {0: [0.437], 1: [0.883], 2: [0.0], 3: [0.395], 4: [0.642], 5: [0.788], 6: [0.818], 7: [0.935], 8: [0.875], 9: [0.921]}
TESTING epoch@23 ::  acc@0.669  loss@1.140
Epoch@@24
[[437   7   0  21 125   5   1  68 243  93]
 [  8 883   0   3   5   2   0   1  17  81]
 [ 57   1   0 209 396 130  73 107  17  10]
 [  8   1   0 395  99 369  35  82   3   8]
 [ 20   0   0 112 642  39  31 151   3   2]
 [  3   0   0  78  34 788   2  94   1   0]
 [  3   1   0 114  33  23 818   5   1   2]
 [  2   0   0   6  19  33   1 935   0   4]
 [ 32  25   0   9  13   0   5  14 875  27]
 [  7  38   0   1   3   1   2  17  10 921]]
TRAINING class wise acc@24 :: {0: [0.492], 1: [0.9335], 2: [0.002], 3: [0.60225], 4: [0.7244], 5: [0.7498], 6: [0.9078], 7: [0.9206], 8: [0.9436], 9: [0.9436]}
TRAIINING epoch@24 ::  acc@0.821  loss@0.527
[[ 492    5    0    2  160    1    1   36  236   67]
 [   4 3734    0    0    0    0    0    0   51  211]
 [  44    0    2  239  514   42   87   53   14    5]
 [  23    0    3 2409  397  862  171  123    8    4]
 [  44    0    2  275 1811   36   67  244   18    3]
 [   8    0    0  842  172 3749   27  201    0    1]
 [   5    1    2  307  114   15 4539    5   12    0]
 [  26    1    0   50  172  132    1 4603    3   12]
 [ 125   29    0    1   40    1    4   10 4718   72]
 [  33  169    0    1   11    0    0   17   51 4718]]
TESTING class wise acc@24 :: {0: [0.504], 1: [0.899], 2: [0.0], 3: [0.538], 4: [0.646], 5: [0.727], 6: [0.89], 7: [0.883], 8: [0.889], 9: [0.919]}
TESTING epoch@24 ::  acc@0.689  loss@1.099
Epoch@@25
[[504  22   0  17 183   0   4  33 130 107]
 [  3 899   0   2   3   1   0   0  19  73]
 [ 44   0   0 210 432  92 134  60  17  11]
 [  7   5   0 538 114 199  79  41   3  14]
 [ 19   3   0 137 646  17  59 110   8   1]
 [  5   1   0 165  34 727  10  52   2   4]
 [  0   3   0  51  34  10 890   4   6   2]
 [  3   0   0  27  30  43   2 883   1  11]
 [ 33  15   0   5  13   0   5   6 889  34]
 [ 12  40   0   3   4   0   3   5  14 919]]
TRAINING class wise acc@25 :: {0: [0.502], 1: [0.93925], 2: [0.004], 3: [0.60075], 4: [0.7436], 5: [0.7522], 6: [0.909], 7: [0.9172], 8: [0.9462], 9: [0.9464]}
TRAIINING epoch@25 ::  acc@0.823  loss@0.515
[[ 502    8    0    3  167    0    1   24  222   73]
 [   8 3757    0    0    4    0    0    0   52  179]
 [  35    0    4  228  547   36   81   54   15    0]
 [  22    1    8 2403  375  863  200  109   13    6]
 [  54    1    8  237 1859   29   57  239   15    1]
 [   5    0    5  847  153 3761   18  205    2    4]
 [   9    0    9  280  119   15 4545    4   18    1]
 [  17    0    2   62  178  128    0 4586    3   24]
 [ 124   42    1    4   38    2    3    4 4731   51]
 [  52  143    0    1    8    0    0   20   44 4732]]
TESTING class wise acc@25 :: {0: [0.595], 1: [0.788], 2: [0.018], 3: [0.674], 4: [0.495], 5: [0.748], 6: [0.784], 7: [0.865], 8: [0.791], 9: [0.882]}
TESTING epoch@25 ::  acc@0.664  loss@1.365
Epoch@@26
[[595   2   8  73 175   4   9  37  46  51]
 [ 21 788   3  13   4   2   5   6  32 126]
 [ 41   0  18 390 262  99 109  77   2   2]
 [  4   1   2 674  33 227  23  34   1   1]
 [ 11   0  25 290 495  33  34 108   3   1]
 [  3   0   2 177  19 748   3  47   1   0]
 [  0   0   7 190  10   7 784   1   1   0]
 [  2   0   2  38  27  60   3 865   0   3]
 [ 91   5  10  20  32   0  24   6 791  21]
 [ 24  28   1  14  15   3   6  19   8 882]]
TRAINING class wise acc@26 :: {0: [0.587], 1: [0.9435], 2: [0.004], 3: [0.65825], 4: [0.7816], 5: [0.7714], 6: [0.9214], 7: [0.9332], 8: [0.9464], 9: [0.9506]}
TRAIINING epoch@26 ::  acc@0.842  loss@0.471
[[ 587    5    0    3  137    0    0   15  187   66]
 [   7 3774    0    0    1    0    1    0   37  180]
 [  29    0    4  223  574   34   83   42   11    0]
 [  12    1    3 2633  337  739  164   98    8    5]
 [  55    0    2  200 1954   40   53  185    8    3]
 [   7    1    1  789  133 3857    9  200    3    0]
 [   4    1    3  237  115   12 4607    5   15    1]
 [  13    2    0   36  156  109    0 4666    3   15]
 [ 131   35    0    1   35    1    7    2 4732   56]
 [  47  136    0    0   14    1    0   20   29 4753]]
TESTING class wise acc@26 :: {0: [0.675], 1: [0.833], 2: [0.007], 3: [0.491], 4: [0.641], 5: [0.63], 6: [0.902], 7: [0.95], 8: [0.894], 9: [0.783]}
TESTING epoch@26 ::  acc@0.681  loss@1.120
Epoch@@27
[[675   1   0   8 109   0   4  82 112   9]
 [ 30 833   0   3   6   0  10   3  73  42]
 [ 73   0   7 100 472  48 137 151  10   2]
 [ 13   0   3 491 174 133  90  89   7   0]
 [ 25   1   7  40 641  11  67 205   3   0]
 [  6   0   0 166  45 630  21 130   2   0]
 [  1   0   3  45  36   5 902   6   2   0]
 [  4   0   0  10  18  13   5 950   0   0]
 [ 67   5   0   1  15   0   6   9 894   3]
 [ 54  68   1   3  14   0   6  28  43 783]]
TRAINING class wise acc@27 :: {0: [0.641], 1: [0.956], 2: [0.018], 3: [0.685], 4: [0.8012], 5: [0.79], 6: [0.9306], 7: [0.9412], 8: [0.9456], 9: [0.9558]}
TRAIINING epoch@27 ::  acc@0.854  loss@0.431
[[ 641    6    0    2  127    0    0   19  153   52]
 [   6 3824    0    1    1    0    0    0   31  137]
 [  40    1   18  209  571   34   71   40   15    1]
 [  16    1   12 2740  307  726  139   47    7    5]
 [  45    0   17  169 2003   31   60  163   11    1]
 [   1    0    1  753  120 3950    6  168    0    1]
 [   4    0    8  229   85    5 4653    0   16    0]
 [  16    0    0   20  133  110    0 4706    0   15]
 [ 148   41    0    1   36    0    8    2 4728   36]
 [  50  112    0    0    9    0    0   17   33 4779]]
TESTING class wise acc@27 :: {0: [0.626], 1: [0.859], 2: [0.0], 3: [0.65], 4: [0.616], 5: [0.646], 6: [0.767], 7: [0.91], 8: [0.913], 9: [0.947]}
TESTING epoch@27 ::  acc@0.693  loss@1.036
Epoch@@28
[[626   3   0  14  94   0   0  26 150  87]
 [  8 859   0   0   2   0   0   1  12 118]
 [ 71   0   0 214 475  55  64  85  21  15]
 [ 19   3   0 650 106 110  22  70   9  11]
 [ 36   1   0 148 616  17  21 147   9   5]
 [  7   1   0 212  29 646   1  93   6   5]
 [  6   3   0 142  56   6 767   8   8   4]
 [ 11   0   0  20  19  26   1 910   0  13]
 [ 36  15   0   5   4   0   2   2 913  23]
 [  9  20   0   0   3   0   0   6  15 947]]
TRAINING class wise acc@28 :: {0: [0.672], 1: [0.954], 2: [0.022], 3: [0.732], 4: [0.832], 5: [0.8176], 6: [0.9358], 7: [0.9472], 8: [0.9564], 9: [0.956]}
TRAIINING epoch@28 ::  acc@0.869  loss@0.395
[[ 672    4    1    1  125    0    1   16  130   50]
 [   5 3816    0    1    2    0    0    0   37  139]
 [  34    0   22  158  635   26   85   26   13    1]
 [  15    1   11 2928  274  589  117   57    1    7]
 [  55    0   14  144 2080   20   36  140   11    0]
 [   6    0    1  641  109 4088    5  147    2    1]
 [   3    2   16  204   72    3 4679    3   17    1]
 [  17    0    0   25  110   98    0 4736    0   14]
 [ 120   36    0    0   28    0    5    1 4782   28]
 [  46  122    0    0   10    0    0   17   25 4780]]
TESTING class wise acc@28 :: {0: [0.613], 1: [0.903], 2: [0.029], 3: [0.635], 4: [0.722], 5: [0.586], 6: [0.918], 7: [0.874], 8: [0.911], 9: [0.869]}
TESTING epoch@28 ::  acc@0.706  loss@1.065
Epoch@@29
[[613   7   5  21 112   2  10  25 166  39]
 [ 11 903   0   2   2   0   1   2  32  47]
 [ 71   2  29 206 410  33 176  54  17   2]
 [ 10   2   8 635 117  94  92  33   4   5]
 [ 15   1  27  83 722  10  76  62   4   0]
 [  6   0   3 257  57 586  19  67   3   2]
 [  1   0   6  46  20   1 918   3   5   0]
 [ 13   0   4  29  53  22   2 874   0   3]
 [ 40   8   1   9  12   1   8   3 911   7]
 [ 23  62   2   2  11   0   2   7  22 869]]
TRAINING class wise acc@29 :: {0: [0.691], 1: [0.9615], 2: [0.055], 3: [0.757], 4: [0.8472], 5: [0.8266], 6: [0.9322], 7: [0.9494], 8: [0.9544], 9: [0.9602]}
TRAIINING epoch@29 ::  acc@0.876  loss@0.380
[[ 691    5    0    1  116    2    1   17  116   51]
 [  11 3846    0    0    0    2    0    1   33  107]
 [  32    0   55  165  597   21   97   19   13    1]
 [   1    0   25 3028  249  529  114   43    9    2]
 [  49    0   28  112 2118   25   53  106    7    2]
 [   2    0    2  597   90 4133    6  166    0    4]
 [   5    0   17  218   73    5 4661    1   19    1]
 [  15    0    0   12  107  103    0 4747    1   15]
 [ 115   35    0    3   33    0   13    0 4772   29]
 [  56  105    0    0    6    0    0   12   20 4801]]
TESTING class wise acc@29 :: {0: [0.541], 1: [0.876], 2: [0.0], 3: [0.607], 4: [0.75], 5: [0.772], 6: [0.839], 7: [0.894], 8: [0.904], 9: [0.909]}
TESTING epoch@29 ::  acc@0.709  loss@1.122
Epoch@@30
[[541  14   0  22 104  10   4  34 198  73]
 [ 10 876   0   3   7   3   2   1  13  85]
 [ 59   1   0 139 526  93  98  62  17   5]
 [  3   1   0 607 112 198  40  29   6   4]
 [ 17   0   0  78 750  31  25  90   8   1]
 [  1   0   0 131  46 772   2  43   3   2]
 [  2   1   0  74  64  12 839   4   3   1]
 [  9   0   0  14  37  38   2 894   1   5]
 [ 30  25   0   7  15   0   1   2 904  16]
 [ 17  34   0   3   8   2   1  14  12 909]]
TRAINING class wise acc@30 :: {0: [0.75], 1: [0.9665], 2: [0.082], 3: [0.77875], 4: [0.8492], 5: [0.8436], 6: [0.9484], 7: [0.9542], 8: [0.9574], 9: [0.9666]}
TRAIINING epoch@30 ::  acc@0.888  loss@0.333
[[ 750    5    2    1   91    0    1    9  101   40]
 [  11 3866    0    0    0    0    0    0   29   94]
 [  29    0   82  155  598   14   91   15   16    0]
 [   4    0   31 3115  211  495  106   33    4    1]
 [  41    0   71  105 2123   27   32   93    5    3]
 [   2    0    1  555   97 4218    3  124    0    0]
 [   3    0   38  157   45    6 4742    0    9    0]
 [  10    0    1   11  110   89    0 4771    0    8]
 [ 127   34    2    1   20    0    7    1 4787   21]
 [  51   84    0    0    7    0    0   12   13 4833]]
TESTING class wise acc@30 :: {0: [0.533], 1: [0.895], 2: [0.0], 3: [0.716], 4: [0.499], 5: [0.811], 6: [0.676], 7: [0.746], 8: [0.846], 9: [0.881]}
TESTING epoch@30 ::  acc@0.660  loss@1.654
Epoch@@31
[[533   8   0  81 185   5   0  10 130  48]
 [ 13 895   0   6   8   0   0   1  27  50]
 [ 34   0   0 436 311 133  51  18  10   7]
 [  4   0   0 716  35 228  10   6   0   1]
 [  8   1   0 310 499 101  20  57   4   0]
 [  3   0   0 155  13 811   0  16   2   0]
 [  1   0   0 290  15  15 676   0   3   0]
 [  5   0   0  47  27 167   2 746   0   6]
 [ 31  18   0  25  42   1   5   7 846  25]
 [ 16  61   0   8  14   6   1   6   7 881]]
TRAINING class wise acc@31 :: {0: [0.774], 1: [0.96575], 2: [0.114], 3: [0.78175], 4: [0.862], 5: [0.852], 6: [0.9462], 7: [0.9574], 8: [0.9674], 9: [0.9684]}
TRAIINING epoch@31 ::  acc@0.893  loss@0.316
[[ 774    5    2    2   85    0    1    6   89   36]
 [   6 3863    0    0    1    0    0    0   35   95]
 [  43    0  114  143  552   19  110   11    7    1]
 [   4    1   33 3127  205  501  106   20    3    0]
 [  46    0   55   95 2155   19   30   96    3    1]
 [   2    0    1  519   79 4260    4  134    0    1]
 [   3    2   46  160   42    2 4731    0   14    0]
 [   9    0    0    9   87   98    0 4787    0   10]
 [ 101   30    1    1   15    0    4    0 4837   11]
 [  44   84    0    1    7    0    0   15    7 4842]]
TESTING class wise acc@31 :: {0: [0.602], 1: [0.899], 2: [0.043], 3: [0.655], 4: [0.621], 5: [0.781], 6: [0.895], 7: [0.83], 8: [0.886], 9: [0.9]}
TESTING epoch@31 ::  acc@0.711  loss@1.403
Epoch@@32
[[602  14   4  49  93   4  15  26 133  60]
 [ 12 899   0   5   8   0   1   2  10  63]
 [ 66   1  43 232 287 103 227  23  16   2]
 [  4   2   6 655  59 172  81  14   3   4]
 [ 11   0  13 122 621  61  54 111   6   1]
 [  1   0   1 160  18 781  11  27   1   0]
 [  0   0   2  78  10   6 895   2   6   1]
 [  4   0   2  32  27  97   5 830   0   3]
 [ 33  31   0  10  17   0   5   4 886  14]
 [ 16  47   0   5   6   3   2  10  11 900]]
TRAINING class wise acc@32 :: {0: [0.764], 1: [0.96775], 2: [0.196], 3: [0.803], 4: [0.8732], 5: [0.8728], 6: [0.9462], 7: [0.9604], 8: [0.963], 9: [0.9694]}
TRAIINING epoch@32 ::  acc@0.901  loss@0.306
[[ 764    2    6    0   91    0    2    8   87   40]
 [   6 3871    0    0    2    0    0    0   31   90]
 [  32    0  196  115  510   12  109   11   14    1]
 [   8    0   44 3212  220  390  105   14    6    1]
 [  42    0   72   73 2183   21   17   83    5    4]
 [   3    1    4  449   68 4364    3  108    0    0]
 [   3    0   57  147   38    3 4731    1   20    0]
 [  15    1    1   14   84   75    0 4802    0    8]
 [ 122   27    9    0   13    0    5    0 4815    9]
 [  40   76    1    3    6    0    0   14   13 4847]]
TESTING class wise acc@32 :: {0: [0.565], 1: [0.892], 2: [0.173], 3: [0.657], 4: [0.817], 5: [0.589], 6: [0.778], 7: [0.833], 8: [0.899], 9: [0.933]}
TESTING epoch@32 ::  acc@0.714  loss@1.095
Epoch@@33
[[565  11  14  30 128   0   1  11 174  66]
 [  9 892   0   1   4   0   0   0  20  74]
 [ 50   2 173 199 402  40  74  21  27  12]
 [ 10   4  36 657 133  84  35  12  11  18]
 [ 17   0  27  67 817  16  11  35   7   3]
 [  8   1  10 264  73 589   5  35  10   5]
 [  2   2  79  83  46   3 778   1   5   1]
 [ 12   2   3  22  70  43   3 833   0  12]
 [ 28  34   2   5   9   0   1   2 899  20]
 [ 12  37   1   2   3   0   1   2   9 933]]
TRAINING class wise acc@33 :: {0: [0.787], 1: [0.96675], 2: [0.254], 3: [0.8225], 4: [0.8632], 5: [0.8786], 6: [0.9502], 7: [0.9592], 8: [0.963], 9: [0.9668]}
TRAIINING epoch@33 ::  acc@0.905  loss@0.290
[[ 787    6    2    0   67    0    2    8   96   32]
 [   8 3867    0    0    2    0    0    0   27   96]
 [  31    0  254  109  459    4  112   12   17    2]
 [   7    0   57 3290  146  401   83   13    1    2]
 [  35    1   88   73 2158   21   24   94    4    2]
 [   1    1    0  433   63 4393    1  106    0    2]
 [   1    1   87  129   19    0 4751    1   11    0]
 [   7    0    0   12   95   78    0 4796    0   12]
 [ 120   36    1    2    8    0    4    0 4815   14]
 [  59   77    0    0    8    0    0   11   11 4834]]
TESTING class wise acc@33 :: {0: [0.65], 1: [0.938], 2: [0.045], 3: [0.565], 4: [0.729], 5: [0.803], 6: [0.792], 7: [0.866], 8: [0.937], 9: [0.849]}
TESTING epoch@33 ::  acc@0.717  loss@1.198
Epoch@@34
[[650  12   1  17  88   6   0  14 157  55]
 [  8 938   0   0   2   0   1   0  15  36]
 [ 78   6  45 160 439 116  84  34  29   9]
 [ 18   3   2 565 105 224  26  30  15  12]
 [ 32   1   6  74 729  72  15  58  13   0]
 [  9   2   2  85  35 803   3  50   8   3]
 [ 10   5  17  98  51   8 792   4  13   2]
 [ 20   0   0   9  38  59   2 866   0   6]
 [ 26  13   1   4   6   1   4   2 937   6]
 [ 18  91   0   0   7   0   1   5  29 849]]
TRAINING class wise acc@34 :: {0: [0.832], 1: [0.97775], 2: [0.378], 3: [0.8485], 4: [0.8888], 5: [0.905], 6: [0.9484], 7: [0.9696], 8: [0.97], 9: [0.9758]}
TRAIINING epoch@34 ::  acc@0.922  loss@0.244
[[ 832    3    6    0   50    0    0    5   74   30]
 [   6 3911    0    0    0    0    0    0   22   61]
 [  23    0  378  103  375    4   93   10   12    2]
 [   4    0   50 3394  134  317   85   13    2    1]
 [  35    0   99   65 2222   17    8   50    1    3]
 [   1    0    3  321   53 4525    3   94    0    0]
 [   2    0   85  143   17    0 4742    0   11    0]
 [   9    0    1    1   64   66    0 4848    0   11]
 [  91   27   13    0   10    0    5    0 4850    4]
 [  41   60    0    0    2    1    0   13    4 4879]]
TESTING class wise acc@34 :: {0: [0.697], 1: [0.943], 2: [0.175], 3: [0.761], 4: [0.619], 5: [0.513], 6: [0.926], 7: [0.674], 8: [0.887], 9: [0.783]}
TESTING epoch@34 ::  acc@0.698  loss@1.657
Epoch@@35
[[697  21  25  35  64   0   9   3 106  40]
 [ 12 943   2   5   0   0   4   1  16  17]
 [ 83   2 175 231 203  21 261  10  14   0]
 [ 10   3  17 761  55  38 109   4   1   2]
 [ 29   2  90 164 619   5  79   7   5   0]
 [  6   0   6 401  35 513  26  12   1   0]
 [  2   0  16  41  10   2 926   0   3   0]
 [ 17   0   7 100 116  67  10 674   0   9]
 [ 36  30  11   9  13   0   9   1 887   4]
 [ 34 141   2   8  11   0   4   2  15 783]]
TRAINING class wise acc@35 :: {0: [0.847], 1: [0.9785], 2: [0.459], 3: [0.875], 4: [0.894], 5: [0.9188], 6: [0.9592], 7: [0.9728], 8: [0.9708], 9: [0.9788]}
TRAIINING epoch@35 ::  acc@0.932  loss@0.214
[[ 847    5    8    0   52    0    0    3   60   25]
 [   8 3914    0    0    0    0    0    1   22   55]
 [  31    0  459   74  328    3   86    5   14    0]
 [   4    0   39 3500  100  259   88    7    2    1]
 [  40    0  100   50 2235   13    7   53    1    1]
 [   1    1    4  286   37 4594    0   76    0    1]
 [   1    0   79  107   10    0 4796    0    7    0]
 [   7    0    1    1   68   52    0 4864    0    7]
 [  95   21    8    1    6    0    3    0 4854   12]
 [  38   53    0    0    5    0    0    6    4 4894]]
TESTING class wise acc@35 :: {0: [0.746], 1: [0.892], 2: [0.281], 3: [0.713], 4: [0.601], 5: [0.745], 6: [0.841], 7: [0.873], 8: [0.847], 9: [0.939]}
TESTING epoch@35 ::  acc@0.748  loss@1.247
Epoch@@36
[[746   7  29  23  41   1   1  18  53  81]
 [  8 892   0   0   2   0   0   0   6  92]
 [ 86   4 281 230 159  66 118  36  11   9]
 [ 21   2  20 713  58 119  26  24   5  12]
 [ 33   1  55 134 601  45  21 101   7   2]
 [ 13   0   4 170  24 745   4  34   2   4]
 [ 10   3  28  87  14   5 841   4   6   2]
 [  8   0   4  27  18  55   2 873   0  13]
 [ 76  30   2   5   6   0   3   4 847  27]
 [ 12  32   0   2   0   0   1   5   9 939]]
TRAINING class wise acc@36 :: {0: [0.843], 1: [0.978], 2: [0.494], 3: [0.84825], 4: [0.8884], 5: [0.9076], 6: [0.9502], 7: [0.9638], 8: [0.9762], 9: [0.9744]}
TRAIINING epoch@36 ::  acc@0.926  loss@0.237
[[ 843    5    9    1   51    0    0    3   58   30]
 [  12 3912    0    1    0    0    0    0   20   55]
 [  30    0  494   85  288    4   82    3   14    0]
 [   6    0   60 3393  129  304   90   16    1    1]
 [  39    0   95   47 2221   21    8   67    1    1]
 [   0    0    0  310   45 4538    1  105    0    1]
 [   2    1  110  116   12    2 4751    1    5    0]
 [   4    0    0    6   84   74    0 4819    0   13]
 [  66   23   13    0    5    0    3    0 4881    9]
 [  44   58    1    0    5    1    0   15    4 4872]]
TESTING class wise acc@36 :: {0: [0.64], 1: [0.896], 2: [0.123], 3: [0.729], 4: [0.687], 5: [0.667], 6: [0.907], 7: [0.802], 8: [0.918], 9: [0.878]}
TESTING epoch@36 ::  acc@0.725  loss@1.474
Epoch@@37
[[640   7  15  39  84   0   8   4 151  52]
 [ 15 896   0   4   4   1   0   0  26  54]
 [ 65   1 123 237 197  41 286  18  29   3]
 [ 19   2   6 729  76  82  70   9   3   4]
 [ 18   1  31 133 687  14  83  28   5   0]
 [  7   0   5 242  35 667  12  27   4   1]
 [  3   0   7  62  12   3 907   1   5   0]
 [  6   1   1  43  74  53  10 802   2   8]
 [ 37  13   3   5   7   0   4   1 918  12]
 [ 25  55   1   2   8   0   4   6  21 878]]
TRAINING class wise acc@37 :: {0: [0.858], 1: [0.97975], 2: [0.553], 3: [0.88], 4: [0.9072], 5: [0.9232], 6: [0.9586], 7: [0.9704], 8: [0.9744], 9: [0.9814]}
TRAIINING epoch@37 ::  acc@0.938  loss@0.201
[[ 858    3   10    1   45    0    0    8   54   21]
 [   9 3919    0    0    0    1    0    0   21   50]
 [  27    0  553   54  258    3   84    7   14    0]
 [   5    0   46 3520   83  267   74    4    1    0]
 [  38    0   96   35 2268   12    1   47    2    1]
 [   1    0    2  272   35 4616    0   73    1    0]
 [   1    0   82  104    6    2 4793    1   10    1]
 [   8    0    0    4   60   68    0 4852    0    8]
 [  72   28   13    1    4    0    4    0 4872    6]
 [  44   37    0    0    2    0    0    7    3 4907]]
TESTING class wise acc@37 :: {0: [0.703], 1: [0.89], 2: [0.352], 3: [0.704], 4: [0.753], 5: [0.646], 6: [0.73], 7: [0.794], 8: [0.904], 9: [0.928]}
TESTING epoch@37 ::  acc@0.740  loss@1.276
Epoch@@38
[[703  10  20  25  35   1   0   3 111  92]
 [ 11 890   1   1   4   0   0   0  21  72]
 [ 88   2 352 165 233  38  66  18  31   7]
 [ 29   4  40 704  80 100  24   8   6   5]
 [ 38   1  43  82 753  24   8  35  13   3]
 [ 11   1  17 231  54 646   2  26   8   4]
 [  4   1  92 118  38   3 730   0  14   0]
 [ 13   0   7  22  75  67   3 794   2  17]
 [ 34  20   2   5  11   1   2   0 904  21]
 [ 14  33   2   4   3   0   0   1  15 928]]
TRAINING class wise acc@38 :: {0: [0.858], 1: [0.98075], 2: [0.613], 3: [0.8985], 4: [0.9172], 5: [0.9394], 6: [0.961], 7: [0.9764], 8: [0.9738], 9: [0.9846]}
TRAIINING epoch@38 ::  acc@0.946  loss@0.176
[[ 858    6   11    1   40    0    0    0   58   26]
 [   7 3923    0    0    0    0    0    0   21   49]
 [  20    0  613   61  215    0   72    3   16    0]
 [   3    0   48 3594   88  197   63    5    2    0]
 [  30    0   81   31 2293   14    3   46    2    0]
 [   1    0    2  197   33 4697    0   70    0    0]
 [   0    0   94   87    2    0 4805    0   12    0]
 [   3    0    0    2   46   58    0 4882    1    8]
 [  86   19    9    0    3    0    6    0 4869    8]
 [  24   34    0    0    5    0    0    9    5 4923]]
TESTING class wise acc@38 :: {0: [0.603], 1: [0.927], 2: [0.259], 3: [0.657], 4: [0.639], 5: [0.773], 6: [0.863], 7: [0.814], 8: [0.947], 9: [0.871]}
TESTING epoch@38 ::  acc@0.735  loss@1.546
Epoch@@39
[[603  17  32  21 108   2   4   8 175  30]
 [ 10 927   2   1   7   0   2   0  23  28]
 [ 40   2 259 211 198  96 136  19  36   3]
 [  9   3  22 657  59 158  60  11  13   8]
 [ 12   3  40 141 639  82  30  42  11   0]
 [  2   1   4 161  22 773   7  17   9   4]
 [  0   1  19  86  14  10 863   0   6   1]
 [  7   0   6  27  41  90   5 814   2   8]
 [ 21  10   3   4  10   0   2   0 947   3]
 [ 15  73   2   2   5   0   1   6  25 871]]
TRAINING class wise acc@39 :: {0: [0.865], 1: [0.9775], 2: [0.63], 3: [0.88825], 4: [0.9084], 5: [0.9326], 6: [0.9588], 7: [0.971], 8: [0.9768], 9: [0.9766]}
TRAIINING epoch@39 ::  acc@0.942  loss@0.196
[[ 865    6   10    1   39    0    0    4   44   31]
 [   6 3910    0    1    1    0    1    0   24   57]
 [  29    1  630   64  194    1   65    1   15    0]
 [   3    0   37 3553   98  219   81    7    1    1]
 [  26    1   94   34 2271   17    2   53    1    1]
 [   0    0    2  213   37 4663    0   83    0    2]
 [   3    0   88  103    6    1 4794    1    4    0]
 [   6    0    0    2   71   60    0 4855    0    6]
 [  73   25    8    0    5    0    0    0 4884    5]
 [  42   51    0    1    5    0    0   10    8 4883]]
TESTING class wise acc@39 :: {0: [0.695], 1: [0.922], 2: [0.343], 3: [0.523], 4: [0.669], 5: [0.791], 6: [0.862], 7: [0.935], 8: [0.833], 9: [0.821]}
TESTING epoch@39 ::  acc@0.739  loss@1.373
Epoch@@40
[[695   7  54  19  77   5   3  53  47  40]
 [ 11 922   6   2   4   1   2   3  19  30]
 [ 59   1 343 108 207  81 116  79   5   1]
 [  8   1  31 523  87 240  41  67   1   1]
 [ 10   1  87  65 669  37  30  98   2   1]
 [  2   0  13  86  33 791   8  65   1   1]
 [  0   0  36  68  14  11 862   8   1   0]
 [  4   0   6   6  19  28   1 935   0   1]
 [103  18   5   7   7   1   7  13 833   6]
 [ 26  80   2   2  12   4   2  35  16 821]]
TRAINING class wise acc@40 :: {0: [0.894], 1: [0.98725], 2: [0.738], 3: [0.90875], 4: [0.9312], 5: [0.9474], 6: [0.9648], 7: [0.9818], 8: [0.9796], 9: [0.985]}
TRAIINING epoch@40 ::  acc@0.956  loss@0.143
[[ 894    7   11    0   27    0    0    5   38   18]
 [   7 3949    0    0    0    0    0    0   11   33]
 [  17    0  738   36  135    0   59    3   12    0]
 [   1    1   42 3635   62  200   55    3    1    0]
 [  24    0   70   21 2328   19    1   34    3    0]
 [   0    0    0  184   28 4737    0   51    0    0]
 [   1    0   76   86    5    0 4824    0    8    0]
 [   0    0    0    0   44   38    0 4909    0    9]
 [  71   11   17    0    2    0    0    0 4898    1]
 [  28   36    0    0    1    0    0    7    3 4925]]
TESTING class wise acc@40 :: {0: [0.738], 1: [0.92], 2: [0.307], 3: [0.556], 4: [0.711], 5: [0.716], 6: [0.919], 7: [0.826], 8: [0.883], 9: [0.872]}
TESTING epoch@40 ::  acc@0.745  loss@1.401
Epoch@@41
[[738  11  32   9  76   0   9   5  80  40]
 [ 11 920   3   2   0   0   1   0  22  41]
 [ 81   2 307  86 240  45 203  16  16   4]
 [ 21   2  42 556 102 125 125  11   7   9]
 [ 26   1  80  63 711  25  57  32   3   2]
 [  8   1  14 145  53 716  24  29   5   5]
 [  3   0  20  32  15   4 919   2   4   1]
 [ 10   1   6  14  78  42   8 826   0  15]
 [ 68  22   3   2   6   0   5   0 883  11]
 [ 22  79   3   0   5   0   3   0  16 872]]
TRAINING class wise acc@41 :: {0: [0.86], 1: [0.9815], 2: [0.708], 3: [0.898], 4: [0.9264], 5: [0.9384], 6: [0.9628], 7: [0.9732], 8: [0.9772], 9: [0.9808]}
TRAIINING epoch@41 ::  acc@0.948  loss@0.176
[[ 860    3   14    0   42    0    0    5   54   22]
 [  10 3926    0    0    1    0    0    1   18   44]
 [  20    0  708   36  152    3   65    3   13    0]
 [   5    0   53 3592   82  210   53    3    0    2]
 [  21    0   68   39 2316   11    2   42    1    0]
 [   1    0    0  189   42 4692    0   76    0    0]
 [   0    1   93   81    3    0 4814    0    8    0]
 [   5    0    1    2   58   59    0 4866    0    9]
 [  72   19    9    0    3    0    1    1 4886    9]
 [  35   49    1    1    1    0    0    8    1 4904]]
TESTING class wise acc@41 :: {0: [0.71], 1: [0.813], 2: [0.319], 3: [0.66], 4: [0.67], 5: [0.768], 6: [0.868], 7: [0.845], 8: [0.894], 9: [0.936]}
TESTING epoch@41 ::  acc@0.748  loss@1.385
Epoch@@42
[[710   3  56  25  52   3   3   9  82  57]
 [ 16 813   1   3   5   1   0   1  20 140]
 [ 68   3 319 150 173  81 167  24   9   6]
 [ 25   1  43 660  42 159  54   6   3   7]
 [ 27   0  77  96 670  55  22  47   4   2]
 [  5   0   6 151  31 768   9  23   3   4]
 [  4   1  30  67  14   9 868   2   3   2]
 [ 12   1   4  18  32  74   2 845   1  11]
 [ 62   8   6   5   4   1   3   1 894  16]
 [ 26  18   1   2   2   2   1   4   8 936]]
TRAINING class wise acc@42 :: {0: [0.888], 1: [0.98425], 2: [0.758], 3: [0.91375], 4: [0.9312], 5: [0.9484], 6: [0.9718], 7: [0.9808], 8: [0.9782], 9: [0.9836]}
TRAIINING epoch@42 ::  acc@0.957  loss@0.146
[[ 888    6    9    1   29    0    0    6   35   26]
 [   7 3937    0    0    0    0    0    0   19   37]
 [  12    0  758   33  130    2   54    1   10    0]
 [   2    0   35 3655   75  193   38    1    0    1]
 [  20    1   65   29 2328   14    1   41    0    1]
 [   1    0    1  160   41 4742    0   54    1    0]
 [   0    0   79   54    3    0 4859    0    5    0]
 [   6    0    0    1   31   48    0 4904    0   10]
 [  68   14   18    1    2    0    2    0 4891    4]
 [  35   32    0    0    2    0    0   11    2 4918]]
TESTING class wise acc@42 :: {0: [0.604], 1: [0.887], 2: [0.361], 3: [0.736], 4: [0.556], 5: [0.757], 6: [0.794], 7: [0.855], 8: [0.913], 9: [0.871]}
TESTING epoch@42 ::  acc@0.733  loss@1.648
Epoch@@43
[[604   9  52  27  52   5   1  21 182  47]
 [ 12 887   4   4   7   2   2   2  31  49]
 [ 54   0 361 234 126  72  84  34  31   4]
 [  9   1  40 736  41 128  19  17   7   2]
 [ 20   1  98 180 556  63  24  54   4   0]
 [  4   0   7 176  23 757   3  26   4   0]
 [  1   0  34 145   5  15 794   3   3   0]
 [  5   0   4  27  24  77   2 855   1   5]
 [ 35   8  12   9   6   0   1   4 913  12]
 [ 24  50   5   6   8   4   1  13  18 871]]
TRAINING class wise acc@43 :: {0: [0.919], 1: [0.985], 2: [0.784], 3: [0.9205], 4: [0.9336], 5: [0.9548], 6: [0.9712], 7: [0.9794], 8: [0.98], 9: [0.9862]}
TRAIINING epoch@43 ::  acc@0.960  loss@0.132
[[ 919    3    4    0   21    0    0    2   32   19]
 [   8 3940    0    0    0    0    0    0   17   35]
 [  18    0  784   37  103    2   42    1   13    0]
 [   2    0   26 3682   65  170   52    2    1    0]
 [  18    0   62   28 2334   11    2   41    2    2]
 [   0    0    0  144   23 4774    0   58    0    1]
 [   1    0   70   66    0    0 4856    0    7    0]
 [   2    0    0    1   50   46    0 4897    0    4]
 [  57   24   14    0    1    0    3    0 4900    1]
 [  29   28    0    0    1    0    0    9    2 4931]]
TESTING class wise acc@43 :: {0: [0.564], 1: [0.939], 2: [0.388], 3: [0.684], 4: [0.549], 5: [0.751], 6: [0.868], 7: [0.85], 8: [0.852], 9: [0.909]}
TESTING epoch@43 ::  acc@0.735  loss@1.801
Epoch@@44
[[564  41  78  36  52   9   4  25 115  76]
 [  4 939   0   3   2   0   1   2   5  44]
 [ 45   4 388 176 134  80 101  50  14   8]
 [  9   1  27 684  41 147  59  18   2  12]
 [ 13   2  97 124 549  55  35 121   3   1]
 [  5   0  14 179  18 751   4  25   0   4]
 [  2   0  40  68  10   6 868   2   2   2]
 [  3   0   7  27  13  82   2 850   1  15]
 [ 31  45  11   9   9   0   3   6 852  34]
 [  4  65   2   1   2   3   1   5   8 909]]
TRAINING class wise acc@44 :: {0: [0.93], 1: [0.9875], 2: [0.833], 3: [0.945], 4: [0.9464], 5: [0.9704], 6: [0.9772], 7: [0.9836], 8: [0.9878], 9: [0.9872]}
TRAIINING epoch@44 ::  acc@0.970  loss@0.097
[[ 930    2    5    0   19    0    0    2   25   17]
 [   7 3950    0    0    0    0    0    0    7   36]
 [  10    0  833   30   85    0   35    1    6    0]
 [   2    0   24 3780   37  106   46    5    0    0]
 [  23    0   56   13 2366    8    0   34    0    0]
 [   0    0    0   99   13 4852    0   36    0    0]
 [   1    0   61   50    1    0 4886    0    1    0]
 [   3    0    0    2   38   33    0 4918    0    6]
 [  39   12    6    0    2    0    1    0 4939    1]
 [  23   31    0    0    1    0    0    9    0 4936]]
TESTING class wise acc@44 :: {0: [0.633], 1: [0.895], 2: [0.425], 3: [0.546], 4: [0.708], 5: [0.767], 6: [0.864], 7: [0.913], 8: [0.895], 9: [0.93]}
TESTING epoch@44 ::  acc@0.758  loss@1.571
Epoch@@45
[[633  11  74  21  79   1   3  12  95  71]
 [  8 895   1   1   5   0   1   1  21  67]
 [ 47   2 425  92 194  71  99  52  11   7]
 [  9   1  44 546  88 174  61  60   4  13]
 [ 15   1  55  52 708  38  16 110   1   4]
 [  9   0  11  86  40 767   5  76   2   4]
 [  3   0  49  45  21   9 864   3   4   2]
 [  6   0   6   9  27  18   2 913   1  18]
 [ 49  13   6   5   9   2   4   4 895  13]
 [ 11  32   4   0   6   3   2   2  10 930]]
TRAINING class wise acc@45 :: {0: [0.92], 1: [0.98925], 2: [0.806], 3: [0.927], 4: [0.9428], 5: [0.96], 6: [0.9706], 7: [0.9826], 8: [0.9862], 9: [0.987]}
TRAIINING epoch@45 ::  acc@0.965  loss@0.116
[[ 920    2   10    0   19    0    0    1   29   19]
 [   2 3957    0    0    0    0    0    0   11   30]
 [  18    0  806   27   89    0   47    2   11    0]
 [   0    0   18 3708   56  154   57    7    0    0]
 [  16    0   45   28 2357   14    3   35    0    2]
 [   0    0    0  136   23 4800    0   41    0    0]
 [   0    0   71   72    2    1 4853    0    1    0]
 [   3    0    0    2   39   36    0 4913    0    7]
 [  49   14    4    0    1    0    1    0 4931    0]
 [  25   25    0    0    2    0    0   11    2 4935]]
TESTING class wise acc@45 :: {0: [0.601], 1: [0.878], 2: [0.37], 3: [0.766], 4: [0.705], 5: [0.681], 6: [0.878], 7: [0.826], 8: [0.684], 9: [0.893]}
TESTING epoch@45 ::  acc@0.728  loss@2.390
Epoch@@46
[[601  11  70  58 130   9   3  16  28  74]
 [ 13 878   5  12   7   0   4   2   4  75]
 [ 46   1 370 192 188  54 122  22   3   2]
 [  3   1  27 766  55  90  46  11   0   1]
 [  5   1  74 122 705  26  30  37   0   0]
 [  3   0   7 233  40 681  11  25   0   0]
 [  0   0  23  81  14   3 878   0   1   0]
 [  7   0   5  50  59  46   6 826   0   1]
 [ 94  48  38  31  31   3  10   2 684  59]
 [ 12  40   1  13  16   2   5  16   2 893]]
TRAINING class wise acc@46 :: {0: [0.88], 1: [0.9785], 2: [0.765], 3: [0.8955], 4: [0.9296], 5: [0.9396], 6: [0.959], 7: [0.974], 8: [0.973], 9: [0.9778]}
TRAIINING epoch@46 ::  acc@0.949  loss@0.186
[[ 880    4   11    2   37    0    0    3   43   20]
 [  11 3914    0    0    2    0    0    0   20   53]
 [  17    0  765   42   92    1   61    3   19    0]
 [  11    1   44 3582   95  193   64    3    6    1]
 [  29    1   50   41 2324   17    4   31    1    2]
 [   2    0    0  187   33 4698    0   75    2    3]
 [   2    2   90   93   10    0 4795    1    7    0]
 [   3    0    1    1   52   59    0 4870    0   14]
 [  73   19   24    0    2    0    3    2 4865   12]
 [  38   44    1    1    6    0    1   18    2 4889]]
TESTING class wise acc@46 :: {0: [0.683], 1: [0.876], 2: [0.391], 3: [0.627], 4: [0.768], 5: [0.779], 6: [0.731], 7: [0.814], 8: [0.884], 9: [0.882]}
TESTING epoch@46 ::  acc@0.743  loss@1.378
Epoch@@47
[[683   7  63  33  72   3   4   6  89  40]
 [ 25 876   6   3   7   2   1   2  22  56]
 [ 54   0 391 155 236  72  56  17  15   4]
 [  5   0  36 627 104 196  12  13   3   4]
 [ 12   1  32  66 768  68   5  44   4   0]
 [  2   0   7 136  48 779   1  22   4   1]
 [  3   0  56 147  44  15 731   1   3   0]
 [  4   0   5  16  58  92   1 814   0  10]
 [ 57  11  14   8  10   1   4   0 884  11]
 [ 25  51   7   4  13   1   1   2  14 882]]
TRAINING class wise acc@47 :: {0: [0.93], 1: [0.98725], 2: [0.835], 3: [0.94875], 4: [0.9528], 5: [0.9688], 6: [0.975], 7: [0.9858], 8: [0.9858], 9: [0.9864]}
TRAIINING epoch@47 ::  acc@0.971  loss@0.099
[[ 930    3    8    0   14    0    0    1   23   21]
 [   6 3949    0    0    0    0    0    0   11   34]
 [  13    0  835   17   75    0   49    2    9    0]
 [   0    0   13 3795   47  110   34    1    0    0]
 [  14    0   38   26 2382   10    0   29    1    0]
 [   0    0    0  110   18 4844    0   28    0    0]
 [   0    0   70   48    3    0 4875    0    4    0]
 [   2    0    0    1   31   31    0 4929    0    6]
 [  38   18    9    0    0    0    3    0 4929    3]
 [  28   29    1    0    0    0    0    8    2 4932]]
TESTING class wise acc@47 :: {0: [0.704], 1: [0.906], 2: [0.362], 3: [0.59], 4: [0.697], 5: [0.813], 6: [0.778], 7: [0.902], 8: [0.904], 9: [0.903]}
TESTING epoch@47 ::  acc@0.756  loss@1.549
Epoch@@48
[[704   9  30  16  55   2   0  14 137  33]
 [ 16 906   0   1   6   2   0   3  16  50]
 [ 74   1 362 109 216  85  72  46  31   4]
 [ 12   1  22 590  97 213  19  40   4   2]
 [ 24   1  26  76 697  62  14  91   8   1]
 [  6   0   6  84  31 813   1  54   4   1]
 [  5   0  40 113  27  19 778   5  12   1]
 [  9   0   1   9  34  39   2 902   0   4]
 [ 50  12   6   4   5   1   1   6 904  11]
 [ 23  44   2   4   5   2   1   6  10 903]]
TRAINING class wise acc@48 :: {0: [0.918], 1: [0.9895], 2: [0.855], 3: [0.93325], 4: [0.9468], 5: [0.964], 6: [0.9776], 7: [0.9842], 8: [0.9832], 9: [0.9874]}
TRAIINING epoch@48 ::  acc@0.968  loss@0.116
[[ 918    3    5    0   25    1    0    4   33   11]
 [   4 3958    0    1    1    0    0    0   11   25]
 [  10    0  855   26   62    1   34    1   11    0]
 [   5    0   27 3733   56  127   48    3    0    1]
 [  17    0   40   27 2367   15    3   29    0    2]
 [   1    2    0  112   26 4820    0   39    0    0]
 [   0    0   45   63    0    0 4888    0    4    0]
 [   4    0    1    2   42   27    0 4921    0    3]
 [  51   10   11    0    3    0    3    2 4916    4]
 [  27   25    0    0    0    0    0    7    4 4937]]
TESTING class wise acc@48 :: {0: [0.614], 1: [0.914], 2: [0.455], 3: [0.723], 4: [0.712], 5: [0.651], 6: [0.851], 7: [0.848], 8: [0.863], 9: [0.892]}
TESTING epoch@48 ::  acc@0.752  loss@1.418
Epoch@@49
[[614   8 105  26  99   0   5   9  73  61]
 [ 15 914   3   0   4   1   0   0  10  53]
 [ 42   0 455 160 140  32 141  13  11   6]
 [  8   1  50 723  78  68  56  10   1   5]
 [ 10   1  90 106 712  21  25  33   2   0]
 [  3   0  16 244  48 651   7  28   2   1]
 [  4   1  46  81  12   3 851   0   1   1]
 [ 11   0  12  29  60  28   3 848   1   8]
 [ 67  29  14   3   8   0   4   0 863  12]
 [ 23  58   5   3   5   0   2   3   9 892]]
TRAINING class wise acc@49 :: {0: [0.927], 1: [0.98975], 2: [0.842], 3: [0.939], 4: [0.95], 5: [0.961], 6: [0.9754], 7: [0.9806], 8: [0.9866], 9: [0.9856]}
TRAIINING epoch@49 ::  acc@0.968  loss@0.114
[[ 927    3   10    0   19    0    0    1   22   18]
 [   2 3959    0    0    0    0    0    0   10   29]
 [  15    0  842   22   66    0   47    1    7    0]
 [   3    0   17 3756   63  123   37    1    0    0]
 [  13    0   34   33 2375    6    1   34    3    1]
 [   0    0    0  115   25 4805    0   53    0    2]
 [   1    1   58   57    3    0 4877    0    3    0]
 [   1    0    1    0   40   47    0 4903    0    8]
 [  38    8   13    0    1    0    1    0 4933    6]
 [  29   30    0    1    5    0    0    6    1 4928]]
TESTING class wise acc@49 :: {0: [0.708], 1: [0.889], 2: [0.375], 3: [0.617], 4: [0.754], 5: [0.714], 6: [0.885], 7: [0.893], 8: [0.924], 9: [0.922]}
TESTING epoch@49 ::  acc@0.768  loss@1.539
[[708  11  33  12  29   0   2  12 117  76]
 [  6 889   1   2   3   0   2   2  18  77]
 [ 79   1 375 112 177  68 117  38  26   7]
 [ 22   1  35 617  94 120  63  25   9  14]
 [ 24   1  46  58 754  23  25  58   6   5]
 [ 11   0   8 147  52 714  10  51   4   3]
 [  4   0  41  35  18   6 885   3   7   1]
 [ 10   0   2  15  35  31   3 893   0  11]
 [ 34  10   8   1   3   1   5   2 924  12]
 [ 13  40   2   0   5   0   1   4  13 922]]
