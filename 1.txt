

Fri Jan 15 15:37:54 2021
imbal_test_balance1_rand_cifar10_vgg_Adam's set level: 10
imbal_test_balance1_rand_cifar10_vgg_Adam logger is ready
imbal_test with imbalance_ratio: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
parallel mode is False
initial count: cifar10: [0 1 2 3 4 5 6 7 8 9] class, each has [5000 5000 5000 5000 5000 5000 5000 5000 5000 5000]
cifar10: [0 1 2 3 4 5 6 7 8 9] class, each has [5000 5000 5000 5000 5000 5000 5000 5000 5000 5000]
Epoch@@0
Files already downloaded and verified
TRAINING class wise acc@0 :: {0: [0.1998], 1: [0.1076], 2: [0.0298], 3: [0.0968], 4: [0.167], 5: [0.041], 6: [0.1958], 7: [0.2274], 8: [0.0738], 9: [0.0864]}
TRAIINING epoch@0 ::  acc@0.123  loss@2.407
[[ 999  446  157  343  630  177  703  772  416  357]
 [ 167  538  138  489  844  225  907 1089  163  440]
 [ 261  543  149  477  780  226  918 1084  149  413]
 [  98  536  161  484  856  211  942 1100  126  486]
 [ 126  510  132  491  835  236  945 1170  109  446]
 [  72  556  152  486  848  205  921 1193  107  460]
 [  38  559  131  516  856  221  979 1149   72  479]
 [  74  534  129  502  832  228  993 1137  114  457]
 [ 657  498  154  399  692  184  767  862  369  418]
 [ 170  547  156  522  830  230  882 1060  171  432]]
TESTING class wise acc@0 :: {0: [0.027], 1: [0.0], 2: [0.0], 3: [0.0], 4: [0.0], 5: [0.0], 6: [0.0], 7: [0.0], 8: [0.286], 9: [0.936]}
TESTING epoch@0 ::  acc@0.125  loss@2.242
Epoch@@1
[[ 27   0   0   0   0   0   0   0 353 620]
 [  0   0   0   0   0   0   0   0  63 937]
 [  2   0   0   0   0   0   0   0  91 907]
 [  0   0   0   0   0   0   0   0  14 986]
 [  1   0   0   0   0   0   0   0  32 967]
 [  0   0   0   0   0   0   0   0  20 980]
 [  0   0   0   0   0   0   0   0   4 996]
 [  0   0   0   0   0   0   0   0  19 981]
 [  0   0   0   0   0   0   0   0 286 714]
 [  0   0   0   0   0   0   0   0  64 936]]
TRAINING class wise acc@1 :: {0: [0.1652], 1: [0.126], 2: [0.0044], 3: [0.0984], 4: [0.0698], 5: [0.1178], 6: [0.545], 7: [0.1942], 8: [0.4374], 9: [0.2656]}
TRAIINING epoch@1 ::  acc@0.202  loss@2.030
[[ 826  570   23  162   53  139  386  327 1639  875]
 [ 442  630   30  287   64  161  775  409 1082 1120]
 [ 126  161   22  394  285  463 2050  702  269  528]
 [  55  118   16  492  274  567 2178  771   83  446]
 [  78  117    9  419  349  514 2447  542  135  390]
 [  38   87   25  415  306  589 2273  815   61  391]
 [  18   58   11  411  374  547 2725  590   28  238]
 [  66  119   29  497  201  590 1892  971   84  551]
 [ 801  498   15  123   40   86  339  201 2187  710]
 [ 401  568   18  272   86  225  764  536  802 1328]]
TESTING class wise acc@1 :: {0: [0.348], 1: [0.0], 2: [0.0], 3: [0.0], 4: [0.18], 5: [0.199], 6: [0.167], 7: [0.579], 8: [0.143], 9: [0.535]}
TESTING epoch@1 ::  acc@0.215  loss@1.931
Epoch@@2
[[348   0   0   0   1  10   7 146  64 424]
 [533   0   0   0   0   0   0  41  27 399]
 [ 41   0   0   0 144 132 136 384   0 163]
 [ 15   0   0   0  66 155 136 456   0 172]
 [ 24   0   0   0 180 159 184 331   2 120]
 [  8   0   0   0  68 199 172 448   0 105]
 [  6   0   0   0 110 193 167 416   0 108]
 [  9   0   0   0  12 122  64 579   0 214]
 [516   0   0   0   0   3   3  53 143 282]
 [363   0   0   0   0   1   2  95   4 535]]
TRAINING class wise acc@2 :: {0: [0.2008], 1: [0.3766], 2: [0.0694], 3: [0.0946], 4: [0.1396], 5: [0.1634], 6: [0.4046], 7: [0.4854], 8: [0.4856], 9: [0.4]}
TRAIINING epoch@2 ::  acc@0.282  loss@1.795
[[1004  817  201  126   55   82   81  310 1500  824]
 [ 296 1883   58   47   19   40   44  257  829 1527]
 [ 250  128  347  409  547  542 1369  877  121  410]
 [  93   78  300  473  462  794 1512  949   30  309]
 [ 118  104  231  339  698  588 1651  912   51  308]
 [  69   55  236  447  497  817 1591 1045   10  233]
 [  40   33  171  369  676  713 2023  771   14  190]
 [  55   92  118  289  276  500  727 2427   17  499]
 [ 807  891  102   67   30   30   32   97 2428  516]
 [ 231 1360   58   82   42   75   50  616  486 2000]]
TESTING class wise acc@2 :: {0: [0.394], 1: [0.491], 2: [0.071], 3: [0.799], 4: [0.002], 5: [0.004], 6: [0.329], 7: [0.454], 8: [0.443], 9: [0.423]}
TESTING epoch@2 ::  acc@0.341  loss@1.646
Epoch@@3
[[394  35 140 182   0   0   0  11 190  48]
 [ 27 491   1  90   0   0   0   5 107 279]
 [ 56   1  71 588   0   3 225  33   7  16]
 [ 16   6  27 799   0   2  81  34   5  30]
 [ 14   7  33 487   2   7 322 111   3  14]
 [ 11   2  21 795   3   4  64  79   6  15]
 [  6   1   5 606   0   5 329  21   1  26]
 [  8   5   8 411   1   5  31 454   1  76]
 [312  68  45  81   0   0   0   4 443  47]
 [ 45 308   9 113   0   0   1  39  62 423]]
TRAINING class wise acc@3 :: {0: [0.4166], 1: [0.58], 2: [0.282], 3: [0.2122], 4: [0.2], 5: [0.4754], 6: [0.4308], 7: [0.5488], 8: [0.5278], 9: [0.494]}
TRAIINING epoch@3 ::  acc@0.417  loss@1.507
[[2083  306  418  241   29   93   40   66 1477  247]
 [ 126 2900   14   92   11   29   12   78  424 1314]
 [ 583   26 1410  587  385  778  868  205   65   93]
 [ 208   26  436 1061  138 1845  735  338   39  174]
 [ 228   23  591  417 1000  606 1233  720   39  143]
 [ 110    8  349  871  160 2377  562  438   17  108]
 [  97   18  393  554  568  881 2154  206   20  109]
 [ 107   30   97  403  319  678  220 2744   25  377]
 [1359  468  146  141   10   33   18   26 2639  160]
 [ 175 1485   27  159   16   54   18  306  290 2470]]
TESTING class wise acc@3 :: {0: [0.431], 1: [0.7], 2: [0.429], 3: [0.067], 4: [0.236], 5: [0.547], 6: [0.798], 7: [0.507], 8: [0.59], 9: [0.369]}
TESTING epoch@3 ::  acc@0.467  loss@1.450
Epoch@@4
[[431  31 219  10  27  14  20   2 240   6]
 [ 39 700   5  16  42   6  10   8  87  87]
 [ 64   4 429  20  75 122 258  10  16   2]
 [ 28   6 175  67  62 349 278  20   6   9]
 [ 32   2 149  18 236  45 453  55   7   3]
 [ 11   1 156  49  40 547 163  28   1   4]
 [  8   0  67  18  69  37 798   1   2   0]
 [ 13   3  52  35 135 150  82 507   5  18]
 [228  70  45   8  26   9  11   2 590  11]
 [ 37 356   7  16  55  12  12  55  81 369]]
TRAINING class wise acc@4 :: {0: [0.4904], 1: [0.7282], 2: [0.4286], 3: [0.2378], 4: [0.4036], 5: [0.5864], 6: [0.6802], 7: [0.621], 8: [0.6202], 9: [0.7086]}
TRAIINING epoch@4 ::  acc@0.550  loss@1.219
[[2452  150  507  197   92   71   65   56 1178  232]
 [  83 3641    4   73   33   15   51   11  331  758]
 [ 515   23 2143  449  456  614  547  157   59   37]
 [ 174   37  459 1189  228 1915  621  195   73  109]
 [ 209   30  670  293 2018  310  732  623   47   68]
 [  62   16  315  820  225 2932  245  332   11   42]
 [  63   38  319  450  397  247 3401   25   33   27]
 [  96   17  124  279  497  608   88 3105   15  171]
 [1097  334   78  126   31   25   30   18 3101  160]
 [ 149  759   12  115   31   23   21  156  191 3543]]
TESTING class wise acc@4 :: {0: [0.681], 1: [0.674], 2: [0.545], 3: [0.447], 4: [0.279], 5: [0.506], 6: [0.718], 7: [0.53], 8: [0.672], 9: [0.711]}
TESTING epoch@4 ::  acc@0.576  loss@1.162
Epoch@@5
[[681   8 105  39   6   2   4   3 132  20]
 [ 25 674   0  24   0   1   1   2 181  92]
 [125   1 545 124  26  39  98   3  35   4]
 [ 29   9 113 447  11 250  90   7  41   3]
 [ 42   3 258 134 279  41 164  60  13   6]
 [ 10   3  88 323  14 506  19  25  11   1]
 [ 12  20  49 161   7  12 718   0  21   0]
 [ 32   3  83 126  64 117  17 530   6  22]
 [229  17  15  46   1   4   3   0 672  13]
 [ 43 116   3  44   1   1   2  15  64 711]]
TRAINING class wise acc@5 :: {0: [0.6468], 1: [0.8184], 2: [0.5166], 3: [0.3182], 4: [0.5778], 5: [0.6144], 6: [0.735], 7: [0.6834], 8: [0.7588], 9: [0.8078]}
TRAIINING epoch@5 ::  acc@0.648  loss@0.993
[[3234   63  450  137   89   47   34   91  627  228]
 [  83 4092   10   58   14    8   57   13  209  456]
 [ 486   11 2583  421  544  373  358  139   72   13]
 [ 108   39  428 1591  253 1746  544  145   81   65]
 [ 187   18  542  218 2889  228  384  485   32   17]
 [  37   12  282  867  249 3072  161  268   15   37]
 [  26   50  269  496  294  123 3675   14   41   12]
 [ 104    9  135  208  461  515   25 3417   13  113]
 [ 614  177   63  112   13   12   52   11 3794  152]
 [ 184  395    4  104   20   11   19  101  123 4039]]
TESTING class wise acc@5 :: {0: [0.799], 1: [0.835], 2: [0.609], 3: [0.122], 4: [0.618], 5: [0.822], 6: [0.597], 7: [0.715], 8: [0.732], 9: [0.706]}
TESTING epoch@5 ::  acc@0.655  loss@0.967
Epoch@@6
[[799  11  79  10  19  12   1  18  42   9]
 [ 28 835   2  18   7   5   6   3  57  39]
 [ 84   0 609  21  93 137  14  35   7   0]
 [ 31   3 118 122  44 599  30  40   9   4]
 [ 30   0 104  26 618  87  17 107   9   2]
 [  5   0  42  28  29 822   7  63   3   1]
 [ 10   2 118 115  64  81 597   3  10   0]
 [ 20   0  40   7  75 139   0 715   0   4]
 [209  19   8  10   3   8   2   5 732   4]
 [ 67 104   1  16   7  20   1  41  37 706]]
TRAINING class wise acc@6 :: {0: [0.7198], 1: [0.862], 2: [0.5936], 3: [0.3908], 4: [0.6666], 5: [0.6328], 6: [0.7658], 7: [0.7388], 8: [0.8258], 9: [0.8322]}
TRAIINING epoch@6 ::  acc@0.703  loss@0.837
[[3599   61  404  103   92   24   27   87  426  177]
 [  77 4310    6   67   10    5   42    6  120  357]
 [ 408   10 2968  380  476  279  287  124   61    7]
 [  92   20  404 1954  253 1526  445  159   78   69]
 [ 167    9  416  232 3333  158  272  364   24   25]
 [  20    3  235  891  225 3164  126  307   10   19]
 [  23   33  240  493  244   83 3829   10   32   13]
 [  95    5  152  211  380  389   10 3694    9   55]
 [ 423  115   58  119    7    4   30    9 4129  106]
 [ 173  346    9   98   11    9   14   59  120 4161]]
TESTING class wise acc@6 :: {0: [0.807], 1: [0.885], 2: [0.79], 3: [0.22], 4: [0.708], 5: [0.273], 6: [0.814], 7: [0.533], 8: [0.839], 9: [0.581]}
TESTING epoch@6 ::  acc@0.645  loss@1.094
Epoch@@7
[[807   9 113   2  10   0   5   0  54   0]
 [ 33 885   2   0   0   0  16   0  55   9]
 [ 72   0 790  11  64   4  50   3   6   0]
 [ 50   9 363 220  78  41 199  14  25   1]
 [ 29   2 171   3 708   1  76   9   1   0]
 [ 15   0 321 177  73 273  95  40   5   1]
 [  7   1 142  10  18   0 814   1   7   0]
 [ 59   1 179  23 175  15  12 533   2   1]
 [106  15  21   5   2   0  10   0 839   2]
 [152 180  11  19   6   0   7   4  40 581]]
TRAINING class wise acc@7 :: {0: [0.7726], 1: [0.884], 2: [0.6476], 3: [0.4906], 4: [0.7388], 5: [0.649], 6: [0.8054], 7: [0.7808], 8: [0.858], 9: [0.8586]}
TRAIINING epoch@7 ::  acc@0.749  loss@0.724
[[3863   44  325  119   79    7   16   90  310  147]
 [  64 4420    5   63   12    3   27    5  102  299]
 [ 372    3 3238  325  399  253  260   97   46    7]
 [  93   24  331 2453  239 1253  355  144   55   53]
 [ 135    5  337  243 3694  111  194  257   14   10]
 [  22    3  229  942  181 3245   89  262   10   17]
 [  19   34  223  394  188   66 4027   10   32    7]
 [  77    2  126  220  290  310    7 3904    4   60]
 [ 343  107   40  100    5    4   22    3 4290   86]
 [ 153  264    3  133   10    3    3   59   79 4293]]
TESTING class wise acc@7 :: {0: [0.504], 1: [0.954], 2: [0.702], 3: [0.314], 4: [0.705], 5: [0.563], 6: [0.963], 7: [0.548], 8: [0.787], 9: [0.519]}
TESTING epoch@7 ::  acc@0.656  loss@1.077
Epoch@@8
[[504  46 241  13  35   1  52   1 101   6]
 [  4 954   2   2   1   1  20   0   9   7]
 [ 15   2 702   9  54  24 190   1   3   0]
 [  6  10 136 314  58 122 345   2   7   0]
 [  2   5  81  12 705  27 158   9   1   0]
 [  2   1 138  94  44 563 154   4   0   0]
 [  0   2  15   8   7   5 963   0   0   0]
 [ 14   3 111  37 125 134  25 548   0   3]
 [ 20  72  36  10   2   1  69   0 787   3]
 [ 22 369   3  20   3   0  20   0  44 519]]
TRAINING class wise acc@8 :: {0: [0.7998], 1: [0.8972], 2: [0.7034], 3: [0.587], 4: [0.7704], 5: [0.669], 6: [0.8172], 7: [0.815], 8: [0.8698], 9: [0.8712]}
TRAIINING epoch@8 ::  acc@0.780  loss@0.648
[[3999   55  277  104   75    8   16   79  273  114]
 [  58 4486    1   50    9    1   28    6   91  270]
 [ 301    4 3517  280  313  241  209   85   41    9]
 [  78   12  287 2935  210  942  293  126   61   56]
 [  93    2  260  247 3852  108  175  248    7    8]
 [  17    0  193  946  179 3345   77  234    6    3]
 [  28   29  212  364  168   77 4086    4   26    6]
 [  80    0  115  206  239  242    1 4075    1   41]
 [ 291   88   40  107    5    0   27    5 4349   88]
 [ 125  231    5  124    7    4    7   58   83 4356]]
TESTING class wise acc@8 :: {0: [0.418], 1: [0.625], 2: [0.531], 3: [0.62], 4: [0.64], 5: [0.63], 6: [0.569], 7: [0.661], 8: [0.988], 9: [0.816]}
TESTING epoch@8 ::  acc@0.650  loss@1.189
Epoch@@9
[[418   0  35  27   1   0   0   3 500  16]
 [  3 625   0   9   0   2   2   0 249 110]
 [ 54   0 531 141  69  62  19  10 109   5]
 [  8   0  21 620  29 120  12   1 172  17]
 [ 38   0  51 142 640  11   5  51  57   5]
 [  1   0  18 266  17 630   1  17  40  10]
 [  3   2  52 210  63  19 569   1  80   1]
 [ 20   0  12 108  44  61   0 661  39  55]
 [  2   1   0   7   0   1   0   0 988   1]
 [  1  11   1   4   0   0   0   0 167 816]]
TRAINING class wise acc@9 :: {0: [0.8218], 1: [0.9086], 2: [0.7422], 3: [0.6328], 4: [0.7936], 5: [0.7046], 6: [0.8382], 7: [0.8374], 8: [0.8844], 9: [0.8854]}
TRAIINING epoch@9 ::  acc@0.805  loss@0.582
[[4109   41  254  107   77    8   15   80  211   98]
 [  65 4543    1   53    3    1   28    1   76  229]
 [ 279    4 3711  249  259  185  191   82   33    7]
 [  55   10  244 3164  214  829  278  119   42   45]
 [  91    6  221  218 3968  108  159  219    6    4]
 [  12    3  187  855  129 3523   76  204    6    5]
 [  28   26  176  321  141   77 4191    6   31    3]
 [  57    5  109  193  210  192    6 4187    3   38]
 [ 259   85   39   81    5    4   25    6 4422   74]
 [ 114  231    3   93    5    4    4   47   72 4427]]
TESTING class wise acc@9 :: {0: [0.726], 1: [0.837], 2: [0.522], 3: [0.608], 4: [0.809], 5: [0.694], 6: [0.643], 7: [0.819], 8: [0.931], 9: [0.918]}
TESTING epoch@9 ::  acc@0.751  loss@0.784
Epoch@@10
[[726   9   5  17  11   0   0  10 155  67]
 [ 14 837   0   7   0   1   1   1  31 108]
 [164   2 522  66 131  53  22  11  25   4]
 [ 30   3  34 608  61 153  19  21  28  43]
 [ 41   1  20  41 809  10   8  59   8   3]
 [  8   0  25 171  48 694   1  37   4  12]
 [ 16  15  39 143  97  23 643   1  18   5]
 [ 22   0  13  41  41  43   0 819   3  18]
 [ 17   5   1  11   0   1   0   1 931  33]
 [  6  27   1   2   1   0   1   5  39 918]]
TRAINING class wise acc@10 :: {0: [0.8434], 1: [0.9224], 2: [0.7664], 3: [0.6794], 4: [0.8218], 5: [0.721], 6: [0.8566], 7: [0.8602], 8: [0.8966], 9: [0.8972]}
TRAIINING epoch@10 ::  acc@0.826  loss@0.518
[[4217   30  218   93   64    4   14   47  229   84]
 [  54 4612    4   47    3    2   14    4   57  203]
 [ 259    1 3832  204  263  151  195   69   25    1]
 [  60    7  184 3397  201  732  222  106   43   48]
 [  84    1  197  204 4109   83  122  189    5    6]
 [   5    1  152  843  133 3605   71  187    1    2]
 [  18   24  195  278  119   53 4283    6   23    1]
 [  53    1   80  191  185  159    3 4301    1   26]
 [ 241   62   36   75    3    0   26    1 4483   73]
 [ 105  197    5   95    5    1    1   42   63 4486]]
TESTING class wise acc@10 :: {0: [0.855], 1: [0.964], 2: [0.767], 3: [0.704], 4: [0.608], 5: [0.737], 6: [0.823], 7: [0.837], 8: [0.774], 9: [0.612]}
TESTING epoch@10 ::  acc@0.768  loss@0.704
Epoch@@11
[[855  16  60  29   4   1   1  16  13   5]
 [  8 964   2  17   0   0   4   0   2   3]
 [ 50   1 767  57  18  49  47  11   0   0]
 [ 15   3  74 704  16 131  37  15   2   3]
 [ 13   2 141  87 608  44  45  59   1   0]
 [  4   0  45 169  11 737   4  30   0   0]
 [  6   7  57  88   6   9 823   1   3   0]
 [  8   2  26  55  16  55   1 837   0   0]
 [ 93  54  11  55   1   2   0   4 774   6]
 [ 37 263   3  64   0   1   1  12   7 612]]
TRAINING class wise acc@11 :: {0: [0.862], 1: [0.9336], 2: [0.7968], 3: [0.7206], 4: [0.8494], 5: [0.7428], 6: [0.8862], 7: [0.8796], 8: [0.916], 9: [0.9174]}
TRAIINING epoch@11 ::  acc@0.850  loss@0.451
[[4310   21  206   80   45    3   14   55  194   72]
 [  28 4668    5   35    4    1   21    1   51  186]
 [ 244    2 3984  197  169  151  162   60   27    4]
 [  60    9  175 3603  162  629  190  109   35   28]
 [  69    6  161  168 4247   90  107  146    1    5]
 [   7    1  147  775  147 3714   57  151    0    1]
 [  14   19  147  222   90   46 4431    7   21    3]
 [  45    0   96  137  154  145    2 4398    1   22]
 [ 194   54   34   66    2    1   14    1 4580   54]
 [  78  163    5   79    3    0    3   36   46 4587]]
TESTING class wise acc@11 :: {0: [0.759], 1: [0.845], 2: [0.665], 3: [0.736], 4: [0.793], 5: [0.733], 6: [0.855], 7: [0.838], 8: [0.823], 9: [0.913]}
TESTING epoch@11 ::  acc@0.796  loss@0.641
Epoch@@12
[[759   7  62  47  22   0  11   8  38  46]
 [  5 845   1  30   9   0  25   1   7  77]
 [ 39   0 665  67  73  73  63  15   5   0]
 [  5   0  39 736  35 118  44  15   1   7]
 [  2   0  37  45 793  27  26  67   3   0]
 [  1   0  24 185  23 733   7  27   0   0]
 [  1   1  22  77  22  19 855   0   2   1]
 [  5   0  12  75  30  36   1 838   0   3]
 [ 45   7  11  64   4   2  12   1 823  31]
 [  5  20   2  45   1   0   2   4   8 913]]
TRAINING class wise acc@12 :: {0: [0.8728], 1: [0.9332], 2: [0.8204], 3: [0.7412], 4: [0.8634], 5: [0.762], 6: [0.8846], 7: [0.8914], 8: [0.9266], 9: [0.914]}
TRAIINING epoch@12 ::  acc@0.861  loss@0.416
[[4364   22  190   78   52    2   10   56  149   77]
 [  36 4666    2   32    2    1   23    2   51  185]
 [ 206    2 4102  162  155  136  158   58   17    4]
 [  41    6  149 3706  135  626  173   95   37   32]
 [  51    3  155  160 4317   71   91  147    5    0]
 [   6    0  135  749  106 3810   39  152    2    1]
 [  21   17  166  220   77   58 4423    1   16    1]
 [  34    0   67  144  151  123    2 4457    2   20]
 [ 145   60   31   67    1    3   12    1 4633   47]
 [  93  170    3   76    5    1    2   21   59 4570]]
TESTING class wise acc@12 :: {0: [0.843], 1: [0.745], 2: [0.696], 3: [0.631], 4: [0.766], 5: [0.73], 6: [0.912], 7: [0.822], 8: [0.853], 9: [0.963]}
TESTING epoch@12 ::  acc@0.796  loss@0.648
Epoch@@13
[[843   6  23  18  11   0   4  11  32  52]
 [ 11 745   1   4   2   1   2   0   8 226]
 [ 74   2 696  31  58  35  85  13   4   2]
 [ 22   0  65 631  31 125  76  22  13  15]
 [ 20   0  43  50 766  29  60  29   2   1]
 [  7   0  56 130  21 730  20  29   1   6]
 [ 10   2  27  23  13   9 912   3   1   0]
 [  9   0  18  32  34  72   1 822   0  12]
 [ 73   9   2  10   0   4   4   1 853  44]
 [  8   8   1   8   2   0   3   1   6 963]]
TRAINING class wise acc@13 :: {0: [0.895], 1: [0.9416], 2: [0.843], 3: [0.7622], 4: [0.8812], 5: [0.7934], 6: [0.9046], 7: [0.9112], 8: [0.9368], 9: [0.93]}
TRAIINING epoch@13 ::  acc@0.880  loss@0.365
[[4475   18  160   58   44    3    4   46  134   58]
 [  33 4708    0   34    4    0   14    0   44  163]
 [ 187    1 4215  139  147  128  119   45   17    2]
 [  52   12  138 3811  130  549  164   84   35   25]
 [  49    4  128  137 4406   67   93  113    2    1]
 [   7    1  119  618   98 3967   56  132    1    1]
 [  18   12  109  207   73   44 4523    1   13    0]
 [  34    0   56  107  127   97    2 4556    0   21]
 [ 147   36   27   50    1    1   16    1 4684   37]
 [  68  156    0   57    7    1    2   18   41 4650]]
TESTING class wise acc@13 :: {0: [0.815], 1: [0.851], 2: [0.84], 3: [0.626], 4: [0.718], 5: [0.519], 6: [0.751], 7: [0.849], 8: [0.917], 9: [0.943]}
TESTING epoch@13 ::  acc@0.783  loss@0.753
Epoch@@14
[[815  10  59   6   3   0   2   2  69  34]
 [  7 851   3   1   0   0   5   0  29 104]
 [ 43   2 840  28  30  11  17  14  13   2]
 [ 30   2 107 626  49  34  56  35  33  28]
 [ 29   0 124  40 718   4   9  69   7   0]
 [ 11   0 130 204  41 519  22  54   9  10]
 [ 11   8 116  41  43   3 751   3  16   8]
 [ 25   0  42  33  24  11   1 849   2  13]
 [ 46   9   2   7   0   0   1   1 917  17]
 [ 16  14   3   4   0   0   1   0  19 943]]
TRAINING class wise acc@14 :: {0: [0.9008], 1: [0.95], 2: [0.854], 3: [0.7908], 4: [0.8934], 5: [0.8078], 6: [0.9156], 7: [0.9152], 8: [0.9396], 9: [0.9328]}
TRAIINING epoch@14 ::  acc@0.890  loss@0.331
[[4504   17  155   47   34    1    3   51  125   63]
 [  30 4750    2   17    5    0   10    1   50  135]
 [ 170    0 4270  117  129  119  131   40   22    2]
 [  30    9  106 3954  113  511  141   77   31   28]
 [  40    2  111  122 4467   65   75  115    1    2]
 [   3    0  114  593   84 4039   33  130    3    1]
 [   8   14  125  163   63   36 4578    1   12    0]
 [  35    0   52   96  107  113    2 4576    0   19]
 [ 141   42   18   49    1    1   15    3 4698   32]
 [  66  136    1   55    4    1    0   25   48 4664]]
TESTING class wise acc@14 :: {0: [0.883], 1: [0.864], 2: [0.744], 3: [0.512], 4: [0.794], 5: [0.792], 6: [0.85], 7: [0.872], 8: [0.895], 9: [0.909]}
TESTING epoch@14 ::  acc@0.811  loss@0.619
Epoch@@15
[[883   6  28  12   6   1   7   2  39  16]
 [ 13 864   1   4   0   0   8   2  17  91]
 [ 90   0 744  21  28  55  36  21   3   2]
 [ 32   2 102 512  42 192  43  52  15   8]
 [ 28   0  74  23 794  16  32  29   4   0]
 [  6   0  45  61  38 792   5  49   2   2]
 [  7   0  68  39  12  14 850   4   5   1]
 [ 17   0  13  22  41  31   0 872   0   4]
 [ 58  10   3  12   0   0   5   3 895  14]
 [ 21  27   2  13   1   1   3   7  16 909]]
TRAINING class wise acc@15 :: {0: [0.911], 1: [0.9566], 2: [0.8722], 3: [0.8158], 4: [0.9112], 5: [0.826], 6: [0.9222], 7: [0.9322], 8: [0.9432], 9: [0.9434]}
TRAIINING epoch@15 ::  acc@0.903  loss@0.292
[[4555   15  142   43   32    3    6   38  116   50]
 [  22 4783    2   24    2    0   13    0   37  117]
 [ 169    0 4361  106   99  106   99   40   18    2]
 [  28    3  103 4079  102  454  115   61   28   27]
 [  36    1   95  100 4556   49   65   96    2    0]
 [   4    0  116  542   76 4130   42   87    1    2]
 [   3   18  103  147   60   41 4611    0   17    0]
 [  31    1   35   83   89   82    1 4661    2   15]
 [ 119   35   29   47    2    1   13    1 4716   37]
 [  49  114    1   57    2    1    0   18   41 4717]]
TESTING class wise acc@15 :: {0: [0.799], 1: [0.93], 2: [0.815], 3: [0.601], 4: [0.773], 5: [0.757], 6: [0.695], 7: [0.878], 8: [0.822], 9: [0.917]}
TESTING epoch@15 ::  acc@0.799  loss@0.697
Epoch@@16
[[799  28  42  29  10   1   1   8  32  50]
 [  3 930   0   2   2   0   2   0   2  59]
 [ 41   3 815  31  41  39  13  14   2   1]
 [ 20   6  81 601  36 185  14  38   4  15]
 [ 21   1  63  42 773  40   5  53   2   0]
 [  3   2  92  78  19 757   1  46   0   2]
 [  8  12  78 111  37  45 695   9   3   2]
 [ 12   1  23  25  23  30   0 878   0   8]
 [ 33  50   7  25   0   0   1   2 822  60]
 [  9  50   2  15   1   0   0   2   4 917]]
TRAINING class wise acc@16 :: {0: [0.9156], 1: [0.9594], 2: [0.886], 3: [0.8318], 4: [0.9178], 5: [0.8458], 6: [0.9304], 7: [0.9392], 8: [0.9466], 9: [0.9494]}
TRAIINING epoch@16 ::  acc@0.912  loss@0.264
[[4578   21  138   29   33    0    7   37  113   44]
 [  17 4797    1   19    5    0   15    1   30  115]
 [ 148    0 4430   84   90  104   91   37   16    0]
 [  22    3   76 4159   88  423  127   50   28   24]
 [  41    2   81   98 4589   48   50   88    0    3]
 [   3    0   85  504   58 4229   25   92    3    1]
 [   9   17  103  135   44   25 4652    0   15    0]
 [  34    0   34   52   97   75    0 4696    0   12]
 [ 119   31   22   49    1    1   10    0 4733   34]
 [  44  109    0   51    2    0    1   16   30 4747]]
TESTING class wise acc@16 :: {0: [0.818], 1: [0.874], 2: [0.625], 3: [0.757], 4: [0.838], 5: [0.569], 6: [0.902], 7: [0.868], 8: [0.862], 9: [0.938]}
TESTING epoch@16 ::  acc@0.805  loss@0.686
Epoch@@17
[[818   8  28  32   5   0  10  15  44  40]
 [  6 874   1  10   1   0   8   3  13  84]
 [ 49   1 625  96  71  24  95  28   9   2]
 [  9   1  24 757  41  36  74  29  11  18]
 [ 11   0  21  59 838   2  31  35   3   0]
 [  5   0  23 295  40 569  21  41   2   4]
 [  4   3   7  47  26   1 902   3   6   1]
 [  5   0   5  52  51   9   2 868   1   7]
 [ 34  16   5  29   0   1   6   4 862  43]
 [  2  30   1  14   1   0   1   6   7 938]]
TRAINING class wise acc@17 :: {0: [0.9306], 1: [0.9646], 2: [0.9014], 3: [0.841], 4: [0.9252], 5: [0.8562], 6: [0.9396], 7: [0.9446], 8: [0.9558], 9: [0.956]}
TRAIINING epoch@17 ::  acc@0.921  loss@0.237
[[4653   12   97   27   30    3    6   29   97   46]
 [  10 4823    0   26    7    0   13    1   22   98]
 [ 124    1 4507   81   97   72   76   31   10    1]
 [  24    5   71 4205   75  427  109   38   24   22]
 [  39    2   91   79 4626   45   48   67    0    3]
 [   1    1   74  475   44 4281   24   99    1    0]
 [   8   12   74  122   53   20 4698    0   12    1]
 [  30    0   29   53   70   83    0 4723    0   12]
 [ 109   21   15   34    1    2    9    0 4779   30]
 [  42   83    0   43    0    0    0   19   33 4780]]
TESTING class wise acc@17 :: {0: [0.688], 1: [0.749], 2: [0.83], 3: [0.719], 4: [0.76], 5: [0.641], 6: [0.879], 7: [0.788], 8: [0.967], 9: [0.837]}
TESTING epoch@17 ::  acc@0.786  loss@0.791
Epoch@@18
[[688   2 106  10   3   0   2   1 185   3]
 [ 27 749   1   4   5   0   6   0 155  53]
 [ 10   0 830  42  18  27  45   4  24   0]
 [  3   0  60 719  38  54  51  20  50   5]
 [ 14   0 103  44 760  11  42  13  12   1]
 [  3   0  55 230  30 641  14  17   9   1]
 [  3   0  54  41   5   3 879   1  14   0]
 [ 25   0  44  43  53  30   2 788   9   6]
 [  8   0  13  10   0   0   1   0 967   1]
 [ 20  10   3  17   0   0   0   0 113 837]]
TRAINING class wise acc@18 :: {0: [0.9388], 1: [0.9672], 2: [0.9104], 3: [0.8592], 4: [0.936], 5: [0.8794], 6: [0.941], 7: [0.9502], 8: [0.9568], 9: [0.9606]}
TRAIINING epoch@18 ::  acc@0.930  loss@0.209
[[4694   13  100   19   18    0    2   23   97   34]
 [  16 4836    0   22    1    0    8    0   30   87]
 [ 113    0 4552   73   75   73   69   34   10    1]
 [  23    2   58 4296   78  387   88   30   21   17]
 [  27    2   77   68 4680   38   42   66    0    0]
 [   1    0   80  375   44 4397   25   77    1    0]
 [   4   10   81  123   42   27 4705    0    8    0]
 [  26    0   36   48   68   63    1 4751    0    7]
 [  94   33   12   39    0    0   10    0 4784   28]
 [  27   88    0   35    1    0    0   15   31 4803]]
TESTING class wise acc@18 :: {0: [0.917], 1: [0.9], 2: [0.796], 3: [0.62], 4: [0.665], 5: [0.719], 6: [0.867], 7: [0.901], 8: [0.851], 9: [0.911]}
TESTING epoch@18 ::  acc@0.815  loss@0.661
Epoch@@19
[[917   5  33   5   4   0   2   3  19  12]
 [ 18 900   4   6   1   0   5   1   7  58]
 [ 72   0 796  30  20  19  41  17   5   0]
 [ 37   1 106 620  29  88  50  43  14  12]
 [ 35   0 137  39 665  23  34  64   3   0]
 [  5   1  83 105  13 719   3  61   3   7]
 [  9   3  63  30   8  11 867   4   5   0]
 [ 20   0  19  17  12  24   0 901   0   7]
 [ 85  14  14   8   0   3   4   1 851  20]
 [ 27  35   3   5   0   0   1   5  13 911]]
TRAINING class wise acc@19 :: {0: [0.9406], 1: [0.967], 2: [0.9238], 3: [0.8788], 4: [0.9434], 5: [0.8936], 6: [0.949], 7: [0.9532], 8: [0.962], 9: [0.9608]}
TRAIINING epoch@19 ::  acc@0.937  loss@0.189
[[4703    9   90   19   24    1    3   32   78   41]
 [  19 4835    0   19    4    0   11    0   25   87]
 [  93    0 4619   52   68   75   60   21   12    0]
 [  15    8   50 4394   61  328   78   28   16   22]
 [  25    2   60   57 4717   40   35   63    1    0]
 [   1    0   68  345   35 4468   20   63    0    0]
 [   1    7   76   98   35   28 4745    1    9    0]
 [  20    0   22   50   56   70    0 4766    0   16]
 [  86   29   15   26    0    1    7    0 4810   26]
 [  31   74    4   37    2    0    0   20   28 4804]]
TESTING class wise acc@19 :: {0: [0.836], 1: [0.903], 2: [0.8], 3: [0.745], 4: [0.851], 5: [0.703], 6: [0.874], 7: [0.846], 8: [0.872], 9: [0.854]}
TESTING epoch@19 ::  acc@0.828  loss@0.612
Epoch@@20
[[836   4  98  16  12   0   1   3  27   3]
 [ 25 903   0   9   1   0   7   0  26  29]
 [ 31   0 800  43  58  21  43   3   1   0]
 [ 22   0  66 745  40  71  29  21   4   2]
 [  8   0  54  48 851   9  13  16   1   0]
 [  5   0  49 187  24 703   5  26   1   0]
 [  3   1  41  41  27   7 874   1   5   0]
 [ 13   0  24  49  45  18   0 846   3   2]
 [ 83   1  13  11   0   0  10   2 872   8]
 [ 46  47   4  21   0   1   1   7  19 854]]
TRAINING class wise acc@20 :: {0: [0.9474], 1: [0.976], 2: [0.9268], 3: [0.8874], 4: [0.9464], 5: [0.9026], 6: [0.9528], 7: [0.9586], 8: [0.9624], 9: [0.9698]}
TRAIINING epoch@20 ::  acc@0.943  loss@0.171
[[4737   11   86   12   20    0    1   24   85   24]
 [  13 4880    1   19    3    0   12    0   19   53]
 [ 102    0 4634   52   57   65   61   17   12    0]
 [  13    5   49 4437   54  291   78   32   19   22]
 [  25    1   56   59 4732   29   42   56    0    0]
 [   1    0   71  311   31 4513   19   54    0    0]
 [   2   17   67   85   36   18 4764    1   10    0]
 [  19    0   31   38   53   56    0 4793    0   10]
 [  80   17   15   30    0    0   15    0 4812   31]
 [  20   53    0   36    2    0    0   14   26 4849]]
TESTING class wise acc@20 :: {0: [0.914], 1: [0.9], 2: [0.752], 3: [0.687], 4: [0.836], 5: [0.75], 6: [0.851], 7: [0.852], 8: [0.905], 9: [0.801]}
TESTING epoch@20 ::  acc@0.825  loss@0.705
Epoch@@21
[[914   6  20  11   8   1   2   1  34   3]
 [ 19 900   0   7   3   0   6   0  37  28]
 [ 75   1 752  33  50  40  28  12   9   0]
 [ 30   3  50 687  47  99  41  27  11   5]
 [ 23   1  52  23 836  13  21  27   4   0]
 [  6   0  35 137  30 750   1  37   4   0]
 [ 13   0  46  48  24  14 851   2   2   0]
 [ 46   0  13  33  34  19   1 852   1   1]
 [ 68   5   4  10   3   0   3   0 905   2]
 [ 53  63   3  21   0   2   3   4  50 801]]
TRAINING class wise acc@21 :: {0: [0.9514], 1: [0.9768], 2: [0.9402], 3: [0.9012], 4: [0.9468], 5: [0.914], 6: [0.9634], 7: [0.964], 8: [0.9686], 9: [0.9712]}
TRAIINING epoch@21 ::  acc@0.950  loss@0.152
[[4757   12   68   18   23    0    3    8   81   30]
 [  12 4884    0    8    3    0   12    0   18   63]
 [  72    1 4701   38   54   54   46   24    9    1]
 [  19    4   35 4506   41  273   64   28   17   13]
 [  21    0   60   69 4734   23   32   60    1    0]
 [   0    0   61  262   32 4570   17   57    1    0]
 [   2    3   59   63   32   17 4817    0    7    0]
 [  18    0   17   29   59   52    0 4820    0    5]
 [  79   16   16   24    0    0    7    0 4843   15]
 [  26   61    1   26    1    0    0    8   21 4856]]
TESTING class wise acc@21 :: {0: [0.907], 1: [0.945], 2: [0.772], 3: [0.629], 4: [0.77], 5: [0.739], 6: [0.868], 7: [0.863], 8: [0.911], 9: [0.776]}
TESTING epoch@21 ::  acc@0.818  loss@0.796
Epoch@@22
[[907  10  29   3   6   0   1   2  36   6]
 [ 24 945   0   1   2   0   2   0  12  14]
 [ 76   2 772  26  32  24  45   6  17   0]
 [ 41  11  79 629  28 104  63  12  25   8]
 [ 21   2  61  34 770  23  37  44   8   0]
 [ 12   2  60 109  23 739  24  25   5   1]
 [ 13  15  48  19  17  13 868   2   5   0]
 [ 30   1  37  21  21  21   1 863   3   2]
 [ 46  25   5   7   0   1   0   2 911   3]
 [ 48 130   3   6   2   1   1   2  31 776]]
TRAINING class wise acc@22 :: {0: [0.9504], 1: [0.9794], 2: [0.946], 3: [0.909], 4: [0.957], 5: [0.927], 6: [0.9658], 7: [0.9688], 8: [0.9686], 9: [0.97]}
TRAIINING epoch@22 ::  acc@0.954  loss@0.141
[[4752   13   74   21   20    0    2   26   64   28]
 [  14 4897    0    7    5    0    5    0   22   50]
 [  68    0 4730   32   50   48   45   19    8    0]
 [  16    3   31 4545   49  230   67   26   19   14]
 [  17    1   48   59 4785   23   25   41    0    1]
 [   2    0   50  244   23 4635   15   31    0    0]
 [   5   11   44   69   26   12 4829    0    4    0]
 [  13    0   21   19   54   35    0 4844    1   13]
 [  69   22   11   28    0    0   10    1 4843   16]
 [  28   56    0   32    2    0    0   13   19 4850]]
TESTING class wise acc@22 :: {0: [0.858], 1: [0.896], 2: [0.729], 3: [0.696], 4: [0.848], 5: [0.788], 6: [0.809], 7: [0.886], 8: [0.876], 9: [0.89]}
TESTING epoch@22 ::  acc@0.828  loss@0.678
Epoch@@23
[[858   5  53  11  11   2   3   9  36  12]
 [ 20 896   2   7   7   0   5   0  18  45]
 [ 48   0 729  42  66  63  27  21   4   0]
 [ 14   1  56 696  41 136  23  25   4   4]
 [  8   0  40  43 848  17  12  30   2   0]
 [  4   0  22 115  27 788   3  39   0   2]
 [  8   1  41  62  31  39 809   5   3   1]
 [ 19   0   9  28  27  28   0 886   0   3]
 [ 62   2   6  31   1   6   2   1 876  13]
 [ 18  43   2  20   2   3   2   7  13 890]]
TRAINING class wise acc@23 :: {0: [0.9614], 1: [0.979], 2: [0.9514], 3: [0.92], 4: [0.9602], 5: [0.9374], 6: [0.9694], 7: [0.9714], 8: [0.9762], 9: [0.973]}
TRAIINING epoch@23 ::  acc@0.960  loss@0.124
[[4807    9   64    9   16    0    4   17   49   25]
 [  12 4895    0   13    2    1    9    0   16   52]
 [  63    0 4757   28   47   44   36   19    6    0]
 [  16    2   24 4600   39  212   58   19   12   18]
 [  19    2   39   46 4801   25   21   47    0    0]
 [   0    0   40  197   25 4687   14   36    1    0]
 [   4    9   33   61   21   15 4847    0    9    1]
 [  12    0   18   17   52   34    0 4857    0   10]
 [  51   12    7   27    0    1    7    0 4881   14]
 [  27   57    0   23    2    0    0   10   16 4865]]
TESTING class wise acc@23 :: {0: [0.9], 1: [0.935], 2: [0.733], 3: [0.573], 4: [0.897], 5: [0.717], 6: [0.816], 7: [0.872], 8: [0.885], 9: [0.927]}
TESTING epoch@23 ::  acc@0.825  loss@0.795
Epoch@@24
[[900  12  22   7  12   0   1   4  19  23]
 [  9 935   0   0   2   0   1   0   7  46]
 [ 81   1 733  24  85  22  34  11   6   3]
 [ 38   6  82 573  91 113  37  29  12  19]
 [ 15   1  42  10 897   9   6  17   2   1]
 [ 10   1  61 100  57 717   9  41   0   4]
 [ 12  13  47  34  55   9 816   2  12   0]
 [ 25   0  12  14  53   8   1 872   1  14]
 [ 65  11   1  13   4   0   2   1 885  18]
 [ 14  40   2   4   0   0   0   1  12 927]]
TRAINING class wise acc@24 :: {0: [0.9628], 1: [0.9802], 2: [0.9548], 3: [0.918], 4: [0.964], 5: [0.933], 6: [0.968], 7: [0.9694], 8: [0.9756], 9: [0.9748]}
TRAIINING epoch@24 ::  acc@0.960  loss@0.125
[[4814    7   56   11   15    0    2   19   54   22]
 [   8 4901    0   15    3    0    5    0   18   50]
 [  52    0 4774   27   35   42   45   16    9    0]
 [   9    6   23 4590   41  218   44   26   21   22]
 [  16    2   39   36 4820   19   25   41    0    2]
 [   1    0   41  209   28 4665   18   38    0    0]
 [   4    5   52   49   28   11 4840    0   11    0]
 [  24    1   17   24   42   37    0 4847    0    8]
 [  41   18   13   23    0    0    8    1 4878   18]
 [  21   46    1   26    0    0    0   14   18 4874]]
TESTING class wise acc@24 :: {0: [0.897], 1: [0.902], 2: [0.763], 3: [0.533], 4: [0.835], 5: [0.836], 6: [0.913], 7: [0.797], 8: [0.882], 9: [0.882]}
TESTING epoch@24 ::  acc@0.824  loss@0.774
Epoch@@25
[[897   8  37   7   6   2   5   3  26   9]
 [ 20 902   0   4   2   0   7   0  21  44]
 [ 57   0 763  14  49  40  60  12   5   0]
 [ 19   2  73 533  62 209  80  11   6   5]
 [ 17   2  45  18 835  23  46  11   3   0]
 [  9   1  40  50  31 836  19  12   0   2]
 [  5   2  37  12  17   9 913   2   3   0]
 [ 19   0  22  25  61  67   3 797   3   3]
 [ 84   4   5  12   1   2   4   1 882   5]
 [ 23  55   1  17   1   0   1   2  18 882]]
TRAINING class wise acc@25 :: {0: [0.9642], 1: [0.9808], 2: [0.9552], 3: [0.9346], 4: [0.9582], 5: [0.9468], 6: [0.9662], 7: [0.9718], 8: [0.9764], 9: [0.976]}
TRAIINING epoch@25 ::  acc@0.963  loss@0.115
[[4821    8   56    6   20    0    5   16   49   19]
 [   9 4904    0    6    3    0    7    0   17   54]
 [  56    0 4776   22   45   42   39   14    6    0]
 [   7    5   28 4673   40  164   42   17   14   10]
 [  19    5   48   37 4791   23   28   49    0    0]
 [   0    1   32  167   20 4734   15   30    1    0]
 [   1    7   44   54   36   17 4831    0   10    0]
 [  16    0   13   23   45   33    0 4859    0   11]
 [  48   11   11   16    0    0   11    0 4882   21]
 [  18   48    0   25    0    0    0   11   18 4880]]
TESTING class wise acc@25 :: {0: [0.858], 1: [0.845], 2: [0.806], 3: [0.65], 4: [0.786], 5: [0.606], 6: [0.846], 7: [0.868], 8: [0.881], 9: [0.952]}
TESTING epoch@25 ::  acc@0.810  loss@0.962
Epoch@@26
[[858   4  53   4   7   1   2   4  45  22]
 [ 18 845   3   0   2   0   8   0  10 114]
 [ 41   2 806  40  42  12  37   9  11   0]
 [ 32   2 106 650  40  56  43  29  11  31]
 [  6   1  94  38 786   9  26  37   2   1]
 [  8   0 107 184  36 606  18  29   4   8]
 [  9   0  65  40  24   2 846   1  10   3]
 [ 21   0  31  20  30  15   1 868   2  12]
 [ 53   7   5   6   0   0   3   1 881  44]
 [ 11  20   1   6   1   0   1   2   6 952]]
TRAINING class wise acc@26 :: {0: [0.9664], 1: [0.9838], 2: [0.9622], 3: [0.9354], 4: [0.963], 5: [0.942], 6: [0.9708], 7: [0.9758], 8: [0.978], 9: [0.9786]}
TRAIINING epoch@26 ::  acc@0.966  loss@0.107
[[4832    6   64    4   22    0    1    8   49   14]
 [  12 4919    0   10    3    0    3    0   18   35]
 [  55    0 4811   19   28   41   34    5    7    0]
 [  10    4   17 4677   35  174   40   21    9   13]
 [  15    0   30   40 4815   35   22   42    0    1]
 [   0    0   40  172   29 4710   15   34    0    0]
 [   3    6   40   51   27   13 4854    0    6    0]
 [  17    0   11   24   39   26    0 4879    0    4]
 [  35   15   12   15    0    0    9    0 4890   24]
 [  26   38    0   14    0    0    1   10   18 4893]]
TESTING class wise acc@26 :: {0: [0.853], 1: [0.846], 2: [0.642], 3: [0.712], 4: [0.729], 5: [0.746], 6: [0.909], 7: [0.901], 8: [0.945], 9: [0.903]}
TESTING epoch@26 ::  acc@0.819  loss@0.876
Epoch@@27
[[853   5  12  19   4   0   7   7  66  27]
 [ 13 846   0   7   0   0   3   0  27 104]
 [ 84   1 642  80  37  29  92  13  19   3]
 [ 11   4  30 712  10 113  50  29  24  17]
 [ 15   1  29  88 729  26  54  52   5   1]
 [  3   0  27 147  12 746  15  45   2   3]
 [  5   3  10  41   6  14 909   2   8   2]
 [ 19   0   4  35  16  15   1 901   3   6]
 [ 30   6   0  11   0   2   2   1 945   3]
 [ 10  24   3   8   0   0   0   4  48 903]]
TRAINING class wise acc@27 :: {0: [0.9666], 1: [0.9812], 2: [0.9624], 3: [0.9418], 4: [0.9704], 5: [0.956], 6: [0.9762], 7: [0.9756], 8: [0.979], 9: [0.9798]}
TRAIINING epoch@27 ::  acc@0.969  loss@0.097
[[4833    7   56   20    8    0    2   11   52   11]
 [  10 4906    0    7    3    0    9    0    7   58]
 [  44    0 4812   20   34   36   34   15    5    0]
 [  10    5   27 4709   34  127   42   21   13   12]
 [  10    2   37   37 4852   17   13   32    0    0]
 [   0    0   29  135   18 4780    6   31    1    0]
 [   2    6   34   49   14    6 4881    0    8    0]
 [  12    0   14   16   32   42    0 4878    0    6]
 [  48    9    7   21    0    0    8    0 4895   12]
 [  14   47    0   17    0    0    0    3   20 4899]]
TESTING class wise acc@27 :: {0: [0.851], 1: [0.892], 2: [0.77], 3: [0.708], 4: [0.836], 5: [0.73], 6: [0.841], 7: [0.851], 8: [0.934], 9: [0.924]}
TESTING epoch@27 ::  acc@0.834  loss@0.738
Epoch@@28
[[851   5  26  20   9   1   2   9  50  27]
 [ 12 892   0   9   2   0   2   0  16  67]
 [ 56   3 770  43  38  30  39   7  13   1]
 [ 15   3  44 708  39 106  26  32  15  12]
 [ 12   1  59  41 836  18  13  14   6   0]
 [  6   0  46 136  31 730   5  41   2   3]
 [  3   4  32  60  29  17 841   1  12   1]
 [ 13   0  22  38  52  17   2 851   1   4]
 [ 34   3   0   9   1   2   1   1 934  15]
 [ 16  27   3  10   0   0   0   5  15 924]]
TRAINING class wise acc@28 :: {0: [0.9732], 1: [0.9822], 2: [0.967], 3: [0.9484], 4: [0.9686], 5: [0.9566], 6: [0.9724], 7: [0.9776], 8: [0.9824], 9: [0.9804]}
TRAIINING epoch@28 ::  acc@0.971  loss@0.091
[[4866    8   34   13   13    0    2   14   31   19]
 [  14 4911    0   11    5    0    7    0   17   35]
 [  47    0 4835   16   15   40   32   10    5    0]
 [   7    3   17 4742   36  112   32   25   18    8]
 [  12    5   25   40 4843   18   25   31    0    1]
 [   0    0   31  129   21 4783   11   25    0    0]
 [   3    6   33   46   30   13 4862    0    6    1]
 [  11    0    9   20   38   26    0 4888    0    8]
 [  29   20    8   14    0    0    7    0 4912   10]
 [  21   35    0   18    1    0    0   12   11 4902]]
TESTING class wise acc@28 :: {0: [0.935], 1: [0.891], 2: [0.733], 3: [0.7], 4: [0.793], 5: [0.774], 6: [0.812], 7: [0.878], 8: [0.763], 9: [0.93]}
TESTING epoch@28 ::  acc@0.821  loss@0.882
Epoch@@29
[[935   9   9   6   2   0   1  12  12  14]
 [ 18 891   0   6   3   0   3   0   4  75]
 [ 99   2 733  34  46  41  27  15   1   2]
 [ 52   5  36 700  30 105  26  24   5  17]
 [ 36   0  38  38 793  26  16  50   3   0]
 [ 14   1  22 137  18 774   4  30   0   0]
 [ 24   8  58  53  23  17 812   2   3   0]
 [ 18   0   8  26  15  53   0 878   0   2]
 [147  16   4  16   1   1   0   4 763  48]
 [ 21  29   1   5   1   1   0   9   3 930]]
TRAINING class wise acc@29 :: {0: [0.9702], 1: [0.9872], 2: [0.9676], 3: [0.953], 4: [0.9742], 5: [0.9614], 6: [0.9782], 7: [0.9794], 8: [0.9804], 9: [0.981]}
TRAIINING epoch@29 ::  acc@0.973  loss@0.084
[[4851    6   46    5   15    0    2   15   48   12]
 [   4 4936    0    6    2    0    3    0    8   41]
 [  38    0 4838   16   32   33   20   15    6    2]
 [   4    3   18 4765   32   97   39   22    9   11]
 [  16    0   29   26 4871   22   14   22    0    0]
 [   0    0   30  115   12 4807   10   26    0    0]
 [   3    3   28   45   14    5 4891    1   10    0]
 [  10    0   13   16   32   24    0 4897    1    7]
 [  43    7    8   13    0    0    8    0 4902   19]
 [  11   38    0   21    0    0    0    8   17 4905]]
TESTING class wise acc@29 :: {0: [0.904], 1: [0.93], 2: [0.832], 3: [0.672], 4: [0.829], 5: [0.7], 6: [0.827], 7: [0.868], 8: [0.892], 9: [0.856]}
TESTING epoch@29 ::  acc@0.831  loss@0.752
Epoch@@30
[[904   5  48   4   5   0   5   4  20   5]
 [ 19 930   3   2   3   0   3   0  11  29]
 [ 49   1 832  25  43  22  20   6   2   0]
 [ 19   3 103 672  56  85  30  17  13   2]
 [ 12   0  76  26 829  13  12  30   2   0]
 [  4   2 102 123  34 700   4  30   1   0]
 [ 13   4  74  39  26   7 827   1   9   0]
 [ 22   0  39  21  29  17   0 868   1   3]
 [ 75   7   6   6   2   0   5   1 892   6]
 [ 34  66   2  10   2   2   1   5  22 856]]
TRAINING class wise acc@30 :: {0: [0.9752], 1: [0.9872], 2: [0.9708], 3: [0.9528], 4: [0.9816], 5: [0.9626], 6: [0.9774], 7: [0.9852], 8: [0.9848], 9: [0.986]}
TRAIINING epoch@30 ::  acc@0.976  loss@0.075
[[4876    5   39   13   11    0    0   11   29   16]
 [   7 4936    0   10    1    0   12    0   11   23]
 [  40    0 4854   10   20   28   30    9    9    0]
 [   6    2   18 4764   21  124   36   10   11    8]
 [   9    1   19   19 4908   10   13   21    0    0]
 [   0    0   33  121    8 4813    5   20    0    0]
 [   3   13   36   38   10   11 4887    0    2    0]
 [  15    0    6    9   18   20    0 4926    0    6]
 [  34    9    7   12    0    0    3    0 4924   11]
 [  12   27    0   11    0    1    0    8   11 4930]]
TESTING class wise acc@30 :: {0: [0.905], 1: [0.904], 2: [0.814], 3: [0.624], 4: [0.826], 5: [0.664], 6: [0.868], 7: [0.845], 8: [0.912], 9: [0.905]}
TESTING epoch@30 ::  acc@0.827  loss@0.839
Epoch@@31
[[905   8  28   6   2   0   2   5  34  10]
 [ 22 904   0   1   2   0   3   0  15  53]
 [ 72   2 814  18  30  16  29  11   6   2]
 [ 30   1 129 624  57  68  48  30  10   3]
 [ 15   0  89  21 826  12  18  17   2   0]
 [ 13   1 108 133  32 664  12  35   1   1]
 [  9   2  69  16  27   5 868   1   3   0]
 [ 24   0  30  34  47  12   1 845   2   5]
 [ 43  10   9   7   2   1   0   1 912  15]
 [ 25  39   3  10   3   0   2   4   9 905]]
TRAINING class wise acc@31 :: {0: [0.9712], 1: [0.9856], 2: [0.9708], 3: [0.9582], 4: [0.9752], 5: [0.964], 6: [0.9788], 7: [0.9826], 8: [0.9822], 9: [0.9856]}
TRAIINING epoch@31 ::  acc@0.975  loss@0.077
[[4856    5   48    7   13    0    2   10   46   13]
 [   8 4928    0    9    4    0    5    0   10   36]
 [  50    0 4854   12   23   28   21    9    3    0]
 [  11    3   13 4791   16  112   30    8   10    6]
 [  11    1   28   19 4876   14   19   32    0    0]
 [   1    0   28  110   12 4820    7   21    0    1]
 [   2    4   24   42   19    8 4894    0    7    0]
 [  13    0    6    9   28   25    0 4913    0    6]
 [  44   13    4   10    0    0    6    0 4911   12]
 [  14   29    0   12    0    0    0    4   13 4928]]
TESTING class wise acc@31 :: {0: [0.824], 1: [0.951], 2: [0.831], 3: [0.758], 4: [0.75], 5: [0.692], 6: [0.877], 7: [0.826], 8: [0.911], 9: [0.848]}
TESTING epoch@31 ::  acc@0.827  loss@0.845
Epoch@@32
[[824  17  58  26   4   0   4   9  43  15]
 [  6 951   1   3   0   0   3   1  15  20]
 [ 29   1 831  49  22  19  35   5   9   0]
 [  7   3  62 758  18  70  53  15  13   1]
 [  6   0 102  57 750  17  51  11   6   0]
 [  2   2  60 185  24 692  10  21   3   1]
 [  4   5  46  51   3   0 877   0  13   1]
 [ 14   0  18  64  45  26   3 826   2   2]
 [ 35  13   9  16   1   0   1   2 911  12]
 [ 15  78   2  26   0   0   2   8  21 848]]
TRAINING class wise acc@32 :: {0: [0.9742], 1: [0.986], 2: [0.9728], 3: [0.9556], 4: [0.9722], 5: [0.9652], 6: [0.9802], 7: [0.9816], 8: [0.9836], 9: [0.9798]}
TRAIINING epoch@32 ::  acc@0.975  loss@0.080
[[4871    5   43   14   10    0    3    7   22   25]
 [   4 4930    0    4    3    0    4    0   16   39]
 [  40    0 4864   10   31   28   15    7    5    0]
 [   5    8   10 4778   30   93   40   13   12   11]
 [  11    1   29   37 4861   14   21   25    1    0]
 [   0    0   29  100    9 4826    8   28    0    0]
 [   1    5   26   38   17    8 4901    0    4    0]
 [   6    0   11   17   26   26    0 4908    0    6]
 [  26   14    5   18    0    0    6    0 4918   13]
 [  17   38    0   21    0    1    0   11   13 4899]]
TESTING class wise acc@32 :: {0: [0.868], 1: [0.925], 2: [0.811], 3: [0.591], 4: [0.82], 5: [0.791], 6: [0.923], 7: [0.861], 8: [0.906], 9: [0.828]}
TESTING epoch@32 ::  acc@0.832  loss@0.846
Epoch@@33
[[868   7  48   8   6   0   6   7  38  12]
 [  6 925   1   2   3   0  15   0  19  29]
 [ 36   1 811  22  41  32  47   8   2   0]
 [ 12   1  88 591  47 142  83  29   6   1]
 [ 15   1  57  17 820  23  45  19   3   0]
 [  2   0  50  86  31 791  18  21   1   0]
 [  6   0  33  15   5  15 923   3   0   0]
 [ 11   0  26  21  40  37   2 861   0   2]
 [ 40   6  11  17   1   2   8   1 906   8]
 [ 20  81   6  20   3   2   8  11  21 828]]
TRAINING class wise acc@33 :: {0: [0.9794], 1: [0.9914], 2: [0.9696], 3: [0.962], 4: [0.9782], 5: [0.9704], 6: [0.9824], 7: [0.9868], 8: [0.9846], 9: [0.9884]}
TRAIINING epoch@33 ::  acc@0.979  loss@0.064
[[4897    3   37    7    9    0    2    6   26   13]
 [   2 4957    0    8    0    0    2    0   11   20]
 [  33    0 4848   13   32   31   21   16    6    0]
 [   5    3   17 4810   22   87   30   12    7    7]
 [  11    1   28   21 4891    9   16   23    0    0]
 [   0    0   30   84   12 4852    9   13    0    0]
 [   0    3   26   28   16    8 4912    0    7    0]
 [   5    0    5   10   24   19    0 4934    0    3]
 [  22   13    8   12    0    0    7    0 4923   15]
 [  13   16    0   14    0    0    0    6    9 4942]]
TESTING class wise acc@33 :: {0: [0.844], 1: [0.932], 2: [0.736], 3: [0.607], 4: [0.761], 5: [0.764], 6: [0.948], 7: [0.868], 8: [0.935], 9: [0.905]}
TESTING epoch@33 ::  acc@0.830  loss@0.936
Epoch@@34
[[844  15  38   9   5   1   2   2  62  22]
 [ 10 932   0   1   0   0   4   1  14  38]
 [ 41   0 736  25  29  32 103  13  18   3]
 [ 21  10  42 607  41 106 115  23  23  12]
 [ 17   4  54  14 761  25  76  44   5   0]
 [  5   3  34 100  24 764  35  28   5   2]
 [  4   5  14   9   5   7 948   1   6   1]
 [ 18   1  12  25  21  37   5 868   0  13]
 [ 30   6   2   7   0   1   7   1 935  11]
 [ 15  52   1   7   1   0   2   0  17 905]]
TRAINING class wise acc@34 :: {0: [0.9796], 1: [0.9846], 2: [0.9748], 3: [0.9638], 4: [0.977], 5: [0.968], 6: [0.9826], 7: [0.9846], 8: [0.9832], 9: [0.985]}
TRAIINING epoch@34 ::  acc@0.978  loss@0.067
[[4898   10   19    3    9    0    0    7   37   17]
 [  12 4923    0    7    4    0    6    0   13   35]
 [  18    1 4874   15   24   28   25   10    5    0]
 [   4    4   13 4819   19   86   30   11    8    6]
 [   6    1   25   32 4885   15   16   20    0    0]
 [   0    0   30   90   14 4840    5   20    0    1]
 [   2    4   30   30   11    7 4913    0    3    0]
 [   9    0   12   10   23   18    0 4923    0    5]
 [  38   12    9   13    0    0    4    0 4916    8]
 [  19   27    0   13    0    0    0    9    7 4925]]
TESTING class wise acc@34 :: {0: [0.87], 1: [0.937], 2: [0.781], 3: [0.71], 4: [0.83], 5: [0.749], 6: [0.899], 7: [0.86], 8: [0.866], 9: [0.825]}
TESTING epoch@34 ::  acc@0.833  loss@0.821
Epoch@@35
[[870  13  60  13   9   1   7   4  19   4]
 [ 12 937   0   1   2   0   8   1  12  27]
 [ 32   1 781  29  47  32  63   8   6   1]
 [ 18   4  62 710  52  82  44  20   6   2]
 [ 19   1  51  36 830  18  28  16   1   0]
 [  2   0  46 134  35 749  11  23   0   0]
 [  5   5  24  31  14  17 899   3   2   0]
 [ 11   0  25  26  39  34   2 860   0   3]
 [ 83  16  10  14   1   1   2   1 866   6]
 [ 39  76   4  15   2   2   2  13  22 825]]
TRAINING class wise acc@35 :: {0: [0.9798], 1: [0.9882], 2: [0.9736], 3: [0.9636], 4: [0.9766], 5: [0.9678], 6: [0.98], 7: [0.9814], 8: [0.9848], 9: [0.9854]}
TRAIINING epoch@35 ::  acc@0.978  loss@0.069
[[4899    4   35    2    6    0    1    9   30   14]
 [   3 4941    0   10    1    0    5    1   14   25]
 [  30    0 4868   12   22   30   28    6    4    0]
 [   5    2   10 4818   20   78   31   21    9    6]
 [   6    1   26   25 4883   18   16   25    0    0]
 [   0    0   29   80   17 4839    8   27    0    0]
 [   1    7   27   36   19    9 4900    0    1    0]
 [   9    0    8   15   25   29    0 4907    0    7]
 [  31   11    3   17    0    0    5    0 4924    9]
 [  15   26    0   14    1    0    0    4   13 4927]]
TESTING class wise acc@35 :: {0: [0.869], 1: [0.924], 2: [0.836], 3: [0.747], 4: [0.761], 5: [0.761], 6: [0.83], 7: [0.759], 8: [0.915], 9: [0.823]}
TESTING epoch@35 ::  acc@0.822  loss@0.848
Epoch@@36
[[869   6  50  15   2   2   1   0  50   5]
 [ 19 924   2   7   1   1   2   0  27  17]
 [ 41   1 836  42  23  34  13   3   7   0]
 [ 16   2  74 747  25  97  22   8   7   2]
 [ 25   0  81  68 761  22  31   8   4   0]
 [  3   1  56 149  21 761   1   7   1   0]
 [  7   0  92  38   8  16 830   0   9   0]
 [ 24   0  23  67  62  62   1 759   0   2]
 [ 48   4  14  11   0   3   3   1 915   1]
 [ 36  74   4  19   1   1   2   7  33 823]]
TRAINING class wise acc@36 :: {0: [0.9816], 1: [0.9884], 2: [0.977], 3: [0.9668], 4: [0.9776], 5: [0.9722], 6: [0.9864], 7: [0.9854], 8: [0.9862], 9: [0.9862]}
TRAIINING epoch@36 ::  acc@0.981  loss@0.059
[[4908    5   22    5    7    0    2    9   24   18]
 [   8 4942    0    6    2    0    5    0    9   28]
 [  28    0 4885    8   27   18   24    6    4    0]
 [   7    5   11 4834   21   76   16   12    8   10]
 [  11    0   24   25 4888   13   14   25    0    0]
 [   0    0   24   82   11 4861    9   13    0    0]
 [   1    3   11   29   14    7 4932    0    3    0]
 [   6    0    3   15   25   19    0 4927    0    5]
 [  31    9    8   11    0    0    3    0 4931    7]
 [  15   28    0   12    1    0    0    3   10 4931]]
TESTING class wise acc@36 :: {0: [0.846], 1: [0.933], 2: [0.864], 3: [0.707], 4: [0.653], 5: [0.661], 6: [0.86], 7: [0.824], 8: [0.939], 9: [0.804]}
TESTING epoch@36 ::  acc@0.809  loss@0.992
Epoch@@37
[[846   6  48  16   3   0   2   1  72   6]
 [ 16 933   3   4   0   0   9   0  18  17]
 [ 44   1 864  29  12  16  18   7   9   0]
 [ 24   2 119 707  15  53  50  20  10   0]
 [ 26   2 183  57 653  12  35  28   4   0]
 [  8   0 114 160  11 661  16  26   4   0]
 [  8   1  90  23   5   6 860   1   6   0]
 [ 42   0  48  49  20  13   1 824   2   1]
 [ 30   8   4   9   0   1   4   0 939   5]
 [ 39  79   7  22   0   1   5   6  37 804]]
TRAINING class wise acc@37 :: {0: [0.9782], 1: [0.989], 2: [0.9724], 3: [0.9658], 4: [0.98], 5: [0.9686], 6: [0.9844], 7: [0.9828], 8: [0.9858], 9: [0.9882]}
TRAIINING epoch@37 ::  acc@0.980  loss@0.066
[[4891    2   38    6    7    0    2   12   32   10]
 [   5 4945    0   10    0    0    2    0    9   29]
 [  38    0 4862   14   21   27   22   11    5    0]
 [   6    2   18 4829   12   78   25    9   10   11]
 [  10    1   21   20 4900   13   20   15    0    0]
 [   0    0   22   98   10 4843    6   20    1    0]
 [   1    4   24   21   15    8 4922    0    5    0]
 [  12    0   12   11   25   21    0 4914    0    5]
 [  26    8    6   18    0    0    5    0 4929    8]
 [  12   26    0   10    0    0    0    5    6 4941]]
TESTING class wise acc@37 :: {0: [0.898], 1: [0.9], 2: [0.754], 3: [0.694], 4: [0.87], 5: [0.715], 6: [0.899], 7: [0.855], 8: [0.948], 9: [0.749]}
TESTING epoch@37 ::  acc@0.828  loss@0.995
Epoch@@38
[[898   4  27   6   6   0   4   0  53   2]
 [ 21 900   0   1   1   0   8   0  57  12]
 [ 59   0 754  31  63  17  45  11  20   0]
 [ 26   2  58 694  51  67  63  11  26   2]
 [ 15   0  32  19 870   6  31  19   8   0]
 [  7   1  37 124  44 715  21  35  16   0]
 [  6   3  38  20  17   7 899   0  10   0]
 [ 26   0  23  30  45  17   1 855   2   1]
 [ 36   2   3   7   0   0   3   1 948   0]
 [ 53  80   3  10   2   1   4   5  93 749]]
TRAINING class wise acc@38 :: {0: [0.9806], 1: [0.9892], 2: [0.9762], 3: [0.9702], 4: [0.979], 5: [0.9764], 6: [0.982], 7: [0.9844], 8: [0.9868], 9: [0.9858]}
TRAIINING epoch@38 ::  acc@0.981  loss@0.062
[[4903    6   33    6    8    0    3    3   24   14]
 [   8 4946    0    4    1    0    4    0    9   28]
 [  37    0 4881   10   21   20   22    6    3    0]
 [   8    1   15 4851   22   54   24    7   10    8]
 [   7    0   20   23 4895   13   13   28    0    1]
 [   0    0   13   64   10 4882    8   23    0    0]
 [   2    5   31   18   18    8 4910    0    7    1]
 [   5    0    6   13   26   22    0 4922    0    6]
 [  20   11    2   13    0    0    6    0 4934   14]
 [   9   21    0   19    0    0    0    9   13 4929]]
TESTING class wise acc@38 :: {0: [0.887], 1: [0.938], 2: [0.736], 3: [0.771], 4: [0.754], 5: [0.764], 6: [0.896], 7: [0.816], 8: [0.893], 9: [0.909]}
TESTING epoch@38 ::  acc@0.836  loss@0.822
Epoch@@39
[[887  14  17  16   1   0   2   0  37  26]
 [  6 938   0   2   0   0   2   0   9  43]
 [ 71   4 736  55  32  37  44   7  11   3]
 [ 17   4  30 771  18  85  37  12  10  16]
 [ 26   4  36  77 754  25  34  35   5   4]
 [  7   2  23 169  13 764   7  10   1   4]
 [  5   6  23  39   5  17 896   2   6   1]
 [ 30   0  15  54  19  39   1 816   2  24]
 [ 47  15   1  14   0   0   2   1 893  27]
 [  9  62   1   7   0   1   0   0  11 909]]
TRAINING class wise acc@39 :: {0: [0.9836], 1: [0.9928], 2: [0.98], 3: [0.9742], 4: [0.9876], 5: [0.9764], 6: [0.985], 7: [0.9888], 8: [0.989], 9: [0.9894]}
TRAIINING epoch@39 ::  acc@0.985  loss@0.048
[[4918    5   17    5    6    0    0    9   33    7]
 [   4 4964    0    1    2    0    4    0    6   19]
 [  18    0 4900    9   17   22   23   10    1    0]
 [   3    0   10 4871   10   64   19    8    7    8]
 [   6    1   14    9 4938    7   14   11    0    0]
 [   0    0   20   69    9 4882    7   13    0    0]
 [   0    4   24   23   14    7 4925    0    3    0]
 [   7    0    8    9   13   14    0 4944    0    5]
 [  26    4    3    8    0    0    5    0 4945    9]
 [  12   16    0    8    0    0    0    6   11 4947]]
TESTING class wise acc@39 :: {0: [0.878], 1: [0.9], 2: [0.786], 3: [0.655], 4: [0.823], 5: [0.793], 6: [0.848], 7: [0.907], 8: [0.901], 9: [0.886]}
TESTING epoch@39 ::  acc@0.838  loss@0.810
Epoch@@40
[[878   7  39  11  10   2   2  12  31   8]
 [ 12 900   1  15   2   1   2   3  14  50]
 [ 48   1 786  28  50  33  35  14   5   0]
 [  7   2  62 655  52 154  27  32   6   3]
 [ 10   0  52  21 823  32  11  49   2   0]
 [  2   0  46 100  29 793   6  23   1   0]
 [  4   4  44  35  32  25 848   4   4   0]
 [ 12   0  12  12  17  38   0 907   0   2]
 [ 51   7   7  16   2   1   1   1 901  13]
 [ 25  36   3  19   2   2   1  12  14 886]]
TRAINING class wise acc@40 :: {0: [0.9804], 1: [0.9908], 2: [0.9768], 3: [0.9728], 4: [0.984], 5: [0.9752], 6: [0.9856], 7: [0.9884], 8: [0.9894], 9: [0.99]}
TRAIINING epoch@40 ::  acc@0.983  loss@0.054
[[4902    3   43    9    2    0    2    8   20   11]
 [   5 4954    0    7    1    0    5    0    9   19]
 [  30    0 4884    7   18   24   23    8    6    0]
 [   6    2   14 4864    8   68   21    4    5    8]
 [   8    0   21   16 4920   13    6   16    0    0]
 [   0    0   20   71   10 4876    8   15    0    0]
 [   1    6   24   22   10    5 4928    0    4    0]
 [   6    0   11    7   16   14    0 4942    0    4]
 [  16    8   10    9    0    0    3    0 4947    7]
 [  11   19    0   10    0    0    0    4    6 4950]]
TESTING class wise acc@40 :: {0: [0.76], 1: [0.909], 2: [0.763], 3: [0.797], 4: [0.81], 5: [0.619], 6: [0.81], 7: [0.879], 8: [0.951], 9: [0.939]}
TESTING epoch@40 ::  acc@0.824  loss@0.960
Epoch@@41
[[760  16  30  27   6   0   1   3 119  38]
 [  3 909   0   3   0   0   2   0  34  49]
 [ 43   2 763  58  43  18  24  11  35   3]
 [ 10   5  32 797  29  39  17  21  29  21]
 [  5   4  40  64 810   9  24  30  10   4]
 [  1   1  37 257  30 619   7  33   9   6]
 [  5  11  39  80  21   3 810   3  26   2]
 [  8   0   9  50  31   4   0 879   7  12]
 [ 12   4   1   9   0   0   0   1 951  22]
 [  4  35   1   5   0   0   0   1  15 939]]
TRAINING class wise acc@41 :: {0: [0.9828], 1: [0.9906], 2: [0.9806], 3: [0.9708], 4: [0.9794], 5: [0.9772], 6: [0.9862], 7: [0.989], 8: [0.9894], 9: [0.9882]}
TRAIINING epoch@41 ::  acc@0.983  loss@0.054
[[4914    3   17    3   18    0    0    7   25   13]
 [   6 4953    0    3    0    0    4    0    9   25]
 [  24    0 4903    7   17   19   17    9    4    0]
 [   7    3    8 4854   18   74   21    4    4    7]
 [  12    1   25   26 4897    9    7   23    0    0]
 [   0    0   13   72   11 4886    4   14    0    0]
 [   1    1   22   28    8    5 4931    0    4    0]
 [   4    0   10    8   17   11    0 4945    0    5]
 [  18    9    3   10    0    0    6    0 4947    7]
 [  11   22    0   16    0    0    0    3    7 4941]]
TESTING class wise acc@41 :: {0: [0.892], 1: [0.929], 2: [0.732], 3: [0.653], 4: [0.783], 5: [0.77], 6: [0.944], 7: [0.883], 8: [0.843], 9: [0.816]}
TESTING epoch@41 ::  acc@0.824  loss@0.976
Epoch@@42
[[892   8  39  13   8   4   7   7  18   4]
 [ 14 929   1   5   0   1  15   1  14  20]
 [ 49   1 732  21  45  46  93  10   2   1]
 [ 11   2  51 653  24 145  74  29   7   4]
 [ 10   0  41  43 783  24  73  24   2   0]
 [  3   0  30 112  18 770  37  30   0   0]
 [  5   0  11  20   8   8 944   1   3   0]
 [ 11   0  10  19  36  37   3 883   1   0]
 [106  15   6  12   3   2   4   1 843   8]
 [ 41  70   3  22   1   2   8  14  23 816]]
TRAINING class wise acc@42 :: {0: [0.9828], 1: [0.9898], 2: [0.9796], 3: [0.9654], 4: [0.9798], 5: [0.9744], 6: [0.9846], 7: [0.9864], 8: [0.9888], 9: [0.9866]}
TRAIINING epoch@42 ::  acc@0.982  loss@0.058
[[4914    6   21    5   12    0    0   10   17   15]
 [   5 4949    0    6    1    0    4    0    7   28]
 [  25    0 4898   16   14   21   14    6    6    0]
 [   8    5   12 4827   20   80   25    9    7    7]
 [  11    0   15   26 4899   15   12   21    1    0]
 [   0    0   21   69   14 4872    4   20    0    0]
 [   0    4   21   29   15    4 4923    0    4    0]
 [  13    0    9   11   16   17    0 4932    0    2]
 [  24    3    5    9    0    0    4    0 4944   11]
 [  13   29    0   12    0    0    0    6    7 4933]]
TESTING class wise acc@42 :: {0: [0.887], 1: [0.957], 2: [0.783], 3: [0.703], 4: [0.853], 5: [0.766], 6: [0.87], 7: [0.867], 8: [0.845], 9: [0.855]}
TESTING epoch@42 ::  acc@0.839  loss@0.817
Epoch@@43
[[887   8  57   9   6   0   3   5  18   7]
 [ 11 957   0   2   2   0   1   0   7  20]
 [ 42   2 783  31  47  36  40  16   2   1]
 [ 33   7  49 703  47  98  33  20   2   8]
 [ 21   1  41  36 853  12  24  12   0   0]
 [  8   1  33 103  40 766  13  36   0   0]
 [ 11   5  33  46  22   8 870   1   3   1]
 [ 13   0   8  29  59  18   1 867   1   4]
 [ 75  25  12  23   0   0   4   1 845  15]
 [ 35  90   3   7   0   1   0   1   8 855]]
TRAINING class wise acc@43 :: {0: [0.9834], 1: [0.9916], 2: [0.9804], 3: [0.9736], 4: [0.9834], 5: [0.9766], 6: [0.987], 7: [0.9892], 8: [0.987], 9: [0.9906]}
TRAIINING epoch@43 ::  acc@0.984  loss@0.053
[[4917    3   27    7    8    0    0    6   25    7]
 [   3 4958    0    3    3    0    5    0    9   19]
 [  18    0 4902   13   17   23   18    5    4    0]
 [  11    2   12 4868   19   57   19    4    4    4]
 [   8    0   20   15 4917   10   13   16    1    0]
 [   1    0   22   63    9 4883    9   13    0    0]
 [   0    5   16   24   10    4 4935    0    6    0]
 [   8    0    9   10   15   10    0 4946    0    2]
 [  21   10    6    8    0    0    6    0 4935   14]
 [   5   14    0    9    1    0    0    5   13 4953]]
TESTING class wise acc@43 :: {0: [0.812], 1: [0.929], 2: [0.737], 3: [0.687], 4: [0.808], 5: [0.69], 6: [0.82], 7: [0.872], 8: [0.948], 9: [0.906]}
TESTING epoch@43 ::  acc@0.821  loss@0.981
Epoch@@44
[[812  14  15   8   5   0   0   9 109  28]
 [  4 929   0   0   0   0   0   0  17  50]
 [ 63   7 737  54  31  20  29  21  35   3]
 [ 17  13  50 687  40  68  44  31  29  21]
 [ 24   2  57  45 808   9  16  23  14   2]
 [  7   4  38 142  35 690  23  39  16   6]
 [  9  22  49  39  27   7 820   0  27   0]
 [ 14   0   9  37  33  14   0 872   5  16]
 [ 16   9   0   6   1   0   2   1 948  17]
 [  9  52   1   3   1   1   0   1  26 906]]
TRAINING class wise acc@44 :: {0: [0.9836], 1: [0.9894], 2: [0.9822], 3: [0.9754], 4: [0.983], 5: [0.9806], 6: [0.9846], 7: [0.9854], 8: [0.99], 9: [0.9866]}
TRAIINING epoch@44 ::  acc@0.984  loss@0.051
[[4918    0   19    6   10    0    2    7   28   10]
 [   2 4947    0    4    0    0    7    0    8   32]
 [  17    0 4911   12   15   20   19    6    0    0]
 [   6    1    7 4877   16   47   16   16    6    8]
 [  13    2   12   15 4915   10   10   22    0    1]
 [   0    0   15   48    9 4903    6   19    0    0]
 [   0    7   27   19   10    7 4923    0    7    0]
 [   2    0   11   15   26   15    0 4927    0    4]
 [  27    7    4    5    0    0    3    0 4950    4]
 [  11   30    0   13    1    0    0    5    7 4933]]
TESTING class wise acc@44 :: {0: [0.871], 1: [0.931], 2: [0.776], 3: [0.777], 4: [0.856], 5: [0.759], 6: [0.865], 7: [0.845], 8: [0.814], 9: [0.896]}
TESTING epoch@44 ::  acc@0.839  loss@0.790
Epoch@@45
[[871   4  47  30  18   1   3   6   9  11]
 [  9 931   2   6   3   0   1   0   3  45]
 [ 47   0 776  54  45  35  38   3   1   1]
 [  7   2  36 777  42  95  28   7   1   5]
 [ 11   1  40  40 856  14  10  26   2   0]
 [  4   1  30 146  34 759   7  18   0   1]
 [  5   0  35  44  35  14 865   0   1   1]
 [ 13   0  18  53  38  28   1 845   0   4]
 [102  19   7  22   2   2  13   0 814  19]
 [ 21  49   1  20   1   1   1   5   5 896]]
TRAINING class wise acc@45 :: {0: [0.9866], 1: [0.9914], 2: [0.9838], 3: [0.976], 4: [0.9858], 5: [0.9804], 6: [0.9894], 7: [0.989], 8: [0.99], 9: [0.9924]}
TRAIINING epoch@45 ::  acc@0.986  loss@0.044
[[4933    3   23    7    6    0    0    4   18    6]
 [   5 4957    0    1    0    0    4    0   10   23]
 [  24    0 4919    9   13   15    9    7    4    0]
 [   6    0    8 4880   15   49   20   13    6    3]
 [   7    0   18   14 4929   10   11   11    0    0]
 [   0    0   20   49   10 4902    5   14    0    0]
 [   1    5    7   19   12    6 4947    0    3    0]
 [   4    0    8   13   14   11    0 4945    0    5]
 [  23    4    2    6    0    0    9    0 4950    6]
 [   6   18    0    4    0    0    0    4    6 4962]]
TESTING class wise acc@45 :: {0: [0.848], 1: [0.922], 2: [0.701], 3: [0.724], 4: [0.881], 5: [0.785], 6: [0.843], 7: [0.817], 8: [0.888], 9: [0.924]}
TESTING epoch@45 ::  acc@0.833  loss@0.872
Epoch@@46
[[848  15  29  32  11   2   3   3  33  24]
 [  6 922   1   4   2   0   0   0   5  60]
 [ 65   4 701  57  67  53  42   5   6   0]
 [ 11   5  33 724  45 127  35   8   3   9]
 [ 10   1  21  35 881  16  23   8   5   0]
 [  2   1  16 133  38 785   9  13   2   1]
 [  8  26  22  48  29  17 843   1   5   1]
 [ 14   0  15  31  65  53   1 817   0   4]
 [ 39  23   2  22   2   1   1   0 888  22]
 [ 13  41   1   9   1   3   0   2   6 924]]
TRAINING class wise acc@46 :: {0: [0.9814], 1: [0.9914], 2: [0.9806], 3: [0.974], 4: [0.9846], 5: [0.9838], 6: [0.9884], 7: [0.9886], 8: [0.9884], 9: [0.9908]}
TRAIINING epoch@46 ::  acc@0.985  loss@0.047
[[4907    3   24   10   10    0    0    7   28   11]
 [   9 4957    0    4    0    0    1    0    4   25]
 [  32    0 4903   12   20   14   14    5    0    0]
 [   8    2   14 4870   12   53   22    8    5    6]
 [   7    0   20   20 4923    7    5   18    0    0]
 [   0    0   13   48    5 4919    5   10    0    0]
 [   2    3   15   17    9    6 4942    0    6    0]
 [   8    0    5    7   14   19    0 4943    0    4]
 [  29    5    3   11    0    0    3    0 4942    7]
 [   9   18    0    7    0    0    0    5    7 4954]]
TESTING class wise acc@46 :: {0: [0.849], 1: [0.896], 2: [0.814], 3: [0.721], 4: [0.846], 5: [0.664], 6: [0.894], 7: [0.853], 8: [0.953], 9: [0.905]}
TESTING epoch@46 ::  acc@0.839  loss@0.851
Epoch@@47
[[849   6  34  21   9   0   5   6  61   9]
 [  8 896   2   2   0   0   4   0  33  55]
 [ 38   0 814  44  46  11  30   9   8   0]
 [ 10   2  82 721  37  44  66  19  17   2]
 [  6   0  54  36 846   9  25  19   5   0]
 [  3   0  72 177  35 664  17  28   4   0]
 [  5   3  43  25  20   2 894   0   8   0]
 [ 14   0  18  49  43  15   2 853   5   1]
 [ 26   3   3   9   0   0   1   0 953   5]
 [ 14  23   3  16   0   1   2   1  35 905]]
TRAINING class wise acc@47 :: {0: [0.986], 1: [0.9918], 2: [0.983], 3: [0.9758], 4: [0.9856], 5: [0.9812], 6: [0.9872], 7: [0.9904], 8: [0.9902], 9: [0.9904]}
TRAIINING epoch@47 ::  acc@0.986  loss@0.045
[[4930    3   23    8    6    0    1    5   15    9]
 [   2 4959    0    1    1    0    5    0   11   21]
 [  19    0 4915   13   12   10   17   12    2    0]
 [   4    3    9 4879   18   53   15    5    9    5]
 [   5    0   14   19 4928   11   12   11    0    0]
 [   0    0   15   46   12 4906   10   11    0    0]
 [   0    2   16   21   12    9 4936    0    4    0]
 [   5    0   10    4   15   14    0 4952    0    0]
 [  18    8    0   13    0    0    3    0 4951    7]
 [  11   20    0    7    0    0    0    3    7 4952]]
TESTING class wise acc@47 :: {0: [0.834], 1: [0.904], 2: [0.788], 3: [0.741], 4: [0.822], 5: [0.712], 6: [0.799], 7: [0.858], 8: [0.866], 9: [0.95]}
TESTING epoch@47 ::  acc@0.827  loss@0.891
Epoch@@48
[[834   9  69  16   7   1   0   6  28  30]
 [ 14 904   0   0   1   0   0   0   7  74]
 [ 44   5 788  51  38  33  26   7   6   2]
 [ 12   3  61 741  28  79  22  23   6  25]
 [  9   1  50  51 822  21  13  30   3   0]
 [  3   1  37 173  25 712   5  34   0  10]
 [  6  26  41  82  19  22 799   1   3   1]
 [ 13   1  13  35  34  27   1 858   1  17]
 [ 66  13  10  12   0   0   1   2 866  30]
 [ 10  26   2   6   0   1   0   0   5 950]]
TRAINING class wise acc@48 :: {0: [0.9854], 1: [0.9914], 2: [0.9818], 3: [0.9748], 4: [0.9862], 5: [0.9806], 6: [0.9872], 7: [0.9886], 8: [0.9914], 9: [0.99]}
TRAIINING epoch@48 ::  acc@0.986  loss@0.048
[[4927    3   22    6    5    0    1    4   22   10]
 [   3 4957    0    3    2    0    3    0    5   27]
 [  19    0 4909   13   12   23   12    7    5    0]
 [   4    2   12 4874   11   51   19   12    7    8]
 [   7    2   11    8 4931   11    8   22    0    0]
 [   0    0   13   55    6 4903   10   11    2    0]
 [   1    5   15   19    9   10 4936    0    5    0]
 [   5    0    6    5   19   18    0 4943    0    4]
 [  24    2    3   10    1    0    1    0 4957    2]
 [   6   23    0   11    0    0    0    4    6 4950]]
TESTING class wise acc@48 :: {0: [0.894], 1: [0.882], 2: [0.752], 3: [0.759], 4: [0.839], 5: [0.694], 6: [0.891], 7: [0.858], 8: [0.91], 9: [0.932]}
TESTING epoch@48 ::  acc@0.841  loss@0.816
Epoch@@49
[[894   5  21  18   9   0   1   4  39   9]
 [ 15 882   0   4   3   0   3   0  14  79]
 [ 72   0 752  46  44  21  49  10   6   0]
 [ 31   1  39 759  34  58  51  13   8   6]
 [ 13   0  33  45 839   7  33  24   5   1]
 [  7   0  53 164  36 694  13  30   2   1]
 [  9   4  20  44  17   9 891   2   3   1]
 [ 19   0  19  43  40  14   2 858   1   4]
 [ 49   2   5  11   0   0   4   0 910  19]
 [ 21  17   3  13   0   0   3   1  10 932]]
TRAINING class wise acc@49 :: {0: [0.9894], 1: [0.9926], 2: [0.9816], 3: [0.9782], 4: [0.9848], 5: [0.9836], 6: [0.9886], 7: [0.9922], 8: [0.9894], 9: [0.9918]}
TRAIINING epoch@49 ::  acc@0.987  loss@0.042
[[4947    0   18    5    4    0    2    5   17    2]
 [   3 4963    0    3    3    0    2    0    5   21]
 [  21    0 4908   12   17   19   16    6    1    0]
 [   2    1   13 4891   14   55   12    4    6    2]
 [   6    0   19   15 4924   13   13   10    0    0]
 [   0    0   10   50   11 4918    2    9    0    0]
 [   0    3   12   20   15    5 4943    0    2    0]
 [   4    0    3   11   12    8    0 4961    0    1]
 [  19    8    6    7    0    0    2    0 4947   11]
 [   6   20    0    5    0    0    0    3    7 4959]]
TESTING class wise acc@49 :: {0: [0.879], 1: [0.925], 2: [0.724], 3: [0.721], 4: [0.761], 5: [0.794], 6: [0.849], 7: [0.888], 8: [0.865], 9: [0.905]}
TESTING epoch@49 ::  acc@0.831  loss@0.871
[[879   3  29  35   7   3   1   9  21  13]
 [ 17 925   0   4   2   0   1   0  11  40]
 [ 54   2 724  61  47  63  32  10   7   0]
 [ 10   5  26 721  29 153  24  19   5   8]
 [ 15   1  39  63 761  46  16  55   2   2]
 [  4   0  19 131  18 794   4  28   0   2]
 [ 11   7  24  64  13  26 849   1   3   2]
 [ 16   0  14  38   9  29   0 888   1   5]
 [ 71  14   4  34   1   0   0   1 865  10]
 [ 24  46   1  12   0   0   0   2  10 905]]
